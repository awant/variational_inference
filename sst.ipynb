{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8eXUCRiWvYi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9mH-rUhWvYq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "device = torch.device('cpu')  # CPU should be fine for this lab\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okMoxTJ9bWjc"
   },
   "source": [
    "# Sentiment Classification \n",
    "\n",
    "\n",
    "We are going to augment a sentiment classifier with a layer of discrete latent variables which will help us improve the model's interpretability. But first, let's quickly review the baseline task.\n",
    "\n",
    "\n",
    "In sentiment classification, we have some text input $x = \\langle x_1, \\ldots, x_n \\rangle$, e.g. a sentence or short paragraph, which expresses a certain sentiment $y$, i.e. one of $K$ classes, towards a subject (e.g. a film or a product). \n",
    "\n",
    "\n",
    "\n",
    "We can learn a sentiment classifier by learning a categorical distribution over classes for a given input:\n",
    "\n",
    "\\begin{align}\n",
    "Y|x &\\sim \\text{Cat}(f(x; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where the Categorical pmf is $\\text{Cat}(y|\\pi) = \\pi_y$.\n",
    "\n",
    "A categorical distribution over $K$ classes is parameterised by a $K$-dimensional probability vector, here we use a neural network $f$ to map from the input to this probability vector. Technically we say *a neural network parameterise our model*, that is, it computes the parameters of our categorical observation model. The figure below is a graphical depiction of the model: circled nodes are random variables (a shaded node is an observed variable), uncircled nodes are deterministic, a plate indicates multiple draws.\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/classifier.png\"  height=\"100\">\n",
    "\n",
    "The neural network (NN) $f(\\cdot; \\theta)$ has parameters of its own, i.e. the weights of the various architecture blocks used, which we denoted generically by $\\theta$.\n",
    "\n",
    "Suppose we have a dataset $\\mathcal D = \\{(x^{(1)}, y^{(1)}), \\ldots, (x^{(N)}, y^{(N)})\\}$ containing $N$ i.i.d. observations. Then we can use the log-likelihood function \n",
    "\\begin{align}\n",
    "\\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{N} \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\\n",
    "&= \\sum_{k=1}^{N} \\log \\text{Cat}(y^{(k)}|f(x^{(k)}; \\theta))\n",
    "\\end{align}\n",
    " to estimate $\\theta$ by maximisation:\n",
    " \\begin{align}\n",
    " \\theta^\\star = \\arg\\max_{\\theta \\in \\Theta} \\mathcal L(\\theta|\\mathcal D) ~ .\n",
    " \\end{align}\n",
    " \n",
    "\n",
    "We can use stochastic gradient-ascent to find a local optimum of $\\mathcal L(\\theta|\\mathcal D)$, which only requires a gradient estimate:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{|\\mathcal D|} \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\ \n",
    "&= \\sum_{k=1}^{|\\mathcal D|} \\frac{1}{N} N \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta)  \\\\\n",
    "&= \\mathbb E_{\\mathcal U(1/N)} \\left[ N \\nabla_\\theta  \\log P(y^{(K)}|x^{(K)}, \\theta) \\right]  \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{N}{M} \\sum_{m=1}^M \\nabla_\\theta  \\log P(y^{(k_m)}|x^{(k_m)}, \\theta) \\\\\n",
    "&\\text{where }K_m \\sim \\mathcal U(1/N)\n",
    "\\end{align}\n",
    "\n",
    "This is a Monte Carlo (MC) estimate of the gradient computed on $M$ data points selected uniformly at random from $\\mathcal D$.\n",
    "\n",
    "For as long as $f$ remains differentiable wrt to its inputs and parameters, we can rely on automatic differentiation to obtain gradient estimates.\n",
    "\n",
    "In what follows we show how to design $f$ and how to extend this basic model to a latent-variable model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LUjyO-39zan"
   },
   "source": [
    "## Data\n",
    "\n",
    "We provide you some code to load the data (see `sst.sstutil.examplereader`). Play with the snippet below and inspect a few training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "4z8Bt5no9z6w",
    "outputId": "c9848b36-0b3d-49a0-d4da-db09e6c7f20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Examples\n",
      "First dev example: Example(tokens=['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "from sst.sstutil import examplereader, Vocabulary, load_glove\n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader('sst/data/sst/train.txt'))\n",
    "dev_data = list(examplereader('sst/data/sst/dev.txt'))\n",
    "test_data = list(examplereader('sst/data/sst/test.txt'))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Examples')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lB2lEsNuWvYx"
   },
   "source": [
    "## Architecture\n",
    "\n",
    "\n",
    "The function $f$ conditions on a high-dimensional input (i.e. text), so we need to convert it to continuous real vectors. This is the job an *encoder*. \n",
    "\n",
    "**Embedding Layer**\n",
    "\n",
    "The first step is to convert the words in $x$ to vectors, which in this lab we will do with a pre-trained embedding layer (we will use GloVe).\n",
    "\n",
    "We will denote the embedding of the $i$th word of the input by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf x_i = \\text{glove}(x_i)\n",
    "\\end{equation}\n",
    "\n",
    "**Encoder Layer**\n",
    "\n",
    "In this lab, an encoder takes a sequence of input vectors $\\mathbf x_1^n$, each $I$-dimensional, and produces a sequence of output vectors $\\mathbf t_1^n$, each $O$-dimensional and a summary vector $\\mathbf h \\in \\mathbb R^O$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf t_1^n, \\mathbf h = \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}})\n",
    "\\end{equation}\n",
    "\n",
    "where we use $\\theta_{\\text{enc}}$ to denote the subset of parameters in $\\theta$ that are specific to this encoder block. \n",
    "\n",
    "*Remark:* in practice for a correct batched implementation, our encoders also take a mask matrix and a vector of lengths.\n",
    "\n",
    "Examples of encoding functions can be a feed-forward NN (with an aggregator based on sum or average/max pooling) or a recurrent NN (e.g. an LSTM/GRU). Other architectures are also possible.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "From our summary vector $\\mathbf h$, we need to parameterise a categorical distribution over $K$ classes, thus we use\n",
    "\n",
    "\\begin{align}\n",
    "f(x; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where $\\text{dense}_K$ is a dense layer with $K=5$ outputs and $\\theta_{\\text{output}}$ corresponds to its parameters (weight matrix and bias vector). Note that we need to use the softmax activation function in order to guarantee that the output of $f$ is a normalised probability vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc15Nv2i41cq"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "To leave an indication of the shape of tensors in the code, we use the following convention\n",
    "\n",
    "```python\n",
    "[B, T, D]\n",
    "```\n",
    "\n",
    "where `B` stands for `batch_size`, `T` stands for `time` (or rather *maximum sequence length*), and `D` is the size of the representation.\n",
    "\n",
    "\n",
    "Consider the following abstract Encoder class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwEPXT2MWvYz",
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    An Encoder for us is a function that\n",
    "      1. transforms a sequence of I-dimensional vectors into a sequence of O-dimensional vectors\n",
    "      2. summarises a sequence of I-dimensional vectors into one O-dimensional vector\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        \"\"\"\n",
    "        The input is a batch-first tensor of token ids. Here is an example:\n",
    "        \n",
    "        Example of inputs (though rather than words, we have word ids):\n",
    "            INPUTS                     MASK       LENGTHS\n",
    "            [the nice cat -PAD-]    -> [1 1 1 0]  [3]\n",
    "            [the nice dog running]  -> [1 1 1 1]  [4]\n",
    "            \n",
    "        Note that:\n",
    "              mask =  inputs == 1\n",
    "              lengths = mask.sum(dim=-1)\n",
    "        \n",
    "        :param inputs: [B, T, I]\n",
    "        :param mask: [B, T]\n",
    "        :param lengths: [B]\n",
    "        :returns: [B, T, O], [B, O]\n",
    "            where the first tensor is the transformed input\n",
    "            and the second tensor is a summary of all inputs\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA5wmkcRg9Am"
   },
   "source": [
    "Let's start easy, implement a *bag of words* encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-9hLQ0lF5SG"
   },
   "outputs": [],
   "source": [
    "class BagOfWordsEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not transform the input sequence, \n",
    "     and its summary output is just a sum.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BagOfWordsEncoder, self).__init__()\n",
    "    \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        return inputs, (inputs * mask.unsqueeze(dim=-1).float()).sum(dim=1)  # sum along time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS7x0hLrUXfN"
   },
   "source": [
    "You can also consider implementing\n",
    "\n",
    "* a feed-forward encoder with average pooling\n",
    "* and a biLSTM encoder\n",
    "\n",
    "but these are certainly optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpOGFpK_Uo0-"
   },
   "outputs": [],
   "source": [
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size,\n",
    "                 activation=None,\n",
    "                 hidden_sizes=[],\n",
    "                 aggregator='avg',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        if aggregator not in ['avg', 'sum']:\n",
    "            raise RuntimeError(\"aggregator param should be 'avg' or 'sum' only\")\n",
    "        self.aggregator = aggregator\n",
    "        layers = []\n",
    "        \n",
    "        def add_dropout_if_possible(idx):\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(('dropout_{}'.format(idx),\n",
    "                                          nn.Dropout(dropout))))\n",
    "        \n",
    "        for idx, hidden_size in enumerate(hidden_sizes):\n",
    "            add_dropout_if_possible(idx)\n",
    "            layers.append(('linear_{}'.format(idx),\n",
    "                           nn.Linear(input_size, hidden_size)))\n",
    "            layers.append(('tanh_{}'.format(idx), nn.Tanh()))\n",
    "            input_size = hidden_size\n",
    "        add_dropout_if_possible(idx)\n",
    "        layers.append(('linear_{}'.format(idx),\n",
    "                       nn.Linear(input_size, output_size)))\n",
    "\n",
    "        self.layer = nn.Sequential(OrderedDict(layers))\n",
    "        self.activation = activation\n",
    "    \n",
    "    def compute_summary_vector(self, out, mask, lengths):\n",
    "        # summarize along time\n",
    "        sum_vec = (out * mask.unsqueeze(dim=-1).float()).sum(dim=1)\n",
    "        \n",
    "        if self.aggregator == 'sum':\n",
    "            return sum_vec\n",
    "        elif self.aggregator == 'avg':\n",
    "            return sum_vec / lengths.unsqueeze(dim=-1).float()\n",
    "        raise RuntimeError(\"Weird aggregator\")\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return: \n",
    "            outputs [B, T, O]\n",
    "            sum/avg pooling [B, O]\n",
    "        \"\"\"\n",
    "        out = self.activation(self.layer(x))\n",
    "        summary_out = self.compute_summary_vector(out, mask, lengths)\n",
    "        return out, summary_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxQ5djZ_VAvK"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence using a bidirectional LSTM\n",
    "     it returns the final state\n",
    "     and the hidden states at each time step. Note: we concatenate representations\n",
    "     from the two directions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features,\n",
    "                 hidden_size: int = 200,\n",
    "                 batch_first: bool = True,\n",
    "                 bidirectional: bool = True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        self.batch_first = batch_first\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=in_features,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=batch_first,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "    \n",
    "    def compute_summary_vec(self, hx):\n",
    "        if self.lstm.bidirectional:\n",
    "            return torch.cat([hx[-2], hx[-1]], dim=-1)\n",
    "        else:\n",
    "            return hx[-1]\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "            outputs [B, T, O]\n",
    "            final state [B, O]\n",
    "        \"\"\"\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=self.batch_first)\n",
    "        packed_out, (hx, cx) = self.lstm(packed_input)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=self.batch_first)\n",
    "        \n",
    "        summary_out = self.compute_summary_vec(hx)\n",
    "        \n",
    "        return out, summary_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_zz5zIyVkSh"
   },
   "source": [
    "Here is some helper code to select and return an encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59ZU6JddVjMV"
   },
   "outputs": [],
   "source": [
    "def get_encoder(layer, in_features, hidden_size, bidirectional=True):\n",
    "    \"\"\"Returns the requested layer.\"\"\"\n",
    "\n",
    "    # TODO: make pass and average layers\n",
    "    if layer == \"bow\":\n",
    "        return BagOfWordsEncoder()\n",
    "    elif layer == 'ff':\n",
    "        return FFEncoder(\n",
    "            in_features, \n",
    "            2 * hidden_size,  # output_size, for convenience to be equal to lstm\n",
    "            hidden_sizes=[hidden_size], \n",
    "            aggregator='avg')\n",
    "    elif layer == \"lstm\":\n",
    "        return LSTMEncoder(\n",
    "            in_features, \n",
    "            hidden_size,\n",
    "            bidirectional=bidirectional)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY8LZiMN5CHW"
   },
   "source": [
    "# Sentiment Classification with Latent Rationale\n",
    "\n",
    "A latent rationale is a compact and informative fragment of the input based on which a NN classifier makes its decisions. [Lei et al (2016)](http://aclweb.org/anthology/D16-1011) proposed to induce such rationales along with a regression model for multi-aspect sentiment analsysis, their model is trained via REINFORCE on a dataset of beer reviews.\n",
    "\n",
    "*Remark:* the model we will develop here can be seen as a probabilistic version of their model. The rest of this notebook focus on our own probabilitisc view of the model.\n",
    "\n",
    "The picture below depicts our latent-variable model for rationale extraction:\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/rationale.png\"  height=\"200\">\n",
    "\n",
    "where we augment the model with a collection of latent variables $z = \\langle z_1, \\ldots, z_n\\rangle$ where $z_i$ is a binary latent variable. Each latent variable $z_i$ regulates whether or not the input $x_i$ is available to the classifier.  We use $x \\odot z$ to denote the selected words, which, in the terminology of Lei et al, is a latent rationale.\n",
    "\n",
    "Again the classifier parameterises a Categorical distribution over $K=5$ outcomes, though this time it can encode only a selection of the input:\n",
    "\n",
    "\\begin{align}\n",
    "    Z_i & \\sim \\text{Bern}(p_1) \\\\\n",
    "    Y|z,x &\\sim \\text{Cat}(f(x \\odot z; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where we have a shared and fixed Bernoulli prior (with parameter $p_1$) for all $n$ latent variables.\n",
    "\n",
    "\n",
    "Here is an example design for $f$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= z_i \\, \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}}) \\\\\n",
    "f(x \\odot z; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "* $z_i$ either leaves $\\mathbf x_i$ unchanged or turns it into a vector of zeros;\n",
    "* the encoder only sees features from selected inputs, i.e. $x_i$ for which $z_i = 1$;\n",
    "* $\\text{dense}_K$ is a linear layer with $K=5$ outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDHNxLHMWvY-"
   },
   "source": [
    "## Prior\n",
    "\n",
    "\n",
    "Our prior is a Bernoulli with fixed parameter $0 < p_1 < 1$:\n",
    "\n",
    "\\begin{align}\n",
    "Z_i & \\sim \\text{Bern}(p_1)\n",
    "\\end{align}\n",
    "\n",
    "whose pmf is $\\text{Bern}(z_i|p_1) = p_1^{z_i}\\times (1-p_1)^{1-z_i}$.\n",
    "\n",
    "As we will be using Bernoulli priors and posteriors, it is a good idea to implement a Bernoulli class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCBcHnTsOuDr"
   },
   "outputs": [],
   "source": [
    "class Bernoulli(object):\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) * pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf). \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1/p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        if logits is None and probs is None:\n",
    "            raise RuntimeError(\"logits or probs should be specified\")\n",
    "        self.probs = torch.sigmoid(logits) if logits is not None else probs\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a single sample with the same shape as the parameters\"\"\"\n",
    "        return torch.bernoulli(self.probs)\n",
    "    \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample.\n",
    "        \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        return x * torch.log(self.probs) + (1. - x) * torch.log(1. - self.probs)\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        p, op = self.probs, other.probs\n",
    "        q, oq = 1. - p, 1. - op\n",
    "        return -(p*torch.log(op/p) + q*torch.log(oq/q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0yfkCZlWvZP"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "The classifier encodes only a selection of the input, which we denote $x \\odot z$, and parameterises a Categorical distribution over $5$ outcomes (sentiment levels).\n",
    "\n",
    "Thus let's implement a Categorical distribution (we will only need to be able to assess its lgo pmf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-6JLDnBQcdg"
   },
   "outputs": [],
   "source": [
    "class Categorical(object):\n",
    "    \n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "        \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B] integers (targets)\n",
    "        :returns: [B] scalars (log probabilities)\n",
    "        \"\"\"\n",
    "        return self.log_probs.gather(1, x.unsqueeze(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdrM_YRI8xBF"
   },
   "source": [
    "and a classifier architecture:\n",
    "\n",
    "* implement the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz7GaKbgRCd8"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:        nn.Embedding = None,\n",
    "                 hidden_size:  int = 200,\n",
    "                 output_size:  int = 1,\n",
    "                 dropout:      float = 0.1,\n",
    "                 layer:        str = \"pass\",\n",
    "                 ):\n",
    "\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            embed\n",
    "            # , nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        :params x: [B, T, I] word representations\n",
    "        :params mask: [B, T] indicates valid positions\n",
    "        :params z: [B, T] binary selectors\n",
    "        :returns: one Categorical distribution per instance in the batch\n",
    "          each conditioning only on x_i for which z_i = 1\n",
    "        \"\"\"\n",
    "        \n",
    "        embs = self.embed_layer(x)  # [B, T, E]\n",
    "        z_mask = z.unsqueeze(-1).float()\n",
    "        masked_emb = embs * z_mask\n",
    "        lengths = mask.sum(1)\n",
    "        \n",
    "        _, enc = self.enc_layer(masked_emb, mask, lengths=lengths)\n",
    "        log_probs = self.output_layer(enc)\n",
    "\n",
    "        return Categorical(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2waCCBF9MaH"
   },
   "source": [
    "## Inference\n",
    "\n",
    "\n",
    "Computing the log-likelihood of an observation requires marginalising over assignments of $z$:\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x,\\theta,p_1) &= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 P(z|p_1)\\times P(y|x,z, \\theta) \\\\\n",
    "&= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 \\left( \\prod_{i=1}^n \\text{Bern}(z_i|p_1)\\right) \\times \\text{Cat}(y|f(x \\odot z; \\theta)) \n",
    "\\end{align}\n",
    "\n",
    "This is clearly intractable: there are $2^n$ possible assignments to $z$ and because the classifier conditions on all latent selectors, there's no way to simplify the expression.\n",
    "\n",
    "We will avoid computing this intractable marginal by instead employing an independently parameterised inference model.\n",
    "This inference model $Q(z|x, y, \\lambda)$ is an approximation to the true postrerior $P(z|x, y, \\theta, p_1)$, and we use $\\lambda$ to denote its parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jcVdYTg8Wun"
   },
   "source": [
    "We make a *mean field* assumption, whereby we model latent variables independently given the input:\n",
    "\\begin{align}\n",
    "Q(z|x, y, \\lambda) \n",
    "    &= \\prod_{i=1}^{n} Q(z_i|x; \\lambda) \\\\\n",
    "    &= \\prod_{i=1}^{n} \\text{Bern}(z_i|g_i(x; \\lambda)) \n",
    "\\end{align}\n",
    "\n",
    "where $g(x; \\lambda)$ is a NN that maps from $x = \\langle x_1, \\ldots, x_n\\rangle$ to $n$ Bernoulli parameters, each of which, is a probability value (thus $0 < g_i(x; \\lambda) < 1$).\n",
    "\n",
    "Note that though we could condition on $y$ for approximate posterior inference, we are opportunistically leaving it out. This way, $Q$ is directly available at test time for making predictions. The figure below is a graphical depiction of the inference model (we show a dashed arrow from $y$ to $z$ to remind you that in principle the label is also available).\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/inference.png\"  height=\"200\">\n",
    "\n",
    "Here is an example design for $g$:\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\lambda_{\\text{enc}}) \\\\\n",
    "g_i(x; \\lambda) &= \\sigma(\\text{dense}_1(\\mathbf t_i; \\lambda_{\\text{output}}))\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{glove}$ is a pre-trained embedding function;\n",
    "* $\\text{dense}_1$ is a dense layer with a single output;\n",
    "* and $\\sigma(\\cdot)$ is the sigmoid function, necessary to parameterise a Bernoulli distribution.\n",
    "\n",
    "From now on we will write $Q(z|x, \\lambda)$, that is, without $y.\n",
    "\n",
    "Here we implement this product of Bernoulli distributions:\n",
    "\n",
    "* implement $g$ in the constructor \n",
    "* and the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLxfcAbuSiFo"
   },
   "outputs": [],
   "source": [
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:       nn.Embedding,\n",
    "                 hidden_size: int = 200,\n",
    "                 layer:       str = \"bow\"\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        :param embed: an embedding layer\n",
    "        :param hidden_suze: hidden size for transformed inputs\n",
    "        :param layer: 'bow' for BoW encoding\n",
    "          you may alternatively implement and 'lstm' option\n",
    "          which uses a biLSTM to transform the inputs\n",
    "        \"\"\"\n",
    "        super(ProductOfBernoullis, self).__init__()\n",
    "        # 1. we should have an embedding layer\n",
    "        # 2. we may transform the representations\n",
    "        # 3. and we should compute parameters for Bernoulli distributions\n",
    "        enc_size = hidden_size * 2\n",
    "        self.emb_layer = nn.Sequential(embed)\n",
    "        self.enc_layer = get_encoder(layer, embed.embedding_dim, hidden_size)\n",
    "        self.outp = nn.Linear(enc_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "        lengths = mask.sum(1)\n",
    "        \n",
    "        embs = self.emb_layer(x)\n",
    "        t, _ = self.enc_layer(embs, mask, lengths)\n",
    "        \n",
    "        logits = self.outp(t)\n",
    "        logits = logits.squeeze(-1)\n",
    "        \n",
    "#         logits = torch.log(self.sigmoid(self.outp(t)).squeeze(-1))\n",
    "        return Bernoulli(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcCu7vkKWvZX"
   },
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "In variational inference, our objective is to maximise the *evidence lowerbound* (ELBO):\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(y|x) &\\ge \\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\text{KL}(Q(z|x, y, \\lambda) || P(z|p_1)) \\\\\n",
    "\\text{ELBO}&\\overset{\\text{MF}}{=}\\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1)) \n",
    "\\end{align}\n",
    "\n",
    "where the *mean field* assumption we made implies that the KL term is simply a sum of KL divergences from a Bernoulli posterior to a Bernoulli prior.\n",
    "\n",
    "Note that the ELBO remains intractable, namely, solving the expectation in closed form still requires $2^n$ evaluations of the classifier network. Though unlike the true posterior $P(z|x,y, \\lambda)$, the approximation $Q(z|x,\\lambda)$ is tractable (it does not require an intractable normalisation) and can be used to obtain gradient estimates based on samples.\n",
    "\n",
    "### Gradient of the classifier network\n",
    "\n",
    "For the classifier, we encounter no problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\text{ELBO} &=\\nabla_\\theta\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\underbrace{\\nabla_\\theta \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{\\color{blue}{0}}  \\\\\n",
    "&=\\sum_{z} Q(z|x, \\lambda)\\nabla_\\theta\\log P(y|x,z,\\theta) \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\theta\\log P(y|x,z,\\theta) \\right] \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S \\nabla_\\theta \\log P(y|x, z^{(s)}, \\theta) \n",
    "\\end{align}\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$.\n",
    "\n",
    "\n",
    "### Gradient of the inference network\n",
    "\n",
    "For the inference model, we have to use the *score function estimator* (a.k.a. REINFORCE):\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\text{ELBO} &=\\nabla_\\lambda\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\nabla_\\lambda \\underbrace{\\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{ \\color{blue}{\\text{tractable} }}  \\\\\n",
    "&=\\sum_{z} \\nabla_\\lambda Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&=\\sum_{z}  \\underbrace{Q(z|x, \\lambda) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\nabla_\\lambda Q(z|x, \\lambda)} \\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(y|x,z,\\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) \\right] - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\left(\\frac{1}{S} \\sum_{s=1}^S  \\log P(y|x, z^{(s)}, \\theta) \\nabla_\\lambda \\log Q(z^{(s)}|x, \\lambda)  \\right) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))  \n",
    "\\end{align}\n",
    "\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cdfkOYdC0LQ"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Let's implement the model and the loss (negative ELBO). We work with the notion of a *surrogate loss*, that is, a computation node whose gradients wrt to parameters are equivalent to the gradients we need.\n",
    "\n",
    "For a given sample $z \\sim Q(z|x, \\lambda)$, the following is a single-sample surrogate loss:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal S(\\theta, \\lambda|x, y) = \\log P(y|x, z, \\theta) + \\color{red}{\\text{detach}(\\log P(y|x, z, \\theta) )}\\log Q(z|x, \\lambda) - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|\\phi))\n",
    "\\end{align}\n",
    "where we introduce an auxiliary function such that\n",
    "\\begin{align}\n",
    "\\text{detach}(f(\\alpha))  &= h(\\alpha) \\\\\n",
    "\\nabla_\\beta \\text{detach}(h(\\alpha))  &= 0 \n",
    "\\end{align}\n",
    "or in words, *detach* does not alter the forward call of its argument function $h$, but it alters $h$'s backward call by setting gradients to zero.\n",
    "\n",
    "Show that it's gradients wrt $\\theta$ and $\\lambda$ are exactly what we need:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FednEChaX6WI"
   },
   "source": [
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\mathcal S(\\theta, \\lambda|x, y) = \\color{red}{?}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaUMKDShx9T0"
   },
   "source": [
    "Implement the forward pass and loss below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cnwwk-7tfR02"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Classifier model:\n",
    "        Z_i ~ Bern(p_1) for i in 1..n\n",
    "        Y|x,z ~ Cat(f([x_i if z_i 1 else 0 for i in 1..n ]))\n",
    "    \n",
    "    Inference model:\n",
    "        Z_i|x ~ Bern(b_i) for i in 1..n\n",
    "            where b_i = g_i(x)\n",
    "    \n",
    "    Objective:\n",
    "        Single-sample MC estimate of ELBO\n",
    "    \n",
    "    Loss: \n",
    "        Surrogate loss\n",
    "\n",
    "    Consists of:\n",
    "        - a product of Bernoulli distributions inference network\n",
    "        - a classifier network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab:       object = None,\n",
    "                 vocab_size:  int = 0,\n",
    "                 emb_size:    int = 200,\n",
    "                 hidden_size: int = 200,\n",
    "                 num_classes: int = 5,\n",
    "                 prior_p1:    float = 0.3,                 \n",
    "                 det_prior: bool = True,\n",
    "                 beta_shape:  list = [0.6, 0.6],\n",
    "                 dropout:     float = 0.1,\n",
    "                 layer_cls:   str = 'bow',\n",
    "                 layer_inf:   str = 'bow',\n",
    "                 latent_variables: bool = True):\n",
    "        \"\"\"\n",
    "        :param vocab: Vocabulary\n",
    "        :param vocab_size: necessary for embedding layer\n",
    "        :param emb_size: dimensionality of embedding layer\n",
    "        :param hidden_size: dimensionality of hidden layers\n",
    "        :param num_classes: number of classes\n",
    "        :param prior_p1: (scalar) prior Bernoulli parameter\n",
    "        :param det_prior: (boolean) whether the prior parameter is deterministic\n",
    "        :param beta_shape: (pair of positive scalars) \n",
    "            when the prior parameter is stochastic\n",
    "            it is sampled from a Beta distribution (ignore this at first)\n",
    "        :param dropout: (scalar) dropout rate\n",
    "        :param layer_cls: type of encoder for classification\n",
    "        :param layer_inf: type of encoder for inference\n",
    "        :param latent_variables: whether compute and use Z as a latent variable\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.padding_idx = 1\n",
    "        self.embed = embed = nn.Embedding(vocab_size, emb_size,\n",
    "                                          padding_idx=self.padding_idx)\n",
    "\n",
    "        self.cls_net = Classifier(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size, \n",
    "            output_size=num_classes,\n",
    "            dropout=dropout, \n",
    "            layer=layer_cls)\n",
    "        \n",
    "        self.inference_net = ProductOfBernoullis(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size,\n",
    "            layer=layer_inf)\n",
    "        \n",
    "        self._prior_p1 = prior_p1\n",
    "        self._det_prior = det_prior\n",
    "        self._beta_shape = beta_shape\n",
    "        self._latent_variables = latent_variables\n",
    "        \n",
    "    def get_prior_p1(self, p_min=0.001, p_max=0.999):\n",
    "        \"\"\"Return the prior Bernoulli parameter\"\"\"\n",
    "        if self._det_prior:\n",
    "            return self._prior_p1\n",
    "        else:\n",
    "            a, b = self._beta_shape\n",
    "            prior_p1 = np.random.beta(a, b)\n",
    "            prior_p1 = max(prior_p1, p_min)\n",
    "            prior_p1 = min(prior_p1, p_max)\n",
    "        return prior_p1\n",
    "\n",
    "    def predict(self, py: Categorical, **kwargs):\n",
    "        \"\"\"\n",
    "        Predict deterministically using argmax.\n",
    "        :param py: B Categorical distributions (one per instance in batch)\n",
    "        :return: predictions\n",
    "            [B] sentiment levels\n",
    "        \"\"\"\n",
    "        assert not self.training, \"should be in eval mode for prediction\"\n",
    "        return py.log_probs.argmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Generate a sequence z with inference model, \n",
    "         then predict with rationale xz, that is, x masked by z.\n",
    "\n",
    "        :param x: [B, T] documents        \n",
    "        :param mask: [B, T] indicates valid positions vs padded positions\n",
    "        :return: \n",
    "            Categorical distributions P(y|x, z)\n",
    "            Bernoulli distributions Q(z|x)\n",
    "            Single sample z ~ Q(z|x) used for the conditional P(y|x, z)\n",
    "        \"\"\"\n",
    "        mask = x != self.padding_idx\n",
    "        \n",
    "        if self._latent_variables:\n",
    "            qz = self.inference_net(x, mask)\n",
    "        \n",
    "            if self.training:  # sample\n",
    "                # [B, T]\n",
    "                z = qz.sample()\n",
    "            else:  # deterministic\n",
    "                # [B, T]\n",
    "                # TODO: consider this\n",
    "                z = (qz.probs >= 0.5).float()\n",
    "                #z = qz.sample()\n",
    "        else:\n",
    "            qz = None\n",
    "            z = torch.ones_like(x)\n",
    "        \n",
    "        z = torch.where(mask, z, torch.zeros_like(z))\n",
    "        py = self.cls_net(x, mask, z)\n",
    "        return py, qz, z\n",
    "\n",
    "    def get_loss(self,\n",
    "                 y,\n",
    "                 py: Categorical,\n",
    "                 qz: Bernoulli,\n",
    "                 z,\n",
    "                 mask,\n",
    "                 iter_i=0,\n",
    "                 # you may ignore the rest of the arguments for the time being\n",
    "                 #  leave them as they are\n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This computes the loss for the whole model.\n",
    "\n",
    "        :param y: target labels [B]\n",
    "        :param py: conditionals P(y|x, z)\n",
    "        :param qz: approximate posteriors Q(z|x)\n",
    "        :param z: sample of binary selectors [B, T]\n",
    "        :param mask: indicates valid positions [B, T]\n",
    "        :param iter_i: indicates the iteration\n",
    "        :param kl_weight: (scalar) multiplies the KL term\n",
    "        :param min_kl: (scalar) sets a minimum for the KL (aka free bits)\n",
    "        :param ll_mean: (scalar) running average of reward\n",
    "        :param ll_std: (scalar) running standard deviation of reward\n",
    "        :return: loss (torch node), terms (dict)\n",
    "        \n",
    "            terms is an OrderedDict that holds the scalar items involved in the loss\n",
    "            e.g. `terms['ll'] = ll.item()` is the log-likelihood term\n",
    "            \n",
    "            Consider tracking the following:\n",
    "            Single-sample ELBO: terms['elbo']\n",
    "            Log-Likelihood log P(y|x,z): terms['ll']\n",
    "            KL: terms['kl']\n",
    "            Score function surrogate log P(y|z, x) log Q(z|x): terms['sf']            \n",
    "            Rate of selected words: terms['selected']\n",
    "        \"\"\"\n",
    "\n",
    "        lengths = mask.sum(1).float()\n",
    "        batch_size = mask.size(0)\n",
    "        terms = OrderedDict()\n",
    "\n",
    "        # shape: [B]\n",
    "        # log p(y|x,z) where z ~ q\n",
    "        #one_hot_target = (targets.unsqueeze(-1) == torch.arange(5, device=device).reshape(1, 5)).float()            \n",
    "        #ll = torch.sum(py.log_probs * one_hot_target, dim=-1)\n",
    "        # [B]\n",
    "        ll = py.log_pmf(y)\n",
    "        \n",
    "        if not self._latent_variables:\n",
    "            ll = ll.mean()\n",
    "            terms['ll'] = ll.item()\n",
    "            terms['ll_mean'] = ll_mean\n",
    "            terms['ll_std'] = ll_std\n",
    "            return -ll, terms\n",
    "        \n",
    "        # KL(q||p)\n",
    "        # [B, T]\n",
    "        prior_p1 = self.get_prior_p1()        \n",
    "        pz = Bernoulli(probs=torch.full_like(qz.probs, prior_p1))\n",
    "        \n",
    "        kl = qz.kl(pz)\n",
    "        kl = torch.where(mask, kl, torch.zeros_like(kl))\n",
    "\n",
    "        # Compute the log density of the sample\n",
    "        # [B, T]\n",
    "        log_q_z = qz.log_pmf(z)\n",
    "        log_q_z = torch.where(mask, log_q_z, torch.zeros_like(log_q_z))\n",
    "        # We have independent Bernoullis, thus we just sum their log probabilities\n",
    "        # [B]\n",
    "        log_q_z = log_q_z.sum(1)\n",
    "        \n",
    "        # surrogate objective for score function estimator\n",
    "        # [B]\n",
    "        reward = (ll.detach() - torch.full_like(ll, ll_mean)) / torch.full_like(ll, ll_std)\n",
    "        sf_surrogate = (reward * log_q_z)\n",
    "\n",
    "        # Make terms in the ELBO\n",
    "        # []\n",
    "        ll = ll.mean()\n",
    "        sf_surrogate = sf_surrogate.mean()\n",
    "        # KL may require annealing and free-bits\n",
    "        # [B]\n",
    "        kl = kl.sum(dim=-1)\n",
    "        kl_fb = torch.max(torch.full_like(kl, min_kl), kl)\n",
    "        # []\n",
    "        kl = kl.mean() \n",
    "        kl_fb = kl_fb.mean() \n",
    "        kl_fb = kl_fb * kl_weight\n",
    "        \n",
    "        terms['elbo'] = (ll - kl_fb).item()\n",
    "        terms['ll'] = ll.item()\n",
    "        terms['kl_fb'] = kl_fb.item()\n",
    "        terms['kl'] = kl.item()\n",
    "        terms['kl_weight'] = kl_weight\n",
    "        terms['sf'] = sf_surrogate.item()\n",
    "        terms['reward'] = reward.mean().item()\n",
    "        terms['ll_mean'] = ll_mean\n",
    "        terms['ll_std'] = ll_std\n",
    "        terms['selected'] = (z.sum(1) / lengths).mean().item()\n",
    "        terms['prior_p1'] = prior_p1\n",
    "        terms['avg_p1'] = (torch.where(mask, qz.probs, torch.zeros_like(qz.probs)).sum() / mask.sum().float()).item()\n",
    "        # TODO log min and max p1 in batch (mask properly)\n",
    "        return - ll - sf_surrogate + kl_fb, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNQDXTpqWvZa"
   },
   "outputs": [],
   "source": [
    "# This will be used later for maintaining running averages of quantites like\n",
    "#  terms in the ELBO\n",
    "from collections import deque\n",
    "\n",
    "class MovingStats:\n",
    "    \n",
    "    def __init__(self, memory=-1):\n",
    "        self.data = deque([])\n",
    "        self.memory = memory\n",
    "        \n",
    "    def append(self, value):\n",
    "        if self.memory != 0:\n",
    "            if self.memory > 0 and len(self.data) == self.memory:\n",
    "                self.data.popleft()\n",
    "            self.data.append(value)\n",
    "        \n",
    "    def mean(self):\n",
    "        if len(self.data):\n",
    "            return np.mean([x for x in self.data])\n",
    "        else:\n",
    "            return 0.\n",
    "    \n",
    "    def std(self):\n",
    "        return np.std(self.data) if len(self.data) > 1 else 1.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "081YSfU9WvZc"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Pc80gseWvZd"
   },
   "outputs": [],
   "source": [
    "# some helper code for mini batching\n",
    "#  this will take care of annoying things such as \n",
    "#  sorting training instances by length (necessary for pytorch's LSTM, for example)\n",
    "from sst.util import make_kv_string, get_minibatch, prepare_minibatch, print_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "_WVr97kilIRV",
    "outputId": "7a9a3984-682a-4520-9f13-84f9364b4d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Configuration\n",
      "training_path        : sst/data/sst/train.txt\n",
      "dev_path             : sst/data/sst/dev.txt\n",
      "test_path            : sst/data/sst/test.txt\n",
      "word_vectors         : sst/data/sst/glove.840B.300d.filtered.txt\n",
      "prior_p1             :        0.3\n",
      "beta_a               :        0.6\n",
      "beta_b               :        0.6\n",
      "det_prior            :          1\n",
      "num_epochs           :         50\n",
      "print_every          :        100\n",
      "eval_every           :         -1\n",
      "batch_size           :         25\n",
      "eval_batch_size      :         25\n",
      "subphrases           :          0\n",
      "min_phrase_length    :          2\n",
      "lowercase            :          1\n",
      "fix_emb              :          1\n",
      "embed_size           :        300\n",
      "hidden_size          :        150\n",
      "num_layers           :          1\n",
      "dropout              :        0.5\n",
      "layer_inf            : bow       \n",
      "layer_cls            : bow       \n",
      "save_path            : data/results\n",
      "baseline_memory      :       1000\n",
      "min_kl               :        0.0\n",
      "kl_weight            :        1.0\n",
      "kl_inc               :      1e-05\n",
      "lr                   :     0.0002\n",
      "weight_decay         :      1e-05\n",
      "lr_decay             :        0.5\n",
      "patience             :          5\n",
      "cooldown             :          5\n",
      "threshold            :     0.0001\n",
      "min_lr               :      1e-05\n",
      "max_grad_norm        :        5.0\n",
      "latent_variables     :          1\n",
      "Set eval_every to 341\n",
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Example\n",
      "First dev example: Example(tokens=['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "# We will use Adam\n",
    "from torch.optim import Adam\n",
    "# and a couple of tricks to reduce learning rate on plateau\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# here is some helper code to evaluate your model\n",
    "from sst.evaluate import evaluate\n",
    "\n",
    "\n",
    "cfg = dict()\n",
    "\n",
    "# Data\n",
    "cfg['training_path'] = \"sst/data/sst/train.txt\"\n",
    "cfg['dev_path'] = \"sst/data/sst/dev.txt\"\n",
    "cfg['test_path'] = \"sst/data/sst/test.txt\"\n",
    "cfg['word_vectors'] = 'sst/data/sst/glove.840B.300d.filtered.txt'\n",
    "# Model\n",
    "cfg['prior_p1'] = 0.3\n",
    "cfg['beta_a'] = 0.6\n",
    "cfg['beta_b'] = 0.6\n",
    "cfg['det_prior'] = True\n",
    "# Architecture\n",
    "cfg['num_epochs'] = 50  # 50\n",
    "cfg['print_every'] = 100\n",
    "cfg['eval_every'] = -1\n",
    "cfg['batch_size'] = 25\n",
    "cfg['eval_batch_size'] = 25\n",
    "cfg['subphrases'] = False\n",
    "cfg['min_phrase_length'] = 2\n",
    "cfg['lowercase'] = True\n",
    "cfg['fix_emb'] = True\n",
    "cfg['embed_size'] = 300\n",
    "cfg['hidden_size'] = 150\n",
    "cfg['num_layers'] = 1\n",
    "cfg['dropout'] = 0.5\n",
    "cfg['layer_inf'] = 'bow'\n",
    "cfg['layer_cls'] = 'bow'\n",
    "cfg['save_path'] = 'data/results'\n",
    "cfg['baseline_memory'] = 1000\n",
    "cfg['min_kl'] = 0.  # use more than 0 to enable free bits\n",
    "cfg['kl_weight'] = 1.  # start from zero to enable annealing\n",
    "cfg['kl_inc'] = 0.00001  \n",
    "# Optimiser (leave as is)\n",
    "cfg['lr'] = 0.0002\n",
    "cfg['weight_decay'] = 1e-5\n",
    "cfg['lr_decay'] = 0.5\n",
    "cfg['patience'] = 5\n",
    "cfg['cooldown'] = 5\n",
    "cfg['threshold'] = 1e-4\n",
    "cfg['min_lr'] = 1e-5\n",
    "cfg['max_grad_norm'] = 5.\n",
    "# special case - with latent variables\n",
    "cfg['latent_variables'] = True\n",
    "\n",
    "\n",
    "print('# Configuration')\n",
    "for k, v in cfg.items():\n",
    "    print(\"{:20} : {:10}\".format(k, v))\n",
    "\n",
    "\n",
    "iters_per_epoch = len(train_data) // cfg[\"batch_size\"]\n",
    "\n",
    "if cfg[\"eval_every\"] == -1:\n",
    "    eval_every = iters_per_epoch\n",
    "    print(\"Set eval_every to {}\".format(iters_per_epoch))\n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader(\n",
    "    cfg['training_path'],\n",
    "    lower=cfg['lowercase'], \n",
    "    subphrases=cfg['subphrases'],\n",
    "    min_length=cfg['min_phrase_length']))\n",
    "dev_data = list(examplereader(cfg['dev_path'], lower=cfg['lowercase']))\n",
    "test_data = list(examplereader(cfg['test_path'], lower=cfg['lowercase']))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Example')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7cvA4K3q2QY2",
    "outputId": "15245097-3f5c-4fc4-8816-b13fb90cacef"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvoFbqez12o8"
   },
   "outputs": [],
   "source": [
    "def compute_pos_frequency(sents):\n",
    "    # decorate func made key tokens bold: dec = \"**\" if z_ == 1 else \"\"\n",
    "    def extract_tokens_z(tokens):\n",
    "        z = list(map(lambda t: int(t[:2] == '**'), tokens))\n",
    "        pure_tokens = list(map(lambda x: x[0][2:-2] if z == 1 else x[0], zip(tokens, z)))\n",
    "        return pure_tokens, z\n",
    "    \n",
    "    pos_freqs = []\n",
    "    for raw_tokens in sents:\n",
    "        pure_tokens, z = extract_tokens_z(raw_tokens)\n",
    "        tagged_tokens = nltk.pos_tag(pure_tokens)\n",
    "        POSes = list(zip(*tagged_tokens))[1]\n",
    "        pos_freqs += [pos for pos, z_ in zip(POSes, z) if z_ == 1]\n",
    "    \n",
    "    pos_freqs = Counter(pos_freqs)\n",
    "    return pos_freqs\n",
    "\n",
    "\n",
    "sents_samples = [\n",
    "    ['**Today**', '**is**', 'a', 'good', '**day**', '.'],\n",
    "    ['Yes', ',', '**it**', 'is']\n",
    "]\n",
    "assert compute_pos_frequency(sents_samples) == Counter({'NN': 2, 'FW': 1, 'VBZ': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PMqtVj0WvZf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Create a vocabulary object to map str <-> int\n",
    "    vocab = Vocabulary()  # populated by load_glove\n",
    "    glove_path = cfg[\"word_vectors\"]\n",
    "    vectors = load_glove(glove_path, vocab)\n",
    "\n",
    "    # You may consider using tensorboardX\n",
    "    # writer = SummaryWriter(log_dir=cfg[\"save_path\"])\n",
    "\n",
    "    # Map the sentiment labels 0-4 to a more readable form (and the opposite)\n",
    "    i2t = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
    "    t2i = OrderedDict({p: i for p, i in zip(i2t, range(len(i2t)))})\n",
    "\n",
    "\n",
    "    print('\\n# Constructing model')\n",
    "    model = Model(\n",
    "        vocab_size=len(vocab.w2i),\n",
    "        emb_size=cfg[\"embed_size\"],\n",
    "        hidden_size=cfg[\"hidden_size\"],\n",
    "        num_classes=len(t2i),\n",
    "        prior_p1=cfg['prior_p1'],\n",
    "        det_prior=cfg['det_prior'],\n",
    "        beta_shape=[cfg['beta_a'], cfg['beta_b']],\n",
    "        vocab=vocab,\n",
    "        dropout=cfg[\"dropout\"],\n",
    "        layer_cls=cfg[\"layer_cls\"],\n",
    "        layer_inf=cfg[\"layer_inf\"],\n",
    "        latent_variables=cfg['latent_variables'])\n",
    "\n",
    "    print('\\n# Loading embeddings')\n",
    "    with torch.no_grad():\n",
    "        model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "        if cfg[\"fix_emb\"]:\n",
    "            print(\"fixed word embeddings\")\n",
    "            model.embed.weight.requires_grad = False\n",
    "        model.embed.weight[1] = 0.  # padding zero\n",
    "\n",
    "    \n",
    "    # Congigure optimiser\n",
    "    optimizer = Adam(model.parameters(), lr=cfg[\"lr\"],\n",
    "                     weight_decay=cfg[\"weight_decay\"])\n",
    "    # and learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "        verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "        min_lr=cfg[\"min_lr\"])\n",
    "\n",
    "    # Prepare a few auxiliary variables\n",
    "    iter_i = 0\n",
    "    train_loss = 0.\n",
    "    print_num = 0\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    best_eval = 1.0e9\n",
    "    best_iter = 0\n",
    "    dev_pos_freqs = None\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Some debugging info\n",
    "    print(model)\n",
    "    print_parameters(model)\n",
    "\n",
    "    batch_size = cfg['batch_size']\n",
    "    eval_batch_size = cfg['eval_batch_size']\n",
    "    print_every = cfg['print_every']\n",
    "\n",
    "    # Parameters of tricks to better optimise the ELBO\n",
    "    kl_inc = cfg['kl_inc']\n",
    "    kl_weight = cfg['kl_weight']\n",
    "    min_kl = cfg['min_kl']\n",
    "    # Running estimates for baselines\n",
    "    ll_moving_stats = MovingStats(cfg['baseline_memory'])\n",
    "    \n",
    "    \n",
    "    stop_training = False\n",
    "    while True:  # when we run out of examples, shuffle and continue\n",
    "        for batch in get_minibatch(train_data, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "            epoch = iter_i // iters_per_epoch\n",
    "            if epoch > cfg['num_epochs']:\n",
    "                stop_training = True\n",
    "                break\n",
    "\n",
    "            # forward pass\n",
    "            model.train()\n",
    "            x, y, _ = prepare_minibatch(batch, model.vocab, device=device)\n",
    "            \n",
    "            py, qz, z = model(x)\n",
    "            \n",
    "            mask = (x != 1)\n",
    "\n",
    "            # \"KL annealing\"\n",
    "            kl_weight += kl_inc\n",
    "            if kl_weight > 1.:\n",
    "                kl_weight = 1.0\n",
    "                \n",
    "            loss, terms = model.get_loss(\n",
    "                y,\n",
    "                py=py, \n",
    "                qz=qz,\n",
    "                z=z,\n",
    "                mask=mask, \n",
    "                kl_weight=kl_weight,\n",
    "                min_kl=min_kl,\n",
    "                ll_mean=ll_moving_stats.mean(),\n",
    "                ll_std=ll_moving_stats.std(),\n",
    "                iter_i=iter_i)\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # keep an running estimate of the reward (log P(y|x,z))\n",
    "            ll_moving_stats.append(terms['ll'])\n",
    "\n",
    "            # backward pass\n",
    "            model.zero_grad()  # erase previous gradients\n",
    "\n",
    "            loss.backward()  # compute new gradients\n",
    "\n",
    "            # gradient clipping generally helps\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['max_grad_norm'])\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            print_num += 1\n",
    "            iter_i += 1\n",
    "\n",
    "            # print info\n",
    "            if iter_i % print_every == 0:\n",
    "\n",
    "                train_loss = train_loss / print_every\n",
    "\n",
    "                print_str = make_kv_string(terms)\n",
    "                print(\"Epoch %r Iter %r loss=%.4f %s\" %\n",
    "                      (epoch, iter_i, train_loss, print_str))\n",
    "                losses.append(train_loss)\n",
    "                print_num = 0\n",
    "                train_loss = 0.\n",
    "\n",
    "            # evaluate\n",
    "            if iter_i % eval_every == 0:\n",
    "\n",
    "                dev_eval, rationales = evaluate(\n",
    "                    model, dev_data,\n",
    "                    batch_size=eval_batch_size,\n",
    "                    device=device,\n",
    "                    cfg=cfg, iter_i=iter_i)\n",
    "                accuracies.append(dev_eval[\"acc\"])\n",
    "                \n",
    "                # compute pos freqs for the last epoch\n",
    "                if (iter_i // iters_per_epoch) > cfg['num_epochs']:\n",
    "                    tokens = [rationale[0] for rationale in rationales]\n",
    "                    dev_pos_freqs = compute_pos_frequency(tokens)\n",
    "\n",
    "                print(\"\\n# epoch %r iter %r: dev %s\" % (\n",
    "                    epoch, iter_i, make_kv_string(dev_eval)))\n",
    "                \n",
    "                for exid in range(3):\n",
    "                    print(' dev%d [gold=%d,pred=%d]:' % (exid, dev_data[exid].label, rationales[exid][1]),  \n",
    "                          ' '.join(rationales[exid][0]))\n",
    "                print()\n",
    "\n",
    "                # adjust learning rate\n",
    "                scheduler.step(dev_eval[\"loss\"])\n",
    "        if stop_training:\n",
    "            break\n",
    "    \n",
    "    return accuracies, losses, dev_pos_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89389
    },
    "colab_type": "code",
    "id": "A5uYKcw-WvZl",
    "outputId": "c4c3e3c6-000b-4418-adc7-bad1a67704fb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Constructing model\n",
      "Classifier #params: 1505\n",
      "ProductOfBernoullis #params: 6218401\n",
      "\n",
      "# Loading embeddings\n",
      "fixed word embeddings\n",
      "Model(\n",
      "  (embed): Embedding(20727, 300, padding_idx=1)\n",
      "  (cls_net): Classifier(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): BagOfWordsEncoder()\n",
      "    (output_layer): Sequential(\n",
      "      (0): Dropout(p=0.5)\n",
      "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
      "      (2): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (inference_net): ProductOfBernoullis(\n",
      "    (emb_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "    )\n",
      "    (enc_layer): BagOfWordsEncoder()\n",
      "    (outp): Linear(in_features=300, out_features=1, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "embed.weight             [20727, 300] requires_grad=False\n",
      "cls_net.output_layer.1.weight [5, 300]     requires_grad=True\n",
      "cls_net.output_layer.1.bias [5]          requires_grad=True\n",
      "inference_net.outp.weight [1, 300]     requires_grad=True\n",
      "inference_net.outp.bias  [1]          requires_grad=True\n",
      "\n",
      "Total parameters: 6219906\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 0 Iter 100 loss=8.5134 elbo -2.5222 ll -1.9053 kl_fb 0.6169 kl 0.6169 kl_weight 1.0000 sf -4.1746 reward 0.3153 ll_mean -1.9979 ll_std 0.2939 selected 0.3972 prior_p1 0.3000 avg_p1 0.4072\n",
      "Epoch 0 Iter 200 loss=10.5925 elbo -2.0366 ll -1.7523 kl_fb 0.2843 kl 0.2843 kl_weight 1.0000 sf -4.4556 reward 0.4027 ll_mean -1.8603 ll_std 0.2681 selected 0.3191 prior_p1 0.3000 avg_p1 0.3547\n",
      "Epoch 0 Iter 300 loss=10.3998 elbo -1.8103 ll -1.6071 kl_fb 0.2032 kl 0.2032 kl_weight 1.0000 sf -7.9013 reward 0.7111 ll_mean -1.7868 ll_std 0.2528 selected 0.3153 prior_p1 0.3000 avg_p1 0.3315\n",
      "\n",
      "# epoch 0 iter 341: dev loss -10.4717 elbo -1.8027 ll -1.5967 kl_fb 0.2061 kl 0.2061 kl_weight 1.0000 sf 12.2744 reward -1.5967 ll_mean 0.0000 ll_std 1.0000 selected 0.0115 prior_p1 0.3000 avg_p1 0.3263 acc 0.2598\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=2]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 1 Iter 400 loss=7.5883 elbo -1.8418 ll -1.6227 kl_fb 0.2191 kl 0.2191 kl_weight 1.0000 sf -7.3822 reward 0.5496 ll_mean -1.7524 ll_std 0.2360 selected 0.2784 prior_p1 0.3000 avg_p1 0.3229\n",
      "Epoch 1 Iter 500 loss=9.7850 elbo -1.7101 ll -1.6001 kl_fb 0.1100 kl 0.1100 kl_weight 1.0000 sf -4.8848 reward 0.5099 ll_mean -1.7159 ll_std 0.2272 selected 0.3029 prior_p1 0.3000 avg_p1 0.3132\n",
      "Epoch 1 Iter 600 loss=8.3566 elbo -1.7042 ll -1.5619 kl_fb 0.1423 kl 0.1423 kl_weight 1.0000 sf -6.6265 reward 0.5996 ll_mean -1.6931 ll_std 0.2187 selected 0.3257 prior_p1 0.3000 avg_p1 0.3166\n",
      "\n",
      "# epoch 1 iter 682: dev loss -10.1558 elbo -1.7325 ll -1.5930 kl_fb 0.1395 kl 0.1395 kl_weight 1.0000 sf 11.8884 reward -1.5930 ll_mean 0.0000 ll_std 1.0000 selected 0.0049 prior_p1 0.3000 avg_p1 0.3185 acc 0.2607\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=2]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 2 Iter 700 loss=8.6415 elbo -1.6225 ll -1.4771 kl_fb 0.1454 kl 0.1454 kl_weight 1.0000 sf -11.5421 reward 0.9332 ll_mean -1.6737 ll_std 0.2107 selected 0.3289 prior_p1 0.3000 avg_p1 0.3182\n",
      "Epoch 2 Iter 800 loss=8.0629 elbo -1.4658 ll -1.3321 kl_fb 0.1337 kl 0.1337 kl_weight 1.0000 sf -17.4556 reward 1.6061 ll_mean -1.6591 ll_std 0.2036 selected 0.2943 prior_p1 0.3000 avg_p1 0.3200\n",
      "Epoch 2 Iter 900 loss=7.6479 elbo -1.7526 ll -1.6214 kl_fb 0.1312 kl 0.1312 kl_weight 1.0000 sf -1.5531 reward 0.1286 ll_mean -1.6468 ll_std 0.1971 selected 0.3337 prior_p1 0.3000 avg_p1 0.3205\n",
      "Epoch 2 Iter 1000 loss=8.1009 elbo -1.8316 ll -1.7169 kl_fb 0.1147 kl 0.1147 kl_weight 1.0000 sf 4.9033 reward -0.4222 ll_mean -1.6356 ll_std 0.1927 selected 0.3244 prior_p1 0.3000 avg_p1 0.3191\n",
      "\n",
      "# epoch 2 iter 1023: dev loss -10.0255 elbo -1.6964 ll -1.5927 kl_fb 0.1037 kl 0.1037 kl_weight 1.0000 sf 11.7219 reward -1.5927 ll_mean 0.0000 ll_std 1.0000 selected 0.0018 prior_p1 0.3000 avg_p1 0.3152 acc 0.2561\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 3 Iter 1100 loss=6.8404 elbo -1.6170 ll -1.5420 kl_fb 0.0750 kl 0.0750 kl_weight 1.0000 sf -3.8812 reward 0.3916 ll_mean -1.5904 ll_std 0.1235 selected 0.2763 prior_p1 0.3000 avg_p1 0.3123\n",
      "Epoch 3 Iter 1200 loss=4.7155 elbo -1.5238 ll -1.4462 kl_fb 0.0776 kl 0.0776 kl_weight 1.0000 sf -14.2049 reward 1.1543 ll_mean -1.5731 ll_std 0.1099 selected 0.2843 prior_p1 0.3000 avg_p1 0.3089\n",
      "Epoch 3 Iter 1300 loss=6.2461 elbo -1.5286 ll -1.4639 kl_fb 0.0647 kl 0.0647 kl_weight 1.0000 sf -9.8595 reward 0.9227 ll_mean -1.5614 ll_std 0.1056 selected 0.2716 prior_p1 0.3000 avg_p1 0.3091\n",
      "\n",
      "# epoch 3 iter 1364: dev loss -9.9181 elbo -1.6724 ll -1.5907 kl_fb 0.0817 kl 0.0817 kl_weight 1.0000 sf 11.5905 reward -1.5907 ll_mean 0.0000 ll_std 1.0000 selected 0.0010 prior_p1 0.3000 avg_p1 0.3129 acc 0.2589\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 4 Iter 1400 loss=5.6790 elbo -1.4257 ll -1.3230 kl_fb 0.1027 kl 0.1027 kl_weight 1.0000 sf -30.6278 reward 2.3166 ll_mean -1.5486 ll_std 0.0974 selected 0.2937 prior_p1 0.3000 avg_p1 0.3140\n",
      "Epoch 4 Iter 1500 loss=5.4584 elbo -1.5902 ll -1.5214 kl_fb 0.0688 kl 0.0688 kl_weight 1.0000 sf -2.7551 reward 0.2130 ll_mean -1.5426 ll_std 0.0992 selected 0.2740 prior_p1 0.3000 avg_p1 0.3134\n",
      "Epoch 4 Iter 1600 loss=3.0554 elbo -1.7028 ll -1.6272 kl_fb 0.0756 kl 0.0756 kl_weight 1.0000 sf 11.6222 reward -0.9344 ll_mean -1.5374 ll_std 0.0961 selected 0.3536 prior_p1 0.3000 avg_p1 0.3141\n",
      "Epoch 4 Iter 1700 loss=4.1407 elbo -1.5209 ll -1.4651 kl_fb 0.0558 kl 0.0558 kl_weight 1.0000 sf -8.3420 reward 0.6971 ll_mean -1.5332 ll_std 0.0976 selected 0.3327 prior_p1 0.3000 avg_p1 0.3066\n",
      "\n",
      "# epoch 4 iter 1705: dev loss -9.6538 elbo -1.6557 ll -1.5886 kl_fb 0.0671 kl 0.0671 kl_weight 1.0000 sf 11.3095 reward -1.5886 ll_mean 0.0000 ll_std 1.0000 selected 0.0006 prior_p1 0.3000 avg_p1 0.3071 acc 0.2598\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 5 Iter 1800 loss=2.5375 elbo -1.5764 ll -1.5095 kl_fb 0.0668 kl 0.0668 kl_weight 1.0000 sf -2.4415 reward 0.2089 ll_mean -1.5296 ll_std 0.0961 selected 0.2625 prior_p1 0.3000 avg_p1 0.3079\n",
      "Epoch 5 Iter 1900 loss=4.5140 elbo -1.4498 ll -1.3955 kl_fb 0.0542 kl 0.0542 kl_weight 1.0000 sf -16.3585 reward 1.3177 ll_mean -1.5251 ll_std 0.0983 selected 0.3104 prior_p1 0.3000 avg_p1 0.3039\n",
      "Epoch 5 Iter 2000 loss=4.5231 elbo -1.4906 ll -1.4203 kl_fb 0.0703 kl 0.0703 kl_weight 1.0000 sf -14.1824 reward 1.0315 ll_mean -1.5215 ll_std 0.0981 selected 0.2955 prior_p1 0.3000 avg_p1 0.3116\n",
      "\n",
      "# epoch 5 iter 2046: dev loss -9.7011 elbo -1.6443 ll -1.5869 kl_fb 0.0574 kl 0.0574 kl_weight 1.0000 sf 11.3454 reward -1.5869 ll_mean 0.0000 ll_std 1.0000 selected 0.0002 prior_p1 0.3000 avg_p1 0.3083 acc 0.2616\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 6 Iter 2100 loss=2.7520 elbo -1.5008 ll -1.4316 kl_fb 0.0692 kl 0.0692 kl_weight 1.0000 sf -10.9305 reward 0.8854 ll_mean -1.5181 ll_std 0.0977 selected 0.3180 prior_p1 0.3000 avg_p1 0.3114\n",
      "Epoch 6 Iter 2200 loss=1.0470 elbo -1.6884 ll -1.6441 kl_fb 0.0443 kl 0.0443 kl_weight 1.0000 sf 14.1273 reward -1.3230 ll_mean -1.5148 ll_std 0.0977 selected 0.3094 prior_p1 0.3000 avg_p1 0.3048\n",
      "Epoch 6 Iter 2300 loss=1.3740 elbo -1.5347 ll -1.4867 kl_fb 0.0481 kl 0.0481 kl_weight 1.0000 sf -3.6244 reward 0.2808 ll_mean -1.5142 ll_std 0.0980 selected 0.3373 prior_p1 0.3000 avg_p1 0.3036\n",
      "\n",
      "# epoch 6 iter 2387: dev loss -9.7284 elbo -1.6352 ll -1.5854 kl_fb 0.0498 kl 0.0498 kl_weight 1.0000 sf 11.3636 reward -1.5854 ll_mean 0.0000 ll_std 1.0000 selected 0.0002 prior_p1 0.3000 avg_p1 0.3091 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Shuffling training data\n",
      "Epoch 7 Iter 2400 loss=2.3142 elbo -1.5526 ll -1.5049 kl_fb 0.0477 kl 0.0477 kl_weight 1.0000 sf -0.9358 reward 0.0786 ll_mean -1.5126 ll_std 0.0979 selected 0.2867 prior_p1 0.3000 avg_p1 0.3089\n",
      "Epoch 7 Iter 2500 loss=2.8268 elbo -1.6237 ll -1.5850 kl_fb 0.0387 kl 0.0387 kl_weight 1.0000 sf 8.1786 reward -0.7672 ll_mean -1.5114 ll_std 0.0959 selected 0.3014 prior_p1 0.3000 avg_p1 0.3064\n",
      "Epoch 7 Iter 2600 loss=3.4818 elbo -1.4732 ll -1.4283 kl_fb 0.0449 kl 0.0449 kl_weight 1.0000 sf -9.9975 reward 0.8353 ll_mean -1.5083 ll_std 0.0958 selected 0.2979 prior_p1 0.3000 avg_p1 0.3094\n",
      "Epoch 7 Iter 2700 loss=5.2560 elbo -1.5586 ll -1.5173 kl_fb 0.0413 kl 0.0413 kl_weight 1.0000 sf 1.4570 reward -0.1365 ll_mean -1.5044 ll_std 0.0949 selected 0.2831 prior_p1 0.3000 avg_p1 0.3102\n",
      "\n",
      "# epoch 7 iter 2728: dev loss -9.6887 elbo -1.6310 ll -1.5847 kl_fb 0.0463 kl 0.0463 kl_weight 1.0000 sf 11.3197 reward -1.5847 ll_mean 0.0000 ll_std 1.0000 selected 0.0001 prior_p1 0.3000 avg_p1 0.3083 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 8 Iter 2800 loss=1.7175 elbo -1.5449 ll -1.5062 kl_fb 0.0387 kl 0.0387 kl_weight 1.0000 sf 0.3757 reward -0.0387 ll_mean -1.5026 ll_std 0.0947 selected 0.3484 prior_p1 0.3000 avg_p1 0.3077\n",
      "Epoch 8 Iter 2900 loss=2.0546 elbo -1.5232 ll -1.4669 kl_fb 0.0563 kl 0.0563 kl_weight 1.0000 sf -4.8962 reward 0.3792 ll_mean -1.5023 ll_std 0.0933 selected 0.2928 prior_p1 0.3000 avg_p1 0.3111\n",
      "Epoch 8 Iter 3000 loss=3.4463 elbo -1.3826 ll -1.3412 kl_fb 0.0414 kl 0.0414 kl_weight 1.0000 sf -20.7139 reward 1.7375 ll_mean -1.5013 ll_std 0.0922 selected 0.3350 prior_p1 0.3000 avg_p1 0.3067\n",
      "\n",
      "# epoch 8 iter 3069: dev loss -9.6167 elbo -1.6272 ll -1.5840 kl_fb 0.0432 kl 0.0432 kl_weight 1.0000 sf 11.2439 reward -1.5840 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3068 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 9 Iter 3100 loss=3.1527 elbo -1.5811 ll -1.5420 kl_fb 0.0391 kl 0.0391 kl_weight 1.0000 sf 5.2095 reward -0.4617 ll_mean -1.4991 ll_std 0.0930 selected 0.3108 prior_p1 0.3000 avg_p1 0.3062\n",
      "Epoch 9 Iter 3200 loss=4.0819 elbo -1.4584 ll -1.4267 kl_fb 0.0317 kl 0.0317 kl_weight 1.0000 sf -8.5713 reward 0.7300 ll_mean -1.4948 ll_std 0.0933 selected 0.2934 prior_p1 0.3000 avg_p1 0.3020\n",
      "Epoch 9 Iter 3300 loss=2.9228 elbo -1.5153 ll -1.4835 kl_fb 0.0317 kl 0.0317 kl_weight 1.0000 sf -0.8578 reward 0.0838 ll_mean -1.4912 ll_std 0.0912 selected 0.3013 prior_p1 0.3000 avg_p1 0.3059\n",
      "Epoch 9 Iter 3400 loss=-0.2740 elbo -1.5686 ll -1.5295 kl_fb 0.0391 kl 0.0391 kl_weight 1.0000 sf 4.5061 reward -0.4181 ll_mean -1.4911 ll_std 0.0919 selected 0.3004 prior_p1 0.3000 avg_p1 0.3090\n",
      "\n",
      "# epoch 9 iter 3410: dev loss -9.6823 elbo -1.6241 ll -1.5834 kl_fb 0.0407 kl 0.0407 kl_weight 1.0000 sf 11.3064 reward -1.5834 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3083 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 10 Iter 3500 loss=1.3099 elbo -1.5225 ll -1.4788 kl_fb 0.0437 kl 0.0437 kl_weight 1.0000 sf -1.4985 reward 0.1270 ll_mean -1.4906 ll_std 0.0923 selected 0.2979 prior_p1 0.3000 avg_p1 0.3078\n",
      "Epoch 10 Iter 3600 loss=3.0555 elbo -1.6335 ll -1.6039 kl_fb 0.0296 kl 0.0296 kl_weight 1.0000 sf 15.5814 reward -1.2445 ll_mean -1.4887 ll_std 0.0926 selected 0.2608 prior_p1 0.3000 avg_p1 0.3054\n",
      "Epoch 10 Iter 3700 loss=-0.3190 elbo -1.5476 ll -1.5027 kl_fb 0.0448 kl 0.0448 kl_weight 1.0000 sf 1.2551 reward -0.1191 ll_mean -1.4917 ll_std 0.0927 selected 0.3044 prior_p1 0.3000 avg_p1 0.3098\n",
      "\n",
      "# epoch 10 iter 3751: dev loss -9.5636 elbo -1.6209 ll -1.5827 kl_fb 0.0382 kl 0.0382 kl_weight 1.0000 sf 11.1845 reward -1.5827 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3057 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 11 Iter 3800 loss=3.4766 elbo -1.6160 ll -1.5780 kl_fb 0.0380 kl 0.0380 kl_weight 1.0000 sf 12.6624 reward -0.9650 ll_mean -1.4889 ll_std 0.0923 selected 0.3225 prior_p1 0.3000 avg_p1 0.3043\n",
      "Epoch 11 Iter 3900 loss=2.5414 elbo -1.6569 ll -1.6267 kl_fb 0.0303 kl 0.0303 kl_weight 1.0000 sf 17.6017 reward -1.5080 ll_mean -1.4870 ll_std 0.0926 selected 0.3204 prior_p1 0.3000 avg_p1 0.3037\n",
      "Epoch 11 Iter 4000 loss=0.0199 elbo -1.4757 ll -1.4344 kl_fb 0.0413 kl 0.0413 kl_weight 1.0000 sf -6.6391 reward 0.5701 ll_mean -1.4883 ll_std 0.0945 selected 0.2994 prior_p1 0.3000 avg_p1 0.3070\n",
      "\n",
      "# epoch 11 iter 4092: dev loss -9.5874 elbo -1.6186 ll -1.5821 kl_fb 0.0365 kl 0.0365 kl_weight 1.0000 sf 11.2060 reward -1.5821 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3063 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 12 Iter 4100 loss=3.4205 elbo -1.4870 ll -1.4546 kl_fb 0.0324 kl 0.0324 kl_weight 1.0000 sf -4.4090 reward 0.3427 ll_mean -1.4868 ll_std 0.0937 selected 0.3078 prior_p1 0.3000 avg_p1 0.3055\n",
      "Shuffling training data\n",
      "Epoch 12 Iter 4200 loss=0.4642 elbo -1.4486 ll -1.4069 kl_fb 0.0417 kl 0.0417 kl_weight 1.0000 sf -10.4510 reward 0.8770 ll_mean -1.4890 ll_std 0.0937 selected 0.3054 prior_p1 0.3000 avg_p1 0.3061\n",
      "Epoch 12 Iter 4300 loss=1.9632 elbo -1.6394 ll -1.6035 kl_fb 0.0359 kl 0.0359 kl_weight 1.0000 sf 16.1673 reward -1.2010 ll_mean -1.4893 ll_std 0.0951 selected 0.3100 prior_p1 0.3000 avg_p1 0.3064\n",
      "Epoch 12 Iter 4400 loss=3.1222 elbo -1.4277 ll -1.3856 kl_fb 0.0421 kl 0.0421 kl_weight 1.0000 sf -11.9288 reward 1.0781 ll_mean -1.4866 ll_std 0.0937 selected 0.2963 prior_p1 0.3000 avg_p1 0.3072\n",
      "\n",
      "# epoch 12 iter 4433: dev loss -9.5590 elbo -1.6158 ll -1.5816 kl_fb 0.0342 kl 0.0342 kl_weight 1.0000 sf 11.1748 reward -1.5816 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3057 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 13 Iter 4500 loss=2.5171 elbo -1.5333 ll -1.5062 kl_fb 0.0271 kl 0.0271 kl_weight 1.0000 sf 2.2902 reward -0.2255 ll_mean -1.4850 ll_std 0.0942 selected 0.2864 prior_p1 0.3000 avg_p1 0.3067\n",
      "Epoch 13 Iter 4600 loss=0.4718 elbo -1.5895 ll -1.5616 kl_fb 0.0279 kl 0.0279 kl_weight 1.0000 sf 8.1194 reward -0.8006 ll_mean -1.4868 ll_std 0.0935 selected 0.2898 prior_p1 0.3000 avg_p1 0.3056\n",
      "Epoch 13 Iter 4700 loss=0.8602 elbo -1.4725 ll -1.4410 kl_fb 0.0315 kl 0.0315 kl_weight 1.0000 sf -6.2439 reward 0.4774 ll_mean -1.4853 ll_std 0.0927 selected 0.3311 prior_p1 0.3000 avg_p1 0.3075\n",
      "\n",
      "# epoch 13 iter 4774: dev loss -9.5500 elbo -1.6135 ll -1.5810 kl_fb 0.0324 kl 0.0324 kl_weight 1.0000 sf 11.1635 reward -1.5810 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3056 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 14 Iter 4800 loss=2.3793 elbo -1.7975 ll -1.7656 kl_fb 0.0319 kl 0.0319 kl_weight 1.0000 sf 32.2752 reward -2.9748 ll_mean -1.4852 ll_std 0.0942 selected 0.2524 prior_p1 0.3000 avg_p1 0.3067\n",
      "Epoch 14 Iter 4900 loss=1.0513 elbo -1.5672 ll -1.5385 kl_fb 0.0286 kl 0.0286 kl_weight 1.0000 sf 6.5939 reward -0.5451 ll_mean -1.4863 ll_std 0.0958 selected 0.2670 prior_p1 0.3000 avg_p1 0.3050\n",
      "Epoch 14 Iter 5000 loss=2.5777 elbo -1.4276 ll -1.4027 kl_fb 0.0249 kl 0.0249 kl_weight 1.0000 sf -9.6682 reward 0.8558 ll_mean -1.4837 ll_std 0.0946 selected 0.3165 prior_p1 0.3000 avg_p1 0.3067\n",
      "Epoch 14 Iter 5100 loss=2.0710 elbo -1.4743 ll -1.4361 kl_fb 0.0382 kl 0.0382 kl_weight 1.0000 sf -6.5842 reward 0.5140 ll_mean -1.4845 ll_std 0.0942 selected 0.3065 prior_p1 0.3000 avg_p1 0.3067\n",
      "\n",
      "# epoch 14 iter 5115: dev loss -9.5390 elbo -1.6113 ll -1.5806 kl_fb 0.0307 kl 0.0307 kl_weight 1.0000 sf 11.1503 reward -1.5806 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3054 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 15 Iter 5200 loss=1.9645 elbo -1.4703 ll -1.4426 kl_fb 0.0277 kl 0.0277 kl_weight 1.0000 sf -5.1430 reward 0.4315 ll_mean -1.4829 ll_std 0.0935 selected 0.3086 prior_p1 0.3000 avg_p1 0.3080\n",
      "Epoch 15 Iter 5300 loss=0.5092 elbo -1.3980 ll -1.3715 kl_fb 0.0265 kl 0.0265 kl_weight 1.0000 sf -13.7990 reward 1.2032 ll_mean -1.4838 ll_std 0.0933 selected 0.3249 prior_p1 0.3000 avg_p1 0.3061\n",
      "Epoch 15 Iter 5400 loss=0.7219 elbo -1.4235 ll -1.4026 kl_fb 0.0209 kl 0.0209 kl_weight 1.0000 sf -9.6629 reward 0.8736 ll_mean -1.4850 ll_std 0.0943 selected 0.2967 prior_p1 0.3000 avg_p1 0.3017\n",
      "\n",
      "# epoch 15 iter 5456: dev loss -9.5114 elbo -1.6093 ll -1.5801 kl_fb 0.0291 kl 0.0291 kl_weight 1.0000 sf 11.1207 reward -1.5801 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3048 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 16 Iter 5500 loss=2.9893 elbo -1.4036 ll -1.3782 kl_fb 0.0254 kl 0.0254 kl_weight 1.0000 sf -12.2539 reward 1.1421 ll_mean -1.4845 ll_std 0.0931 selected 0.2762 prior_p1 0.3000 avg_p1 0.3049\n",
      "Epoch 16 Iter 5600 loss=0.9377 elbo -1.3883 ll -1.3535 kl_fb 0.0348 kl 0.0348 kl_weight 1.0000 sf -19.0018 reward 1.3828 ll_mean -1.4839 ll_std 0.0943 selected 0.3077 prior_p1 0.3000 avg_p1 0.3076\n",
      "Epoch 16 Iter 5700 loss=0.9219 elbo -1.7188 ll -1.6858 kl_fb 0.0330 kl 0.0330 kl_weight 1.0000 sf 29.2630 reward -2.1347 ll_mean -1.4832 ll_std 0.0949 selected 0.3375 prior_p1 0.3000 avg_p1 0.3073\n",
      "\n",
      "# epoch 16 iter 5797: dev loss -9.4756 elbo -1.6079 ll -1.5797 kl_fb 0.0281 kl 0.0281 kl_weight 1.0000 sf 11.0835 reward -1.5797 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3040 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 17 Iter 5800 loss=0.3579 elbo -1.5517 ll -1.5250 kl_fb 0.0266 kl 0.0266 kl_weight 1.0000 sf 4.4973 reward -0.4208 ll_mean -1.4852 ll_std 0.0946 selected 0.3008 prior_p1 0.3000 avg_p1 0.3044\n",
      "Shuffling training data\n",
      "Epoch 17 Iter 5900 loss=2.5191 elbo -1.4586 ll -1.4370 kl_fb 0.0216 kl 0.0216 kl_weight 1.0000 sf -5.4565 reward 0.5062 ll_mean -1.4839 ll_std 0.0928 selected 0.3227 prior_p1 0.3000 avg_p1 0.3035\n",
      "Epoch 17 Iter 6000 loss=1.8605 elbo -1.3858 ll -1.3549 kl_fb 0.0309 kl 0.0309 kl_weight 1.0000 sf -16.8103 reward 1.4028 ll_mean -1.4846 ll_std 0.0925 selected 0.3349 prior_p1 0.3000 avg_p1 0.3088\n",
      "Epoch 17 Iter 6100 loss=2.2041 elbo -1.4653 ll -1.4381 kl_fb 0.0271 kl 0.0271 kl_weight 1.0000 sf -5.9806 reward 0.5004 ll_mean -1.4844 ll_std 0.0926 selected 0.2837 prior_p1 0.3000 avg_p1 0.3061\n",
      "\n",
      "# epoch 17 iter 6138: dev loss -9.6059 elbo -1.6064 ll -1.5794 kl_fb 0.0270 kl 0.0270 kl_weight 1.0000 sf 11.2123 reward -1.5794 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3071 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Shuffling training data\n",
      "Epoch 18 Iter 6200 loss=-0.1611 elbo -1.5505 ll -1.5277 kl_fb 0.0228 kl 0.0228 kl_weight 1.0000 sf 5.5216 reward -0.4515 ll_mean -1.4860 ll_std 0.0925 selected 0.2900 prior_p1 0.3000 avg_p1 0.3059\n",
      "Epoch 18 Iter 6300 loss=0.9978 elbo -1.4516 ll -1.4294 kl_fb 0.0222 kl 0.0222 kl_weight 1.0000 sf -6.9578 reward 0.6162 ll_mean -1.4859 ll_std 0.0917 selected 0.3228 prior_p1 0.3000 avg_p1 0.3071\n",
      "Epoch 18 Iter 6400 loss=1.5446 elbo -1.5133 ll -1.4908 kl_fb 0.0225 kl 0.0225 kl_weight 1.0000 sf 0.5773 reward -0.0579 ll_mean -1.4856 ll_std 0.0912 selected 0.2878 prior_p1 0.3000 avg_p1 0.3083\n",
      "\n",
      "# epoch 18 iter 6479: dev loss -9.5979 elbo -1.6056 ll -1.5791 kl_fb 0.0264 kl 0.0264 kl_weight 1.0000 sf 11.2035 reward -1.5791 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3069 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 19 Iter 6500 loss=4.3253 elbo -1.3264 ll -1.3039 kl_fb 0.0225 kl 0.0225 kl_weight 1.0000 sf -22.0837 reward 1.9516 ll_mean -1.4848 ll_std 0.0927 selected 0.3365 prior_p1 0.3000 avg_p1 0.3063\n",
      "Epoch 19 Iter 6600 loss=3.3199 elbo -1.5793 ll -1.5457 kl_fb 0.0336 kl 0.0336 kl_weight 1.0000 sf 9.0833 reward -0.6813 ll_mean -1.4827 ll_std 0.0924 selected 0.3224 prior_p1 0.3000 avg_p1 0.3086\n",
      "Epoch 19 Iter 6700 loss=2.9358 elbo -1.6354 ll -1.6064 kl_fb 0.0290 kl 0.0290 kl_weight 1.0000 sf 17.5228 reward -1.3547 ll_mean -1.4815 ll_std 0.0922 selected 0.2731 prior_p1 0.3000 avg_p1 0.3063\n",
      "Epoch 19 Iter 6800 loss=0.5456 elbo -1.3800 ll -1.3581 kl_fb 0.0219 kl 0.0219 kl_weight 1.0000 sf -12.0661 reward 1.3274 ll_mean -1.4809 ll_std 0.0926 selected 0.2894 prior_p1 0.3000 avg_p1 0.3059\n",
      "\n",
      "# epoch 19 iter 6820: dev loss -9.5260 elbo -1.6047 ll -1.5790 kl_fb 0.0258 kl 0.0258 kl_weight 1.0000 sf 11.1307 reward -1.5790 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3053 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 20 Iter 6900 loss=-1.2439 elbo -1.6195 ll -1.5878 kl_fb 0.0317 kl 0.0317 kl_weight 1.0000 sf 14.5511 reward -1.1165 ll_mean -1.4831 ll_std 0.0938 selected 0.3260 prior_p1 0.3000 avg_p1 0.3058\n",
      "Epoch 20 Iter 7000 loss=1.5719 elbo -1.6715 ll -1.6476 kl_fb 0.0239 kl 0.0239 kl_weight 1.0000 sf 20.7210 reward -1.7481 ll_mean -1.4831 ll_std 0.0941 selected 0.3025 prior_p1 0.3000 avg_p1 0.3022\n",
      "Epoch 20 Iter 7100 loss=3.6300 elbo -1.4347 ll -1.4061 kl_fb 0.0286 kl 0.0286 kl_weight 1.0000 sf -9.8461 reward 0.7996 ll_mean -1.4822 ll_std 0.0952 selected 0.3081 prior_p1 0.3000 avg_p1 0.3069\n",
      "\n",
      "# epoch 20 iter 7161: dev loss -9.5781 elbo -1.6041 ll -1.5788 kl_fb 0.0253 kl 0.0253 kl_weight 1.0000 sf 11.1822 reward -1.5788 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3065 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 21 Iter 7200 loss=3.1787 elbo -1.4343 ll -1.4079 kl_fb 0.0265 kl 0.0265 kl_weight 1.0000 sf -9.2568 reward 0.7489 ll_mean -1.4793 ll_std 0.0954 selected 0.3400 prior_p1 0.3000 avg_p1 0.3070\n",
      "Epoch 21 Iter 7300 loss=0.8319 elbo -1.3205 ll -1.3010 kl_fb 0.0195 kl 0.0195 kl_weight 1.0000 sf -20.6067 reward 1.8463 ll_mean -1.4788 ll_std 0.0963 selected 0.3182 prior_p1 0.3000 avg_p1 0.3054\n",
      "Epoch 21 Iter 7400 loss=1.1823 elbo -1.4483 ll -1.4186 kl_fb 0.0297 kl 0.0297 kl_weight 1.0000 sf -7.9758 reward 0.6138 ll_mean -1.4782 ll_std 0.0970 selected 0.3179 prior_p1 0.3000 avg_p1 0.3061\n",
      "Epoch 21 Iter 7500 loss=-0.0583 elbo -1.5853 ll -1.5602 kl_fb 0.0251 kl 0.0251 kl_weight 1.0000 sf 8.8174 reward -0.8209 ll_mean -1.4808 ll_std 0.0967 selected 0.2848 prior_p1 0.3000 avg_p1 0.3068\n",
      "\n",
      "# epoch 21 iter 7502: dev loss -9.5703 elbo -1.6034 ll -1.5786 kl_fb 0.0248 kl 0.0248 kl_weight 1.0000 sf 11.1737 reward -1.5786 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3064 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 22 Iter 7600 loss=1.8788 elbo -1.4332 ll -1.4033 kl_fb 0.0298 kl 0.0298 kl_weight 1.0000 sf -10.4054 reward 0.8187 ll_mean -1.4822 ll_std 0.0963 selected 0.2901 prior_p1 0.3000 avg_p1 0.3083\n",
      "Epoch 22 Iter 7700 loss=2.1497 elbo -1.4124 ll -1.3905 kl_fb 0.0219 kl 0.0219 kl_weight 1.0000 sf -10.4727 reward 0.9562 ll_mean -1.4828 ll_std 0.0966 selected 0.3140 prior_p1 0.3000 avg_p1 0.3048\n",
      "Epoch 22 Iter 7800 loss=0.9990 elbo -1.5964 ll -1.5682 kl_fb 0.0282 kl 0.0282 kl_weight 1.0000 sf 10.8277 reward -0.8886 ll_mean -1.4823 ll_std 0.0966 selected 0.2636 prior_p1 0.3000 avg_p1 0.3054\n",
      "\n",
      "# epoch 22 iter 7843: dev loss -9.5470 elbo -1.6025 ll -1.5784 kl_fb 0.0241 kl 0.0241 kl_weight 1.0000 sf 11.1495 reward -1.5784 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3058 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 23 Iter 7900 loss=1.2293 elbo -1.5401 ll -1.5184 kl_fb 0.0217 kl 0.0217 kl_weight 1.0000 sf 4.8491 reward -0.3989 ll_mean -1.4806 ll_std 0.0948 selected 0.2630 prior_p1 0.3000 avg_p1 0.3037\n",
      "Epoch 23 Iter 8000 loss=1.3150 elbo -1.4321 ll -1.4077 kl_fb 0.0243 kl 0.0243 kl_weight 1.0000 sf -9.1987 reward 0.7740 ll_mean -1.4807 ll_std 0.0943 selected 0.2686 prior_p1 0.3000 avg_p1 0.3040\n",
      "Epoch 23 Iter 8100 loss=2.1236 elbo -1.6384 ll -1.6049 kl_fb 0.0335 kl 0.0335 kl_weight 1.0000 sf 17.0212 reward -1.3219 ll_mean -1.4811 ll_std 0.0937 selected 0.3173 prior_p1 0.3000 avg_p1 0.3071\n",
      "\n",
      "# epoch 23 iter 8184: dev loss -9.5336 elbo -1.6017 ll -1.5783 kl_fb 0.0235 kl 0.0235 kl_weight 1.0000 sf 11.1353 reward -1.5783 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3056 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 24 Iter 8200 loss=-1.0488 elbo -1.4648 ll -1.4448 kl_fb 0.0201 kl 0.0201 kl_weight 1.0000 sf -4.7080 reward 0.4266 ll_mean -1.4848 ll_std 0.0937 selected 0.3353 prior_p1 0.3000 avg_p1 0.3055\n",
      "Shuffling training data\n",
      "Epoch 24 Iter 8300 loss=1.2851 elbo -1.2721 ll -1.2480 kl_fb 0.0241 kl 0.0241 kl_weight 1.0000 sf -34.0241 reward 2.5627 ll_mean -1.4850 ll_std 0.0925 selected 0.3494 prior_p1 0.3000 avg_p1 0.3064\n",
      "Epoch 24 Iter 8400 loss=2.7959 elbo -1.5437 ll -1.5254 kl_fb 0.0183 kl 0.0183 kl_weight 1.0000 sf 5.3862 reward -0.4477 ll_mean -1.4840 ll_std 0.0924 selected 0.3265 prior_p1 0.3000 avg_p1 0.3046\n",
      "Epoch 24 Iter 8500 loss=2.4103 elbo -1.4409 ll -1.4174 kl_fb 0.0235 kl 0.0235 kl_weight 1.0000 sf -7.2732 reward 0.7093 ll_mean -1.4827 ll_std 0.0920 selected 0.2687 prior_p1 0.3000 avg_p1 0.3061\n",
      "\n",
      "# epoch 24 iter 8525: dev loss -9.5009 elbo -1.6009 ll -1.5780 kl_fb 0.0229 kl 0.0229 kl_weight 1.0000 sf 11.1018 reward -1.5780 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3048 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 25 Iter 8600 loss=-0.4335 elbo -1.5684 ll -1.5433 kl_fb 0.0251 kl 0.0251 kl_weight 1.0000 sf 7.4012 reward -0.6409 ll_mean -1.4841 ll_std 0.0924 selected 0.2898 prior_p1 0.3000 avg_p1 0.3059\n",
      "Epoch 25 Iter 8700 loss=3.8826 elbo -1.4084 ll -1.3900 kl_fb 0.0184 kl 0.0184 kl_weight 1.0000 sf -11.8919 reward 1.0021 ll_mean -1.4829 ll_std 0.0927 selected 0.2978 prior_p1 0.3000 avg_p1 0.3021\n",
      "Epoch 25 Iter 8800 loss=1.3825 elbo -1.4926 ll -1.4693 kl_fb 0.0233 kl 0.0233 kl_weight 1.0000 sf -1.7134 reward 0.1444 ll_mean -1.4827 ll_std 0.0927 selected 0.3248 prior_p1 0.3000 avg_p1 0.3044\n",
      "\n",
      "# epoch 25 iter 8866: dev loss -9.3689 elbo -1.6005 ll -1.5779 kl_fb 0.0226 kl 0.0226 kl_weight 1.0000 sf 10.9694 reward -1.5779 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3018 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 26 Iter 8900 loss=5.2547 elbo -1.6276 ll -1.6042 kl_fb 0.0234 kl 0.0234 kl_weight 1.0000 sf 17.6716 reward -1.3268 ll_mean -1.4794 ll_std 0.0941 selected 0.2938 prior_p1 0.3000 avg_p1 0.3018\n",
      "Epoch 26 Iter 9000 loss=1.0860 elbo -1.3829 ll -1.3554 kl_fb 0.0276 kl 0.0276 kl_weight 1.0000 sf -19.0654 reward 1.3061 ll_mean -1.4796 ll_std 0.0951 selected 0.3193 prior_p1 0.3000 avg_p1 0.3035\n",
      "Epoch 26 Iter 9100 loss=3.4296 elbo -1.4212 ll -1.3957 kl_fb 0.0255 kl 0.0255 kl_weight 1.0000 sf -10.2772 reward 0.8705 ll_mean -1.4789 ll_std 0.0955 selected 0.2879 prior_p1 0.3000 avg_p1 0.3069\n",
      "Epoch 26 Iter 9200 loss=1.4486 elbo -1.4085 ll -1.3861 kl_fb 0.0224 kl 0.0224 kl_weight 1.0000 sf -11.9796 reward 0.9531 ll_mean -1.4762 ll_std 0.0945 selected 0.2885 prior_p1 0.3000 avg_p1 0.3045\n",
      "\n",
      "# epoch 26 iter 9207: dev loss -9.5046 elbo -1.5997 ll -1.5777 kl_fb 0.0220 kl 0.0220 kl_weight 1.0000 sf 11.1043 reward -1.5777 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3050 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 27 Iter 9300 loss=1.9513 elbo -1.4007 ll -1.3801 kl_fb 0.0206 kl 0.0206 kl_weight 1.0000 sf -11.6499 reward 1.0051 ll_mean -1.4745 ll_std 0.0939 selected 0.2963 prior_p1 0.3000 avg_p1 0.3062\n",
      "Epoch 27 Iter 9400 loss=2.2364 elbo -1.4326 ll -1.4118 kl_fb 0.0208 kl 0.0208 kl_weight 1.0000 sf -6.7758 reward 0.6655 ll_mean -1.4743 ll_std 0.0939 selected 0.3295 prior_p1 0.3000 avg_p1 0.3051\n",
      "Epoch 27 Iter 9500 loss=1.3439 elbo -1.3746 ll -1.3465 kl_fb 0.0281 kl 0.0281 kl_weight 1.0000 sf -17.3476 reward 1.3685 ll_mean -1.4740 ll_std 0.0932 selected 0.2877 prior_p1 0.3000 avg_p1 0.3070\n",
      "\n",
      "# epoch 27 iter 9548: dev loss -9.5083 elbo -1.5991 ll -1.5775 kl_fb 0.0216 kl 0.0216 kl_weight 1.0000 sf 11.1074 reward -1.5775 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3051 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 28 Iter 9600 loss=1.3952 elbo -1.4859 ll -1.4650 kl_fb 0.0209 kl 0.0209 kl_weight 1.0000 sf -0.7417 reward 0.0729 ll_mean -1.4718 ll_std 0.0933 selected 0.2745 prior_p1 0.3000 avg_p1 0.3038\n",
      "Epoch 28 Iter 9700 loss=1.1913 elbo -1.5915 ll -1.5720 kl_fb 0.0195 kl 0.0195 kl_weight 1.0000 sf 13.2597 reward -1.0763 ll_mean -1.4724 ll_std 0.0925 selected 0.3015 prior_p1 0.3000 avg_p1 0.3025\n",
      "Epoch 28 Iter 9800 loss=-1.5712 elbo -1.6311 ll -1.6095 kl_fb 0.0216 kl 0.0216 kl_weight 1.0000 sf 14.9315 reward -1.4742 ll_mean -1.4737 ll_std 0.0921 selected 0.2810 prior_p1 0.3000 avg_p1 0.3048\n",
      "\n",
      "# epoch 28 iter 9889: dev loss -9.4955 elbo -1.5984 ll -1.5773 kl_fb 0.0211 kl 0.0211 kl_weight 1.0000 sf 11.0939 reward -1.5773 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3048 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch    28: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 29 Iter 9900 loss=0.3385 elbo -1.4352 ll -1.4185 kl_fb 0.0167 kl 0.0167 kl_weight 1.0000 sf -7.3612 reward 0.6411 ll_mean -1.4774 ll_std 0.0918 selected 0.3196 prior_p1 0.3000 avg_p1 0.3035\n",
      "Shuffling training data\n",
      "Epoch 29 Iter 10000 loss=1.4571 elbo -1.3546 ll -1.3323 kl_fb 0.0223 kl 0.0223 kl_weight 1.0000 sf -19.8681 reward 1.5956 ll_mean -1.4767 ll_std 0.0905 selected 0.2565 prior_p1 0.3000 avg_p1 0.3037\n",
      "Epoch 29 Iter 10100 loss=0.2620 elbo -1.4813 ll -1.4592 kl_fb 0.0221 kl 0.0221 kl_weight 1.0000 sf -2.6958 reward 0.2118 ll_mean -1.4785 ll_std 0.0911 selected 0.3335 prior_p1 0.3000 avg_p1 0.3034\n",
      "Epoch 29 Iter 10200 loss=3.2053 elbo -1.4270 ll -1.4040 kl_fb 0.0230 kl 0.0230 kl_weight 1.0000 sf -10.2180 reward 0.7910 ll_mean -1.4772 ll_std 0.0926 selected 0.3007 prior_p1 0.3000 avg_p1 0.3041\n",
      "\n",
      "# epoch 29 iter 10230: dev loss -9.4634 elbo -1.5981 ll -1.5772 kl_fb 0.0209 kl 0.0209 kl_weight 1.0000 sf 11.0615 reward -1.5772 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3041 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 30 Iter 10300 loss=-0.7478 elbo -1.3965 ll -1.3662 kl_fb 0.0302 kl 0.0302 kl_weight 1.0000 sf -16.1551 reward 1.2051 ll_mean -1.4801 ll_std 0.0945 selected 0.2881 prior_p1 0.3000 avg_p1 0.3056\n",
      "Epoch 30 Iter 10400 loss=2.3282 elbo -1.4640 ll -1.4447 kl_fb 0.0192 kl 0.0192 kl_weight 1.0000 sf -4.9182 reward 0.3815 ll_mean -1.4805 ll_std 0.0937 selected 0.3310 prior_p1 0.3000 avg_p1 0.3045\n",
      "Epoch 30 Iter 10500 loss=0.1839 elbo -1.5615 ll -1.5454 kl_fb 0.0161 kl 0.0161 kl_weight 1.0000 sf 7.2308 reward -0.6667 ll_mean -1.4818 ll_std 0.0953 selected 0.2950 prior_p1 0.3000 avg_p1 0.3045\n",
      "\n",
      "# epoch 30 iter 10571: dev loss -9.4761 elbo -1.5980 ll -1.5772 kl_fb 0.0208 kl 0.0208 kl_weight 1.0000 sf 11.0741 reward -1.5772 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3044 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 31 Iter 10600 loss=3.8130 elbo -1.4492 ll -1.4315 kl_fb 0.0176 kl 0.0176 kl_weight 1.0000 sf -5.9375 reward 0.5214 ll_mean -1.4810 ll_std 0.0948 selected 0.3188 prior_p1 0.3000 avg_p1 0.3037\n",
      "Shuffling training data\n",
      "Epoch 31 Iter 10700 loss=2.9739 elbo -1.4532 ll -1.4305 kl_fb 0.0226 kl 0.0226 kl_weight 1.0000 sf -6.0068 reward 0.5227 ll_mean -1.4807 ll_std 0.0959 selected 0.2503 prior_p1 0.3000 avg_p1 0.3058\n",
      "Epoch 31 Iter 10800 loss=2.0960 elbo -1.4035 ll -1.3874 kl_fb 0.0161 kl 0.0161 kl_weight 1.0000 sf -9.6149 reward 0.9484 ll_mean -1.4786 ll_std 0.0962 selected 0.3005 prior_p1 0.3000 avg_p1 0.3033\n",
      "Epoch 31 Iter 10900 loss=1.9589 elbo -1.3474 ll -1.3302 kl_fb 0.0172 kl 0.0172 kl_weight 1.0000 sf -17.1855 reward 1.5361 ll_mean -1.4774 ll_std 0.0958 selected 0.2806 prior_p1 0.3000 avg_p1 0.3041\n",
      "\n",
      "# epoch 31 iter 10912: dev loss -9.4568 elbo -1.5977 ll -1.5771 kl_fb 0.0206 kl 0.0206 kl_weight 1.0000 sf 11.0545 reward -1.5771 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3039 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 32 Iter 11000 loss=2.1977 elbo -1.5388 ll -1.5224 kl_fb 0.0165 kl 0.0165 kl_weight 1.0000 sf 5.0069 reward -0.4791 ll_mean -1.4763 ll_std 0.0962 selected 0.2849 prior_p1 0.3000 avg_p1 0.3041\n",
      "Epoch 32 Iter 11100 loss=0.6717 elbo -1.4235 ll -1.4076 kl_fb 0.0159 kl 0.0159 kl_weight 1.0000 sf -8.7434 reward 0.7226 ll_mean -1.4764 ll_std 0.0953 selected 0.3163 prior_p1 0.3000 avg_p1 0.3034\n",
      "Epoch 32 Iter 11200 loss=1.5277 elbo -1.4414 ll -1.4268 kl_fb 0.0145 kl 0.0145 kl_weight 1.0000 sf -6.0716 reward 0.5359 ll_mean -1.4777 ll_std 0.0949 selected 0.2876 prior_p1 0.3000 avg_p1 0.3024\n",
      "\n",
      "# epoch 32 iter 11253: dev loss -9.4422 elbo -1.5975 ll -1.5770 kl_fb 0.0205 kl 0.0205 kl_weight 1.0000 sf 11.0397 reward -1.5770 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3036 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 33 Iter 11300 loss=2.1882 elbo -1.4293 ll -1.4089 kl_fb 0.0205 kl 0.0205 kl_weight 1.0000 sf -7.8317 reward 0.6876 ll_mean -1.4746 ll_std 0.0956 selected 0.3036 prior_p1 0.3000 avg_p1 0.3036\n",
      "Epoch 33 Iter 11400 loss=0.1980 elbo -1.4578 ll -1.4401 kl_fb 0.0177 kl 0.0177 kl_weight 1.0000 sf -3.4224 reward 0.3656 ll_mean -1.4757 ll_std 0.0974 selected 0.2525 prior_p1 0.3000 avg_p1 0.3049\n",
      "Epoch 33 Iter 11500 loss=0.9203 elbo -1.4990 ll -1.4839 kl_fb 0.0151 kl 0.0151 kl_weight 1.0000 sf 0.9198 reward -0.0922 ll_mean -1.4750 ll_std 0.0971 selected 0.3316 prior_p1 0.3000 avg_p1 0.3038\n",
      "\n",
      "# epoch 33 iter 11594: dev loss -9.4185 elbo -1.5973 ll -1.5769 kl_fb 0.0204 kl 0.0204 kl_weight 1.0000 sf 11.0158 reward -1.5769 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3031 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Iter 11600 loss=3.1250 elbo -1.5457 ll -1.5239 kl_fb 0.0218 kl 0.0218 kl_weight 1.0000 sf 6.1993 reward -0.5044 ll_mean -1.4746 ll_std 0.0977 selected 0.2787 prior_p1 0.3000 avg_p1 0.3023\n",
      "Shuffling training data\n",
      "Epoch 34 Iter 11700 loss=0.7937 elbo -1.4852 ll -1.4699 kl_fb 0.0153 kl 0.0153 kl_weight 1.0000 sf -0.5569 reward 0.0610 ll_mean -1.4758 ll_std 0.0968 selected 0.3028 prior_p1 0.3000 avg_p1 0.3038\n",
      "Epoch 34 Iter 11800 loss=2.6164 elbo -1.4135 ll -1.3918 kl_fb 0.0217 kl 0.0217 kl_weight 1.0000 sf -10.4839 reward 0.8553 ll_mean -1.4750 ll_std 0.0973 selected 0.3248 prior_p1 0.3000 avg_p1 0.3048\n",
      "Epoch 34 Iter 11900 loss=1.8974 elbo -1.4148 ll -1.3984 kl_fb 0.0164 kl 0.0164 kl_weight 1.0000 sf -10.0787 reward 0.7838 ll_mean -1.4748 ll_std 0.0975 selected 0.3158 prior_p1 0.3000 avg_p1 0.3030\n",
      "\n",
      "# epoch 34 iter 11935: dev loss -9.4845 elbo -1.5969 ll -1.5768 kl_fb 0.0200 kl 0.0200 kl_weight 1.0000 sf 11.0813 reward -1.5768 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3046 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 35 Iter 12000 loss=1.2655 elbo -1.4360 ll -1.4166 kl_fb 0.0194 kl 0.0194 kl_weight 1.0000 sf -6.8714 reward 0.5989 ll_mean -1.4757 ll_std 0.0987 selected 0.2780 prior_p1 0.3000 avg_p1 0.3051\n",
      "Epoch 35 Iter 12100 loss=1.2885 elbo -1.5872 ll -1.5668 kl_fb 0.0205 kl 0.0205 kl_weight 1.0000 sf 10.7047 reward -0.9372 ll_mean -1.4748 ll_std 0.0981 selected 0.2561 prior_p1 0.3000 avg_p1 0.3046\n",
      "Epoch 35 Iter 12200 loss=-0.1240 elbo -1.4592 ll -1.4424 kl_fb 0.0167 kl 0.0167 kl_weight 1.0000 sf -4.0649 reward 0.3437 ll_mean -1.4761 ll_std 0.0980 selected 0.2831 prior_p1 0.3000 avg_p1 0.3044\n",
      "\n",
      "# epoch 35 iter 12276: dev loss -9.4852 elbo -1.5966 ll -1.5768 kl_fb 0.0199 kl 0.0199 kl_weight 1.0000 sf 11.0819 reward -1.5768 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3046 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 36 Iter 12300 loss=1.2863 elbo -1.3198 ll -1.2988 kl_fb 0.0211 kl 0.0211 kl_weight 1.0000 sf -19.9426 reward 1.8496 ll_mean -1.4773 ll_std 0.0965 selected 0.3251 prior_p1 0.3000 avg_p1 0.3056\n",
      "Shuffling training data\n",
      "Epoch 36 Iter 12400 loss=1.7071 elbo -1.3612 ll -1.3425 kl_fb 0.0188 kl 0.0188 kl_weight 1.0000 sf -17.0710 reward 1.3850 ll_mean -1.4765 ll_std 0.0967 selected 0.3323 prior_p1 0.3000 avg_p1 0.3022\n",
      "Epoch 36 Iter 12500 loss=0.3146 elbo -1.3782 ll -1.3613 kl_fb 0.0169 kl 0.0169 kl_weight 1.0000 sf -13.4712 reward 1.1843 ll_mean -1.4769 ll_std 0.0976 selected 0.3529 prior_p1 0.3000 avg_p1 0.3056\n",
      "Epoch 36 Iter 12600 loss=1.7958 elbo -1.4939 ll -1.4725 kl_fb 0.0214 kl 0.0214 kl_weight 1.0000 sf -0.7086 reward 0.0596 ll_mean -1.4782 ll_std 0.0959 selected 0.2852 prior_p1 0.3000 avg_p1 0.3038\n",
      "\n",
      "# epoch 36 iter 12617: dev loss -9.4674 elbo -1.5964 ll -1.5767 kl_fb 0.0197 kl 0.0197 kl_weight 1.0000 sf 11.0637 reward -1.5767 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3042 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 37 Iter 12700 loss=3.6265 elbo -1.3626 ll -1.3321 kl_fb 0.0306 kl 0.0306 kl_weight 1.0000 sf -21.8926 reward 1.4931 ll_mean -1.4760 ll_std 0.0964 selected 0.3365 prior_p1 0.3000 avg_p1 0.3070\n",
      "Epoch 37 Iter 12800 loss=0.9357 elbo -1.4778 ll -1.4604 kl_fb 0.0174 kl 0.0174 kl_weight 1.0000 sf -2.0856 reward 0.1742 ll_mean -1.4772 ll_std 0.0968 selected 0.3168 prior_p1 0.3000 avg_p1 0.3050\n",
      "Epoch 37 Iter 12900 loss=1.5846 elbo -1.5027 ll -1.4839 kl_fb 0.0188 kl 0.0188 kl_weight 1.0000 sf 0.6984 reward -0.0639 ll_mean -1.4778 ll_std 0.0961 selected 0.3187 prior_p1 0.3000 avg_p1 0.3053\n",
      "\n",
      "# epoch 37 iter 12958: dev loss -9.5062 elbo -1.5961 ll -1.5766 kl_fb 0.0195 kl 0.0195 kl_weight 1.0000 sf 11.1024 reward -1.5766 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3051 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 38 Iter 13000 loss=2.6820 elbo -1.4327 ll -1.4135 kl_fb 0.0192 kl 0.0192 kl_weight 1.0000 sf -7.6505 reward 0.6633 ll_mean -1.4769 ll_std 0.0956 selected 0.2667 prior_p1 0.3000 avg_p1 0.3061\n",
      "Epoch 38 Iter 13100 loss=4.2761 elbo -1.4744 ll -1.4568 kl_fb 0.0177 kl 0.0177 kl_weight 1.0000 sf -2.1430 reward 0.1859 ll_mean -1.4747 ll_std 0.0963 selected 0.2845 prior_p1 0.3000 avg_p1 0.3052\n",
      "Epoch 38 Iter 13200 loss=1.0731 elbo -1.6514 ll -1.6236 kl_fb 0.0278 kl 0.0278 kl_weight 1.0000 sf 22.3222 reward -1.5492 ll_mean -1.4731 ll_std 0.0971 selected 0.2752 prior_p1 0.3000 avg_p1 0.3071\n",
      "\n",
      "# epoch 38 iter 13299: dev loss -9.5252 elbo -1.5960 ll -1.5766 kl_fb 0.0194 kl 0.0194 kl_weight 1.0000 sf 11.1212 reward -1.5766 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3056 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 39 Iter 13300 loss=0.8141 elbo -1.4123 ll -1.3944 kl_fb 0.0180 kl 0.0180 kl_weight 1.0000 sf -10.2490 reward 0.8227 ll_mean -1.4733 ll_std 0.0960 selected 0.2778 prior_p1 0.3000 avg_p1 0.3042\n",
      "Shuffling training data\n",
      "Epoch 39 Iter 13400 loss=1.9937 elbo -1.3344 ll -1.3139 kl_fb 0.0204 kl 0.0204 kl_weight 1.0000 sf -21.5976 reward 1.6717 ll_mean -1.4729 ll_std 0.0951 selected 0.2916 prior_p1 0.3000 avg_p1 0.3058\n",
      "Epoch 39 Iter 13500 loss=1.0443 elbo -1.6186 ll -1.5993 kl_fb 0.0194 kl 0.0194 kl_weight 1.0000 sf 15.9775 reward -1.3712 ll_mean -1.4715 ll_std 0.0932 selected 0.2980 prior_p1 0.3000 avg_p1 0.3052\n",
      "Epoch 39 Iter 13600 loss=0.5813 elbo -1.4963 ll -1.4761 kl_fb 0.0202 kl 0.0202 kl_weight 1.0000 sf 0.4586 reward -0.0400 ll_mean -1.4723 ll_std 0.0943 selected 0.3060 prior_p1 0.3000 avg_p1 0.3062\n",
      "\n",
      "# epoch 39 iter 13640: dev loss -9.4916 elbo -1.5957 ll -1.5765 kl_fb 0.0192 kl 0.0192 kl_weight 1.0000 sf 11.0873 reward -1.5765 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3048 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch    39: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Shuffling training data\n",
      "Epoch 40 Iter 13700 loss=0.2939 elbo -1.6674 ll -1.6427 kl_fb 0.0247 kl 0.0247 kl_weight 1.0000 sf 23.3623 reward -1.7782 ll_mean -1.4746 ll_std 0.0945 selected 0.2458 prior_p1 0.3000 avg_p1 0.3049\n",
      "Epoch 40 Iter 13800 loss=2.5487 elbo -1.4686 ll -1.4477 kl_fb 0.0209 kl 0.0209 kl_weight 1.0000 sf -3.2050 reward 0.2755 ll_mean -1.4738 ll_std 0.0950 selected 0.3079 prior_p1 0.3000 avg_p1 0.3056\n",
      "Epoch 40 Iter 13900 loss=1.2344 elbo -1.4885 ll -1.4681 kl_fb 0.0204 kl 0.0204 kl_weight 1.0000 sf -0.7043 reward 0.0593 ll_mean -1.4738 ll_std 0.0952 selected 0.3202 prior_p1 0.3000 avg_p1 0.3052\n",
      "\n",
      "# epoch 40 iter 13981: dev loss -9.4885 elbo -1.5956 ll -1.5765 kl_fb 0.0191 kl 0.0191 kl_weight 1.0000 sf 11.0841 reward -1.5765 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3047 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Iter 14000 loss=1.7914 elbo -1.6721 ll -1.6501 kl_fb 0.0221 kl 0.0221 kl_weight 1.0000 sf 23.7060 reward -1.8352 ll_mean -1.4739 ll_std 0.0960 selected 0.3159 prior_p1 0.3000 avg_p1 0.3059\n",
      "Shuffling training data\n",
      "Epoch 41 Iter 14100 loss=1.8220 elbo -1.4971 ll -1.4782 kl_fb 0.0189 kl 0.0189 kl_weight 1.0000 sf 0.2823 reward -0.0239 ll_mean -1.4758 ll_std 0.0967 selected 0.3160 prior_p1 0.3000 avg_p1 0.3052\n",
      "Epoch 41 Iter 14200 loss=-0.2071 elbo -1.5152 ll -1.4959 kl_fb 0.0193 kl 0.0193 kl_weight 1.0000 sf 2.3481 reward -0.1914 ll_mean -1.4773 ll_std 0.0969 selected 0.2960 prior_p1 0.3000 avg_p1 0.3040\n",
      "Epoch 41 Iter 14300 loss=0.6880 elbo -1.5337 ll -1.5157 kl_fb 0.0180 kl 0.0180 kl_weight 1.0000 sf 4.1821 reward -0.3879 ll_mean -1.4775 ll_std 0.0986 selected 0.3099 prior_p1 0.3000 avg_p1 0.3032\n",
      "\n",
      "# epoch 41 iter 14322: dev loss -9.4749 elbo -1.5954 ll -1.5764 kl_fb 0.0190 kl 0.0190 kl_weight 1.0000 sf 11.0703 reward -1.5764 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3044 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 42 Iter 14400 loss=2.2533 elbo -1.5563 ll -1.5394 kl_fb 0.0169 kl 0.0169 kl_weight 1.0000 sf 8.4454 reward -0.6293 ll_mean -1.4774 ll_std 0.0986 selected 0.3369 prior_p1 0.3000 avg_p1 0.3031\n",
      "Epoch 42 Iter 14500 loss=2.6192 elbo -1.4947 ll -1.4759 kl_fb 0.0188 kl 0.0188 kl_weight 1.0000 sf -0.1090 reward 0.0099 ll_mean -1.4769 ll_std 0.0988 selected 0.2669 prior_p1 0.3000 avg_p1 0.3054\n",
      "Epoch 42 Iter 14600 loss=1.6772 elbo -1.3395 ll -1.3165 kl_fb 0.0230 kl 0.0230 kl_weight 1.0000 sf -21.2265 reward 1.6212 ll_mean -1.4763 ll_std 0.0986 selected 0.3124 prior_p1 0.3000 avg_p1 0.3066\n",
      "\n",
      "# epoch 42 iter 14663: dev loss -9.4705 elbo -1.5952 ll -1.5764 kl_fb 0.0188 kl 0.0188 kl_weight 1.0000 sf 11.0657 reward -1.5764 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3043 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 43 Iter 14700 loss=0.1687 elbo -1.4495 ll -1.4302 kl_fb 0.0193 kl 0.0193 kl_weight 1.0000 sf -5.7913 reward 0.4721 ll_mean -1.4768 ll_std 0.0988 selected 0.3554 prior_p1 0.3000 avg_p1 0.3038\n",
      "Shuffling training data\n",
      "Epoch 43 Iter 14800 loss=0.2325 elbo -1.5043 ll -1.4866 kl_fb 0.0177 kl 0.0177 kl_weight 1.0000 sf 0.9643 reward -0.0845 ll_mean -1.4783 ll_std 0.0982 selected 0.2843 prior_p1 0.3000 avg_p1 0.3036\n",
      "Epoch 43 Iter 14900 loss=2.3883 elbo -1.4693 ll -1.4505 kl_fb 0.0188 kl 0.0188 kl_weight 1.0000 sf -2.6570 reward 0.2720 ll_mean -1.4777 ll_std 0.1001 selected 0.2586 prior_p1 0.3000 avg_p1 0.3059\n",
      "Epoch 43 Iter 15000 loss=-0.0279 elbo -1.5665 ll -1.5501 kl_fb 0.0164 kl 0.0164 kl_weight 1.0000 sf 7.5708 reward -0.7100 ll_mean -1.4796 ll_std 0.0993 selected 0.2904 prior_p1 0.3000 avg_p1 0.3025\n",
      "\n",
      "# epoch 43 iter 15004: dev loss -9.4712 elbo -1.5951 ll -1.5764 kl_fb 0.0187 kl 0.0187 kl_weight 1.0000 sf 11.0664 reward -1.5764 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3044 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 44 Iter 15100 loss=2.2532 elbo -1.4905 ll -1.4796 kl_fb 0.0109 kl 0.0109 kl_weight 1.0000 sf -0.0057 reward 0.0006 ll_mean -1.4797 ll_std 0.0993 selected 0.2933 prior_p1 0.3000 avg_p1 0.3018\n",
      "Epoch 44 Iter 15200 loss=3.9916 elbo -1.4567 ll -1.4347 kl_fb 0.0220 kl 0.0220 kl_weight 1.0000 sf -5.6686 reward 0.4233 ll_mean -1.4764 ll_std 0.0984 selected 0.3448 prior_p1 0.3000 avg_p1 0.3062\n",
      "Epoch 44 Iter 15300 loss=1.8013 elbo -1.4269 ll -1.4098 kl_fb 0.0171 kl 0.0171 kl_weight 1.0000 sf -7.0141 reward 0.6726 ll_mean -1.4754 ll_std 0.0976 selected 0.2880 prior_p1 0.3000 avg_p1 0.3042\n",
      "\n",
      "# epoch 44 iter 15345: dev loss -9.4688 elbo -1.5949 ll -1.5764 kl_fb 0.0186 kl 0.0186 kl_weight 1.0000 sf 11.0637 reward -1.5764 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3043 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 45 Iter 15400 loss=2.1291 elbo -1.3854 ll -1.3689 kl_fb 0.0165 kl 0.0165 kl_weight 1.0000 sf -13.8133 reward 1.0987 ll_mean -1.4757 ll_std 0.0972 selected 0.3003 prior_p1 0.3000 avg_p1 0.3044\n",
      "Epoch 45 Iter 15500 loss=2.1782 elbo -1.3444 ll -1.3283 kl_fb 0.0161 kl 0.0161 kl_weight 1.0000 sf -19.3156 reward 1.5355 ll_mean -1.4762 ll_std 0.0963 selected 0.3172 prior_p1 0.3000 avg_p1 0.3026\n",
      "Epoch 45 Iter 15600 loss=0.1880 elbo -1.6508 ll -1.6329 kl_fb 0.0178 kl 0.0178 kl_weight 1.0000 sf 19.8416 reward -1.5926 ll_mean -1.4768 ll_std 0.0980 selected 0.2903 prior_p1 0.3000 avg_p1 0.3027\n",
      "\n",
      "# epoch 45 iter 15686: dev loss -9.4577 elbo -1.5949 ll -1.5763 kl_fb 0.0186 kl 0.0186 kl_weight 1.0000 sf 11.0526 reward -1.5763 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3041 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 46 Iter 15700 loss=0.9491 elbo -1.3940 ll -1.3828 kl_fb 0.0113 kl 0.0113 kl_weight 1.0000 sf -8.7827 reward 0.9426 ll_mean -1.4762 ll_std 0.0992 selected 0.2922 prior_p1 0.3000 avg_p1 0.3018\n",
      "Shuffling training data\n",
      "Epoch 46 Iter 15800 loss=3.1889 elbo -1.5407 ll -1.5201 kl_fb 0.0206 kl 0.0206 kl_weight 1.0000 sf 5.9288 reward -0.4718 ll_mean -1.4737 ll_std 0.0985 selected 0.2991 prior_p1 0.3000 avg_p1 0.3039\n",
      "Epoch 46 Iter 15900 loss=1.9344 elbo -1.3455 ll -1.3292 kl_fb 0.0163 kl 0.0163 kl_weight 1.0000 sf -13.8667 reward 1.4854 ll_mean -1.4738 ll_std 0.0974 selected 0.2629 prior_p1 0.3000 avg_p1 0.3054\n",
      "Epoch 46 Iter 16000 loss=1.6029 elbo -1.5127 ll -1.4946 kl_fb 0.0180 kl 0.0180 kl_weight 1.0000 sf 2.4830 reward -0.2324 ll_mean -1.4721 ll_std 0.0970 selected 0.3055 prior_p1 0.3000 avg_p1 0.3047\n",
      "\n",
      "# epoch 46 iter 16027: dev loss -9.4737 elbo -1.5948 ll -1.5763 kl_fb 0.0185 kl 0.0185 kl_weight 1.0000 sf 11.0686 reward -1.5763 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3044 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 47 Iter 16100 loss=-0.3068 elbo -1.4645 ll -1.4525 kl_fb 0.0120 kl 0.0120 kl_weight 1.0000 sf -1.8615 reward 0.2159 ll_mean -1.4735 ll_std 0.0972 selected 0.2834 prior_p1 0.3000 avg_p1 0.3034\n",
      "Epoch 47 Iter 16200 loss=1.8425 elbo -1.3672 ll -1.3514 kl_fb 0.0158 kl 0.0158 kl_weight 1.0000 sf -12.5176 reward 1.2641 ll_mean -1.4748 ll_std 0.0976 selected 0.3261 prior_p1 0.3000 avg_p1 0.3050\n",
      "Epoch 47 Iter 16300 loss=4.5199 elbo -1.5956 ll -1.5760 kl_fb 0.0196 kl 0.0196 kl_weight 1.0000 sf 12.9092 reward -1.0658 ll_mean -1.4720 ll_std 0.0976 selected 0.3316 prior_p1 0.3000 avg_p1 0.3049\n",
      "\n",
      "# epoch 47 iter 16368: dev loss -9.4385 elbo -1.5947 ll -1.5763 kl_fb 0.0184 kl 0.0184 kl_weight 1.0000 sf 11.0332 reward -1.5763 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3036 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Iter 16400 loss=-0.4817 elbo -1.6416 ll -1.6229 kl_fb 0.0188 kl 0.0188 kl_weight 1.0000 sf 17.7616 reward -1.5178 ll_mean -1.4737 ll_std 0.0983 selected 0.3139 prior_p1 0.3000 avg_p1 0.3048\n",
      "Shuffling training data\n",
      "Epoch 48 Iter 16500 loss=2.5153 elbo -1.5143 ll -1.4954 kl_fb 0.0189 kl 0.0189 kl_weight 1.0000 sf 2.9059 reward -0.2256 ll_mean -1.4730 ll_std 0.0993 selected 0.3016 prior_p1 0.3000 avg_p1 0.3035\n",
      "Epoch 48 Iter 16600 loss=1.8873 elbo -1.4972 ll -1.4750 kl_fb 0.0222 kl 0.0222 kl_weight 1.0000 sf 0.4284 reward -0.0357 ll_mean -1.4715 ll_std 0.0980 selected 0.3205 prior_p1 0.3000 avg_p1 0.3065\n",
      "Epoch 48 Iter 16700 loss=1.4937 elbo -1.3708 ll -1.3515 kl_fb 0.0193 kl 0.0193 kl_weight 1.0000 sf -16.1260 reward 1.2505 ll_mean -1.4705 ll_std 0.0952 selected 0.3568 prior_p1 0.3000 avg_p1 0.3039\n",
      "\n",
      "# epoch 48 iter 16709: dev loss -9.4199 elbo -1.5946 ll -1.5762 kl_fb 0.0184 kl 0.0184 kl_weight 1.0000 sf 11.0145 reward -1.5762 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3032 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 49 Iter 16800 loss=-0.3277 elbo -1.5440 ll -1.5260 kl_fb 0.0180 kl 0.0180 kl_weight 1.0000 sf 6.7192 reward -0.5618 ll_mean -1.4728 ll_std 0.0948 selected 0.2913 prior_p1 0.3000 avg_p1 0.3029\n",
      "Epoch 49 Iter 16900 loss=1.3975 elbo -1.5507 ll -1.5284 kl_fb 0.0222 kl 0.0222 kl_weight 1.0000 sf 7.4983 reward -0.5795 ll_mean -1.4732 ll_std 0.0953 selected 0.3215 prior_p1 0.3000 avg_p1 0.3047\n",
      "Epoch 49 Iter 17000 loss=2.8191 elbo -1.3476 ll -1.3264 kl_fb 0.0213 kl 0.0213 kl_weight 1.0000 sf -20.3607 reward 1.5308 ll_mean -1.4725 ll_std 0.0955 selected 0.3136 prior_p1 0.3000 avg_p1 0.3055\n",
      "\n",
      "# epoch 49 iter 17050: dev loss -9.4492 elbo -1.5945 ll -1.5762 kl_fb 0.0183 kl 0.0183 kl_weight 1.0000 sf 11.0437 reward -1.5762 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3039 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 50 Iter 17100 loss=-0.6704 elbo -1.4796 ll -1.4630 kl_fb 0.0166 kl 0.0166 kl_weight 1.0000 sf -1.0499 reward 0.1006 ll_mean -1.4725 ll_std 0.0947 selected 0.2611 prior_p1 0.3000 avg_p1 0.3017\n",
      "Shuffling training data\n",
      "Epoch 50 Iter 17200 loss=1.0337 elbo -1.6822 ll -1.6669 kl_fb 0.0153 kl 0.0153 kl_weight 1.0000 sf 26.8123 reward -2.0600 ll_mean -1.4727 ll_std 0.0943 selected 0.2886 prior_p1 0.3000 avg_p1 0.3020\n",
      "Epoch 50 Iter 17300 loss=0.7998 elbo -1.4988 ll -1.4782 kl_fb 0.0206 kl 0.0206 kl_weight 1.0000 sf 0.2363 reward -0.0195 ll_mean -1.4764 ll_std 0.0944 selected 0.3424 prior_p1 0.3000 avg_p1 0.3044\n",
      "\n",
      "# epoch 50 iter 17391: dev loss -9.4447 elbo -1.5942 ll -1.5762 kl_fb 0.0181 kl 0.0181 kl_weight 1.0000 sf 11.0389 reward -1.5762 ll_mean 0.0000 ll_std 1.0000 selected 0.0000 prior_p1 0.3000 avg_p1 0.3038 acc 0.2625\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "accuracies, losses, dev_pos_freqs = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5JFHz-qtWs6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "fD15EDngtayQ",
    "outputId": "e6f99122-f8c1-4d87-b552-f0de1fff693e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "e2yhxh_T4hS9",
    "outputId": "e67c6d37-de20-4d2d-ece8-ad37a6bff4f3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "25BWgZj44nE9",
    "outputId": "effa4090-97d1-4b2f-ee6f-d3b38452826c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pos_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w_Ko657vRGo"
   },
   "source": [
    "# Variance reduction\n",
    "\n",
    "**This is an extra**\n",
    "\n",
    "We can use a *control variate* to reduce the variance of our gradient estimates.\n",
    "\n",
    "Let's recap the idea in general terms. We are looking to solve some expectation\n",
    "\\begin{align}\n",
    "\\mu_f = \\mathbb E[f(Z)]\n",
    "\\end{align}\n",
    "but unfortunatelly, realising the full sum (or integral for continuous variables) is intractable. Thus we employ MC estimation\n",
    "\\begin{align}\n",
    "\\hat \\mu_f &\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S f(z_s) & \\text{where }z_s \\sim Q(z|x)\n",
    "\\end{align}\n",
    "Note that the variance of this estimate is\n",
    "\\begin{align}\n",
    "\\text{Var}(\\hat \\mu_f) &=  \\frac{1}{S}\\text{Var}(f(Z)) \\\\\n",
    "&= \\frac{1}{S} \\mathbb E[( f(Z) - \\mathbb E[f(Z)])^2]\n",
    "\\end{align}\n",
    "Note that this variance is such that it goes down as we sample more, in a rate $\\mathcal O(S^{-1})$.\n",
    "See that if we sample $10$ times more, we will only obtain an decrease in variance in the order of $10^{-1}$. This means that sampling more is generally not the most convenient way to decrease variance.\n",
    "\n",
    "*Digression* we can estimate the variance itself via MC, an unbiased estimate looks like\n",
    "\\begin{align}\n",
    "\\hat \\sigma^2_f = \\frac{1}{S(S-1)} \\sum_{s=1}^S (f(z_s) - \\hat \\mu_f)^2\n",
    "\\end{align}\n",
    "but not that this estimate is even hard to improve since it decreases with $\\mathcal O(S^{-2})$.\n",
    "\n",
    "Back to out main problem: let's try and improve the variance of our estimator to $\\mu_f$.\n",
    "\n",
    "It's a fact, and it can be shown trivially, that\n",
    "\\begin{align}\n",
    "\\mu_f &=  \\mathbb E[f(Z) - \\psi(Z)] + \\underbrace{\\mathbb E[\\psi(Z)]}_{\\mu_\\psi} \\\\\n",
    " &\\overset{\\text{MC}}{\\approx} \\underbrace{\\left(\\frac{1}{S} \\sum_{s=1}^S f(z_s) - \\psi(z_s) \\right) + \\mu_\\psi}_{\\hat c}\n",
    "\\end{align}\n",
    "where we assume the existence of some function $\\psi(z)$ for which the expected value $\\mu_\\psi$ is known and we estimate the expected difference $\\mathbb E[f(Z) - \\psi(Z)]$ via MC. We used this axuxiliary function, also known as a *control variate*, to derive a new estimator, which we will denote by $\\hat c$.\n",
    "\n",
    "The variance of this new estimator is show below:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}( \\hat c ) &= \\text{Var}(\\hat \\mu_{f-\\psi}) + 2\\underbrace{\\text{Cov}(\\hat \\mu_{f-\\psi}, \\mu_\\psi)}_{\\mathbb E[\\hat \\mu_{f-\\psi}  \\mu_\\psi] - \\mathbb E[\\hat \\mu_{f-\\psi}] \\mathbb E[\\mu_\\psi]} + \\underbrace{\\text{Var}(\\mu_\\psi)}_{\\color{blue}{0} } \\\\\n",
    "&= \\frac{1}{S}\\text{Var}(f- \\psi)  + 2 \\underbrace{\\left( \\mu_\\psi \\mu_{f-\\psi} - \\mu_{f-\\psi} \\mu_\\psi \\right)}_{\\color{blue}{0}} \n",
    "\\end{align}\n",
    "where the variance of $\\mu_\\psi$ is 0 because we know it in closed form (no need for MC estimation), and the covariance is $0$ as shown in the second row.\n",
    "\n",
    "That is, the variance of $\\hat c$ is essentially the variance of estimating $\\mathbb E[f(Z) - \\psi(Z)]$, which in turn depends on the variance \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(f-\\psi) &= \\text{Var}(f) - 2\\text{Cov}(f, \\psi) + \\text{Var}(\\psi)\n",
    "\\end{align}\n",
    "where we can see that if $\\text{Cov}(f, \\psi) > \\frac{\\text{Var}(\\psi)}{2}$ we achieve variance reduction as then $\\text{Var}(f-\\psi)$ would be smaller than $\\text{Var(f)}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovKcRnqH_PGp"
   },
   "source": [
    "\n",
    "## Baselines\n",
    "\n",
    "Baslines are control variates of a very simple form:\n",
    "\\begin{align}\n",
    "\\mathbb E[f(Z)] = \\mathbb E[f(Z) - C] + \\mathbb E[C]\n",
    "\\end{align}\n",
    "where $C$ is a constant with respect to $z$.\n",
    "\n",
    "In the context of the score function estimator, a baseline looks like a quantity $C(x; \\omega)$, this may be\n",
    "* just a constant;\n",
    "* or a function of the input (but not of the latent variable), which could be itself implemented as a neural network;\n",
    "* a combination of the two.\n",
    " \n",
    "\n",
    "Let's focus on the first term of the ELBO (so I'm omitting the KL term here). The gradient with respect to parameters of the inference model becomes:\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\\\\\n",
    "&=\\mathbb E_{Q(z|x, \\lambda)}\\left[\\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) - \\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] + \\underbrace{\\mathbb E_{Q(z|x, \\lambda)}\\left[\\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] }_{=0} \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\color{blue}{\\left(\\log P(x|z, \\theta) - C(x; \\omega) \\right)}\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right] \\\\\n",
    "&\n",
    "\\end{align}\n",
    "We can show that the last term is $0$\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]  \\\\&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]\\\\\n",
    "&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\right] \\\\\n",
    "&= C(x; \\omega) \\sum_z Q(z|x, \\lambda) \\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\\\\n",
    "&= C(x; \\omega) \\sum_z\\nabla_\\lambda Q(z|x, \\lambda)  \\\\\n",
    "&= C(x; \\omega) \\nabla_\\lambda \\underbrace{\\sum_z Q(z|x, \\lambda)  }_{=1}\\\\\n",
    "&=0\n",
    "\\end{align}\n",
    "\n",
    "Examples of useful baselines:\n",
    "\n",
    "* a running average of the learning signal: at some iteration $t$ we can use a running average of $\\log P(x|z, \\theta)$ using parameter estimates $\\theta$ from iterations $i < t$, this is a baseline that likely leads to high correlation between control variate and learning signal and can lead to variance reduction;\n",
    "* another technique is to have an MLP with parameters $\\omega$ predict a scalar and train this MLP to approximate the learning signal $\\log P(x|z, \\theta)$ via regression:\n",
    "\\begin{align}\n",
    "\\arg\\max_\\omega \\left( C(x; \\omega) - \\log P(x|z, \\theta) \\right)^2\n",
    "\\end{align}\n",
    "its left as an extra to implement these ideas.\n",
    "\n",
    "One more note: we can also use something called a *multiplicative baseline* in the literature of reinforcement learning, whereby we incorporate a running estimate of the standard deviation of the learning signal computed based on the values attained on previous iterations:\n",
    "\\begin{align}\n",
    "\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\frac{1}{\\hat\\sigma_{\\text{past}}}\\left(\\log P(x|z, \\theta) - \\hat \\mu_{\\text{past}}\\right)\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\n",
    "\\end{align}\n",
    "this form of contorl variate aim at promoting the learning signal (or reward in reinforcement learning literature) to be distributed by $\\mathcal N(0, 1)$. Note that multiplying the reward by a constant does not bias the estimator, and in this case, may lead to variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVsWgmlIWvZq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2VntYV3WvZt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTxG1AvPWvZv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of SST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
