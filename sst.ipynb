{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8eXUCRiWvYi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9mH-rUhWvYq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "# device = torch.device('cpu')  # CPU should be fine for this lab\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okMoxTJ9bWjc"
   },
   "source": [
    "# Sentiment Classification \n",
    "\n",
    "\n",
    "We are going to augment a sentiment classifier with a layer of discrete latent variables which will help us improve the model's interpretability. But first, let's quickly review the baseline task.\n",
    "\n",
    "\n",
    "In sentiment classification, we have some text input $x = \\langle x_1, \\ldots, x_n \\rangle$, e.g. a sentence or short paragraph, which expresses a certain sentiment $y$, i.e. one of $K$ classes, towards a subject (e.g. a film or a product). \n",
    "\n",
    "\n",
    "\n",
    "We can learn a sentiment classifier by learning a categorical distribution over classes for a given input:\n",
    "\n",
    "\\begin{align}\n",
    "Y|x &\\sim \\text{Cat}(f(x; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where the Categorical pmf is $\\text{Cat}(y|\\pi) = \\pi_y$.\n",
    "\n",
    "A categorical distribution over $K$ classes is parameterised by a $K$-dimensional probability vector, here we use a neural network $f$ to map from the input to this probability vector. Technically we say *a neural network parameterise our model*, that is, it computes the parameters of our categorical observation model. The figure below is a graphical depiction of the model: circled nodes are random variables (a shaded node is an observed variable), uncircled nodes are deterministic, a plate indicates multiple draws.\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/classifier.png\"  height=\"100\">\n",
    "\n",
    "The neural network (NN) $f(\\cdot; \\theta)$ has parameters of its own, i.e. the weights of the various architecture blocks used, which we denoted generically by $\\theta$.\n",
    "\n",
    "Suppose we have a dataset $\\mathcal D = \\{(x^{(1)}, y^{(1)}), \\ldots, (x^{(N)}, y^{(N)})\\}$ containing $N$ i.i.d. observations. Then we can use the log-likelihood function \n",
    "\\begin{align}\n",
    "\\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{N} \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\\n",
    "&= \\sum_{k=1}^{N} \\log \\text{Cat}(y^{(k)}|f(x^{(k)}; \\theta))\n",
    "\\end{align}\n",
    " to estimate $\\theta$ by maximisation:\n",
    " \\begin{align}\n",
    " \\theta^\\star = \\arg\\max_{\\theta \\in \\Theta} \\mathcal L(\\theta|\\mathcal D) ~ .\n",
    " \\end{align}\n",
    " \n",
    "\n",
    "We can use stochastic gradient-ascent to find a local optimum of $\\mathcal L(\\theta|\\mathcal D)$, which only requires a gradient estimate:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal L(\\theta|\\mathcal D) &= \\sum_{k=1}^{|\\mathcal D|} \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta) \\\\ \n",
    "&= \\sum_{k=1}^{|\\mathcal D|} \\frac{1}{N} N \\nabla_\\theta  \\log P(y^{(k)}|x^{(k)}, \\theta)  \\\\\n",
    "&= \\mathbb E_{\\mathcal U(1/N)} \\left[ N \\nabla_\\theta  \\log P(y^{(K)}|x^{(K)}, \\theta) \\right]  \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{N}{M} \\sum_{m=1}^M \\nabla_\\theta  \\log P(y^{(k_m)}|x^{(k_m)}, \\theta) \\\\\n",
    "&\\text{where }K_m \\sim \\mathcal U(1/N)\n",
    "\\end{align}\n",
    "\n",
    "This is a Monte Carlo (MC) estimate of the gradient computed on $M$ data points selected uniformly at random from $\\mathcal D$.\n",
    "\n",
    "For as long as $f$ remains differentiable wrt to its inputs and parameters, we can rely on automatic differentiation to obtain gradient estimates.\n",
    "\n",
    "In what follows we show how to design $f$ and how to extend this basic model to a latent-variable model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LUjyO-39zan"
   },
   "source": [
    "## Data\n",
    "\n",
    "We provide you some code to load the data (see `sst.sstutil.examplereader`). Play with the snippet below and inspect a few training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "4z8Bt5no9z6w",
    "outputId": "c9848b36-0b3d-49a0-d4da-db09e6c7f20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Examples\n",
      "First dev example: Example(tokens=['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['It', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'Buy', 'and', 'Accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "from sst.sstutil import examplereader, Vocabulary, load_glove\n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader('sst/data/sst/train.txt'))\n",
    "dev_data = list(examplereader('sst/data/sst/dev.txt'))\n",
    "test_data = list(examplereader('sst/data/sst/test.txt'))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Examples')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lB2lEsNuWvYx"
   },
   "source": [
    "## Architecture\n",
    "\n",
    "\n",
    "The function $f$ conditions on a high-dimensional input (i.e. text), so we need to convert it to continuous real vectors. This is the job an *encoder*. \n",
    "\n",
    "**Embedding Layer**\n",
    "\n",
    "The first step is to convert the words in $x$ to vectors, which in this lab we will do with a pre-trained embedding layer (we will use GloVe).\n",
    "\n",
    "We will denote the embedding of the $i$th word of the input by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf x_i = \\text{glove}(x_i)\n",
    "\\end{equation}\n",
    "\n",
    "**Encoder Layer**\n",
    "\n",
    "In this lab, an encoder takes a sequence of input vectors $\\mathbf x_1^n$, each $I$-dimensional, and produces a sequence of output vectors $\\mathbf t_1^n$, each $O$-dimensional and a summary vector $\\mathbf h \\in \\mathbb R^O$:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mathbf t_1^n, \\mathbf h = \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}})\n",
    "\\end{equation}\n",
    "\n",
    "where we use $\\theta_{\\text{enc}}$ to denote the subset of parameters in $\\theta$ that are specific to this encoder block. \n",
    "\n",
    "*Remark:* in practice for a correct batched implementation, our encoders also take a mask matrix and a vector of lengths.\n",
    "\n",
    "Examples of encoding functions can be a feed-forward NN (with an aggregator based on sum or average/max pooling) or a recurrent NN (e.g. an LSTM/GRU). Other architectures are also possible.\n",
    "\n",
    "**Output Layer**\n",
    "\n",
    "From our summary vector $\\mathbf h$, we need to parameterise a categorical distribution over $K$ classes, thus we use\n",
    "\n",
    "\\begin{align}\n",
    "f(x; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where $\\text{dense}_K$ is a dense layer with $K=5$ outputs and $\\theta_{\\text{output}}$ corresponds to its parameters (weight matrix and bias vector). Note that we need to use the softmax activation function in order to guarantee that the output of $f$ is a normalised probability vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kc15Nv2i41cq"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "To leave an indication of the shape of tensors in the code, we use the following convention\n",
    "\n",
    "```python\n",
    "[B, T, D]\n",
    "```\n",
    "\n",
    "where `B` stands for `batch_size`, `T` stands for `time` (or rather *maximum sequence length*), and `D` is the size of the representation.\n",
    "\n",
    "\n",
    "Consider the following abstract Encoder class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwEPXT2MWvYz",
    "tags": [
     "encoders"
    ]
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    An Encoder for us is a function that\n",
    "      1. transforms a sequence of I-dimensional vectors into a sequence of O-dimensional vectors\n",
    "      2. summarises a sequence of I-dimensional vectors into one O-dimensional vector\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        \"\"\"\n",
    "        The input is a batch-first tensor of token ids. Here is an example:\n",
    "        \n",
    "        Example of inputs (though rather than words, we have word ids):\n",
    "            INPUTS                     MASK       LENGTHS\n",
    "            [the nice cat -PAD-]    -> [1 1 1 0]  [3]\n",
    "            [the nice dog running]  -> [1 1 1 1]  [4]\n",
    "            \n",
    "        Note that:\n",
    "              mask =  inputs == 1\n",
    "              lengths = mask.sum(dim=-1)\n",
    "        \n",
    "        :param inputs: [B, T, I]\n",
    "        :param mask: [B, T]\n",
    "        :param lengths: [B]\n",
    "        :returns: [B, T, O], [B, O]\n",
    "            where the first tensor is the transformed input\n",
    "            and the second tensor is a summary of all inputs\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WA5wmkcRg9Am"
   },
   "source": [
    "Let's start easy, implement a *bag of words* encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-9hLQ0lF5SG"
   },
   "outputs": [],
   "source": [
    "class BagOfWordsEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This encoder does not transform the input sequence, \n",
    "     and its summary output is just a sum.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, inputs, mask, lengths):\n",
    "        return inputs, (inputs * mask.unsqueeze(-1).float()).sum(dim=1)  # sum along time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS7x0hLrUXfN"
   },
   "source": [
    "You can also consider implementing\n",
    "\n",
    "* a feed-forward encoder with average pooling\n",
    "* and a biLSTM encoder\n",
    "\n",
    "but these are certainly optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpOGFpK_Uo0-"
   },
   "outputs": [],
   "source": [
    "class FFEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    A typical feed-forward NN with tanh hidden activations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size,\n",
    "                 activation=None,\n",
    "                 hidden_sizes=[],\n",
    "                 aggregator='avg',\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param input_size: int\n",
    "        :param output_size: int\n",
    "        :param hidden_sizes: list of integers (dimensionality of hidden layers)\n",
    "        :param aggregator: 'sum' or 'avg'\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        if aggregator not in ['avg', 'sum']:\n",
    "            raise RuntimeError(\"aggregator param should be 'avg' or 'sum' only\")\n",
    "        self.aggregator = aggregator\n",
    "        layers = []\n",
    "        \n",
    "        def add_dropout_if_possible(idx):\n",
    "            if dropout > 0:\n",
    "                layers.append(\n",
    "                    ('dropout_{}'.format(idx), nn.Dropout(dropout))\n",
    "                )\n",
    "        \n",
    "        for idx, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.append(\n",
    "                ('linear_{}'.format(idx), nn.Linear(input_size, hidden_size))\n",
    "            )\n",
    "            layers.append(\n",
    "                ('tanh_{}'.format(idx), nn.Tanh())\n",
    "            )\n",
    "            input_size = hidden_size\n",
    "\n",
    "        add_dropout_if_possible(idx)\n",
    "        layers.append(\n",
    "            ('linear_out', nn.Linear(input_size, output_size))\n",
    "        )\n",
    "\n",
    "        self.layer = nn.Sequential(OrderedDict(layers))\n",
    "        self.activation = activation if activation else nn.Tanh()\n",
    "    \n",
    "    def compute_summary_vector(self, out, mask, lengths):\n",
    "        # summarize along time\n",
    "        sum_vec = (out * mask.unsqueeze(dim=-1).float()).sum(dim=1)\n",
    "        \n",
    "        if self.aggregator == 'sum':\n",
    "            return sum_vec\n",
    "        elif self.aggregator == 'avg':\n",
    "            return sum_vec / lengths.unsqueeze(dim=-1).float()\n",
    "        raise RuntimeError(\"Weird aggregator\")\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return: \n",
    "            outputs [B, T, O]\n",
    "            sum/avg pooling [B, O]\n",
    "        \"\"\"\n",
    "        out = self.activation(self.layer(x))\n",
    "        summary_out = self.compute_summary_vector(out, mask, lengths)\n",
    "        return out, summary_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxQ5djZ_VAvK"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMEncoder(Encoder):\n",
    "    \"\"\"\n",
    "    This module encodes a sequence using a bidirectional LSTM\n",
    "     it returns the final state\n",
    "     and the hidden states at each time step. Note: we concatenate representations\n",
    "     from the two directions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features,\n",
    "                 hidden_size: int = 200,\n",
    "                 batch_first: bool = True,\n",
    "                 bidirectional: bool = True):\n",
    "        \"\"\"\n",
    "        :param in_features:\n",
    "        :param hidden_size:\n",
    "        :param batch_first:\n",
    "        :param bidirectional:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.batch_first = batch_first\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=in_features,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=batch_first,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "    \n",
    "    def compute_summary_vec(self, hx):\n",
    "        if self.lstm.bidirectional:\n",
    "            return torch.cat([hx[-2], hx[-1]], dim=-1)\n",
    "        else:\n",
    "            return hx[-1]\n",
    "\n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Encode sentence x\n",
    "        :param x: sequence of word embeddings, shape [B, T, I]\n",
    "        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n",
    "        :param lengths: the lengths of each input sequence [B]\n",
    "        :return:\n",
    "            outputs [B, T, O]\n",
    "            final state [B, O]\n",
    "        \"\"\"\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=self.batch_first)\n",
    "        packed_out, (hx, cx) = self.lstm(packed_input)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=self.batch_first)\n",
    "        \n",
    "        summary_out = self.compute_summary_vec(hx)\n",
    "        \n",
    "        return out, summary_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_zz5zIyVkSh"
   },
   "source": [
    "Here is some helper code to select and return an encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59ZU6JddVjMV"
   },
   "outputs": [],
   "source": [
    "def get_encoder(layer, in_features, hidden_size, bidirectional=True):\n",
    "    \"\"\"Returns the requested layer.\"\"\"\n",
    "\n",
    "    if layer == \"bow\":\n",
    "        return BagOfWordsEncoder()\n",
    "    elif layer == 'ff':\n",
    "        return FFEncoder(\n",
    "            in_features, \n",
    "            2 * hidden_size,  # output_size, for convenience to be equal to lstm\n",
    "            hidden_sizes=[hidden_size], \n",
    "            aggregator='avg')\n",
    "    elif layer == \"lstm\":\n",
    "        return LSTMEncoder(\n",
    "            in_features, \n",
    "            hidden_size,\n",
    "            bidirectional=bidirectional)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(get_encoder('bow', None, None), BagOfWordsEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY8LZiMN5CHW"
   },
   "source": [
    "# Sentiment Classification with Latent Rationale\n",
    "\n",
    "A latent rationale is a compact and informative fragment of the input based on which a NN classifier makes its decisions. [Lei et al (2016)](http://aclweb.org/anthology/D16-1011) proposed to induce such rationales along with a regression model for multi-aspect sentiment analsysis, their model is trained via REINFORCE on a dataset of beer reviews.\n",
    "\n",
    "*Remark:* the model we will develop here can be seen as a probabilistic version of their model. The rest of this notebook focus on our own probabilitisc view of the model.\n",
    "\n",
    "The picture below depicts our latent-variable model for rationale extraction:\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/rationale.png\"  height=\"200\">\n",
    "\n",
    "where we augment the model with a collection of latent variables $z = \\langle z_1, \\ldots, z_n\\rangle$ where $z_i$ is a binary latent variable. Each latent variable $z_i$ regulates whether or not the input $x_i$ is available to the classifier.  We use $x \\odot z$ to denote the selected words, which, in the terminology of Lei et al, is a latent rationale.\n",
    "\n",
    "Again the classifier parameterises a Categorical distribution over $K=5$ outcomes, though this time it can encode only a selection of the input:\n",
    "\n",
    "\\begin{align}\n",
    "    Z_i & \\sim \\text{Bern}(p_1) \\\\\n",
    "    Y|z,x &\\sim \\text{Cat}(f(x \\odot z; \\theta))\n",
    "\\end{align}\n",
    "\n",
    "where we have a shared and fixed Bernoulli prior (with parameter $p_1$) for all $n$ latent variables.\n",
    "\n",
    "\n",
    "Here is an example design for $f$:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= z_i \\, \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\theta_{\\text{enc}}) \\\\\n",
    "f(x \\odot z; \\theta) &= \\text{softmax}(\\text{dense}_K(\\mathbf h; \\theta_{\\text{output}}))\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "* $z_i$ either leaves $\\mathbf x_i$ unchanged or turns it into a vector of zeros;\n",
    "* the encoder only sees features from selected inputs, i.e. $x_i$ for which $z_i = 1$;\n",
    "* $\\text{dense}_K$ is a linear layer with $K=5$ outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hDHNxLHMWvY-"
   },
   "source": [
    "## Prior\n",
    "\n",
    "\n",
    "Our prior is a Bernoulli with fixed parameter $0 < p_1 < 1$:\n",
    "\n",
    "\\begin{align}\n",
    "Z_i & \\sim \\text{Bern}(p_1)\n",
    "\\end{align}\n",
    "\n",
    "whose pmf is $\\text{Bern}(z_i|p_1) = p_1^{z_i}\\times (1-p_1)^{1-z_i}$.\n",
    "\n",
    "As we will be using Bernoulli priors and posteriors, it is a good idea to implement a Bernoulli class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCBcHnTsOuDr"
   },
   "outputs": [],
   "source": [
    "class Bernoulli(object):\n",
    "    \"\"\"\n",
    "    This class encapsulates a collection of Bernoulli distributions. \n",
    "    Each Bernoulli is uniquely specified by p_1, where\n",
    "        Bernoulli(X=x|p_1) = pow(p_1, x) * pow(1 - p_1, 1 - x)\n",
    "    is the Bernoulli probability mass function (pmf). \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, logits=None, probs=None):\n",
    "        \"\"\"\n",
    "        We can specify a Bernoulli distribution via a logit or a probability. \n",
    "         You need to specify at least one, and if you specify both, beware that\n",
    "         in this implementation logits will be used.\n",
    "         \n",
    "        Recall that: probs = sigmoid(logits).\n",
    "         \n",
    "        :param logits: a tensor of logits (a logit is defined as log (p_1/p_0))\n",
    "            where p_0 = 1 - p_1\n",
    "        :param probs: a tensor of probabilities, each in (0, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        if logits is None and probs is None:\n",
    "            raise ValueError(\"logits or probs should be specified\")\n",
    "        self.probs = torch.sigmoid(logits) if logits is not None else probs\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Returns a single sample with the same shape as the parameters\"\"\"\n",
    "        return torch.bernoulli(self.probs)\n",
    "    \n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        Assess the log probability of a sample.\n",
    "        \n",
    "        :param x: either a single sample (0 or 1) or a tensor of samples with the same shape as the parameters.\n",
    "        :returns: tensor with log probabilities with the same shape as parameters\n",
    "            (if the input is a single sample we broadcast it to the shape of the parameters)\n",
    "        \"\"\"\n",
    "        return x * torch.log(self.probs) + (1. - x) * torch.log(1. - self.probs)\n",
    "    \n",
    "    def kl(self, other: 'Bernoulli'):\n",
    "        \"\"\"\n",
    "        Compute the KL divergence between two Bernoulli distributions (from self to other).\n",
    "        \n",
    "        :return: KL[self||other] with same shape parameters\n",
    "        \"\"\"\n",
    "        p, op = self.probs, other.probs\n",
    "        q, oq = 1. - p, 1. - op\n",
    "        return p*torch.log(p/op) + q*torch.log(q/oq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0yfkCZlWvZP"
   },
   "source": [
    "## Classifier\n",
    "\n",
    "The classifier encodes only a selection of the input, which we denote $x \\odot z$, and parameterises a Categorical distribution over $5$ outcomes (sentiment levels).\n",
    "\n",
    "Thus let's implement a Categorical distribution (we will only need to be able to assess its log pmf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-6JLDnBQcdg"
   },
   "outputs": [],
   "source": [
    "class Categorical(object):\n",
    "    def __init__(self, log_probs):\n",
    "        # [B, K]: class probs\n",
    "        self.log_probs = log_probs\n",
    "\n",
    "    def log_pmf(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B] integers (targets)\n",
    "        :returns: [B, 1] scalars (log probabilities)\n",
    "        \"\"\"\n",
    "        return self.log_probs.gather(1, x.unsqueeze(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [3, 1, 5, 2, 8]\n",
    "], dtype=torch.float)\n",
    "categorical = Categorical(log_probs)\n",
    "\n",
    "assert (categorical.log_pmf(x=torch.tensor([2, 1])) == torch.tensor([[3.], [1.]], dtype=torch.float)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdrM_YRI8xBF"
   },
   "source": [
    "and a classifier architecture:\n",
    "\n",
    "* implement the forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sz7GaKbgRCd8"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Encoder takes an input text (and rationale z) and computes p(y|x,z)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:        nn.Embedding = None,\n",
    "                 hidden_size:  int = 200,\n",
    "                 output_size:  int = 1,\n",
    "                 dropout:      float = 0.1,\n",
    "                 layer:        str = \"pass\",\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        emb_size = embed.weight.shape[1]\n",
    "        enc_size = hidden_size * 2\n",
    "        # Here we embed the words\n",
    "        self.embed_layer = nn.Sequential(\n",
    "            embed,\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.enc_layer = get_encoder(layer, emb_size, hidden_size)\n",
    "\n",
    "        # and here we predict categorical parameters\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, output_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask, z) -> Categorical:\n",
    "        \"\"\"\n",
    "        :params x: [B, T] word idxs\n",
    "        :params mask: [B, T] indicates valid positions\n",
    "        :params z: [B, T] binary selectors\n",
    "        :returns: one Categorical distribution per instance in the batch\n",
    "          each conditioning only on x_i for which z_i = 1\n",
    "        \"\"\"\n",
    "        z_mask = z\n",
    "        \n",
    "        embs = self.embed_layer(x)  # [B, T, E]\n",
    "        masked_emb = embs * z_mask.unsqueeze(-1).float()\n",
    "        lengths = mask.sum(1)  # [B]\n",
    "        \n",
    "        _, enc = self.enc_layer(masked_emb, mask, lengths=lengths)  # enc: [B, E]\n",
    "        log_probs = self.output_layer(enc)  # log_probs: [B, output_size=K]\n",
    "\n",
    "        return Categorical(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2waCCBF9MaH"
   },
   "source": [
    "## Inference\n",
    "\n",
    "\n",
    "Computing the log-likelihood of an observation requires marginalising over assignments of $z$:\n",
    "\n",
    "\\begin{align}\n",
    "P(y|x,\\theta,p_1) &= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 P(z|p_1)\\times P(y|x,z, \\theta) \\\\\n",
    "&= \\sum_{z_1 = 0}^1 \\cdots \\sum_{z_n=0}^1 \\left( \\prod_{i=1}^n \\text{Bern}(z_i|p_1)\\right) \\times \\text{Cat}(y|f(x \\odot z; \\theta)) \n",
    "\\end{align}\n",
    "\n",
    "This is clearly intractable: there are $2^n$ possible assignments to $z$ and because the classifier conditions on all latent selectors, there's no way to simplify the expression.\n",
    "\n",
    "We will avoid computing this intractable marginal by instead employing an independently parameterised inference model.\n",
    "This inference model $Q(z|x, y, \\lambda)$ is an approximation to the true postrerior $P(z|x, y, \\theta, p_1)$, and we use $\\lambda$ to denote its parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jcVdYTg8Wun"
   },
   "source": [
    "We make a *mean field* assumption, whereby we model latent variables independently given the input:\n",
    "\\begin{align}\n",
    "Q(z|x, y, \\lambda) \n",
    "    &= \\prod_{i=1}^{n} Q(z_i|x; \\lambda) \\\\\n",
    "    &= \\prod_{i=1}^{n} \\text{Bern}(z_i|g_i(x; \\lambda)) \n",
    "\\end{align}\n",
    "\n",
    "where $g(x; \\lambda)$ is a NN that maps from $x = \\langle x_1, \\ldots, x_n\\rangle$ to $n$ Bernoulli parameters, each of which, is a probability value (thus $0 < g_i(x; \\lambda) < 1$).\n",
    "\n",
    "Note that though we could condition on $y$ for approximate posterior inference, we are opportunistically leaving it out. This way, $Q$ is directly available at test time for making predictions. The figure below is a graphical depiction of the inference model (we show a dashed arrow from $y$ to $z$ to remind you that in principle the label is also available).\n",
    "\n",
    "<img src=\"https://github.com/probabll/dgm4nlp/raw/master/notebooks/sst/img/inference.png\"  height=\"200\">\n",
    "\n",
    "Here is an example design for $g$:\n",
    "\\begin{align}\n",
    "\\mathbf x_i &= \\text{glove}(x_i) \\\\\n",
    "\\mathbf t_1^n, \\mathbf h &= \\text{encoder}(\\mathbf x_1^n; \\lambda_{\\text{enc}}) \\\\\n",
    "g_i(x; \\lambda) &= \\sigma(\\text{dense}_1(\\mathbf t_i; \\lambda_{\\text{output}}))\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{glove}$ is a pre-trained embedding function;\n",
    "* $\\text{dense}_1$ is a dense layer with a single output;\n",
    "* and $\\sigma(\\cdot)$ is the sigmoid function, necessary to parameterise a Bernoulli distribution.\n",
    "\n",
    "From now on we will write $Q(z|x, \\lambda)$, that is, without $y.\n",
    "\n",
    "Here we implement this product of Bernoulli distributions:\n",
    "\n",
    "* implement $g$ in the constructor \n",
    "* and the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLxfcAbuSiFo"
   },
   "outputs": [],
   "source": [
    "class ProductOfBernoullis(nn.Module):\n",
    "    \"\"\"\n",
    "    This is an inference network that parameterises independent Bernoulli distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 embed:       nn.Embedding,\n",
    "                 hidden_size: int = 200,\n",
    "                 layer:       str = \"bow\",\n",
    "                 dropout:     float = 0.1):\n",
    "        \"\"\"\n",
    "        :param embed: an embedding layer\n",
    "        :param hidden_suze: hidden size for transformed inputs\n",
    "        :param layer: 'bow' for BoW encoding\n",
    "          you may alternatively implement and 'lstm' option\n",
    "          which uses a biLSTM to transform the inputs\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 1. we should have an embedding layer\n",
    "        # 2. we may transform the representations\n",
    "        # 3. and we should compute parameters for Bernoulli distributions\n",
    "        enc_size = hidden_size * 2\n",
    "        self.emb_layer = embed\n",
    "        self.enc_layer = get_encoder(layer, embed.embedding_dim, hidden_size)\n",
    "        \n",
    "        self.outp = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(enc_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.report_params()\n",
    "\n",
    "    def report_params(self):\n",
    "        count = 0\n",
    "        for name, p in self.named_parameters():\n",
    "            if p.requires_grad and \"embed\" not in name:\n",
    "                count += np.prod(list(p.shape))\n",
    "        print(\"{} #params: {}\".format(self.__class__.__name__, count))\n",
    "\n",
    "    def forward(self, x, mask) -> Bernoulli:\n",
    "        \"\"\"\n",
    "        It takes a tensor of tokens ids (integers)\n",
    "         and predicts a Bernoulli distribution for each position.\n",
    "        \n",
    "        :param x: [B, T]\n",
    "        :param mask: [B, T]\n",
    "        :returns: Bernoulli\n",
    "        \"\"\"\n",
    "        lengths = mask.sum(1)\n",
    "        \n",
    "        embs = self.emb_layer(x)  # [B, T, E]\n",
    "        t, _ = self.enc_layer(embs, mask, lengths)  # t: [B, T, E]\n",
    "        \n",
    "        logits = self.outp(t)  # [B, T, 1]\n",
    "        logits = logits.squeeze(-1)  # [B, T]\n",
    "\n",
    "        return Bernoulli(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcCu7vkKWvZX"
   },
   "source": [
    "## Parameter Estimation\n",
    "\n",
    "In variational inference, our objective is to maximise the *evidence lowerbound* (ELBO):\n",
    "\n",
    "\\begin{align}\n",
    "\\log P(y|x) &\\ge \\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\text{KL}(Q(z|x, y, \\lambda) || P(z|p_1)) \\\\\n",
    "\\text{ELBO}&\\overset{\\text{MF}}{=}\\mathbb E_{Q(z|x, y, \\lambda)}\\left[ \\log P(y|x, z, \\theta, p_1) \\right] - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1)) \n",
    "\\end{align}\n",
    "\n",
    "where the *mean field* assumption we made implies that the KL term is simply a sum of KL divergences from a Bernoulli posterior to a Bernoulli prior.\n",
    "\n",
    "Note that the ELBO remains intractable, namely, solving the expectation in closed form still requires $2^n$ evaluations of the classifier network. Though unlike the true posterior $P(z|x,y, \\lambda)$, the approximation $Q(z|x,\\lambda)$ is tractable (it does not require an intractable normalisation) and can be used to obtain gradient estimates based on samples.\n",
    "\n",
    "### Gradient of the classifier network\n",
    "\n",
    "For the classifier, we encounter no problem:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\theta \\text{ELBO} &=\\nabla_\\theta\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\underbrace{\\nabla_\\theta \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{\\color{blue}{0}}  \\\\\n",
    "&=\\sum_{z} Q(z|x, \\lambda)\\nabla_\\theta\\log P(y|x,z,\\theta) \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\theta\\log P(y|x,z,\\theta) \\right] \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S \\nabla_\\theta \\log P(y|x, z^{(s)}, \\theta) \n",
    "\\end{align}\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$.\n",
    "\n",
    "\n",
    "### Gradient of the inference network\n",
    "\n",
    "For the inference model, we have to use the *score function estimator* (a.k.a. REINFORCE):\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\text{ELBO} &=\\nabla_\\lambda\\sum_{z} Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\nabla_\\lambda \\underbrace{\\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))}_{ \\color{blue}{\\text{tractable} }}  \\\\\n",
    "&=\\sum_{z} \\nabla_\\lambda Q(z|x, \\lambda)\\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&=\\sum_{z}  \\underbrace{Q(z|x, \\lambda) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\nabla_\\lambda Q(z|x, \\lambda)} \\log P(y|x,z,\\theta) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(y|x,z,\\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) \\right] - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))   \\\\\n",
    "&\\overset{\\text{MC}}{\\approx} \\left(\\frac{1}{S} \\sum_{s=1}^S  \\log P(y|x, z^{(s)}, \\theta) \\nabla_\\lambda \\log Q(z^{(s)}|x, \\lambda)  \\right) - \\sum_{i=1}^n \\nabla_\\lambda \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|p_1))  \n",
    "\\end{align}\n",
    "\n",
    "where $z^{(s)} \\sim Q(z|x,\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cdfkOYdC0LQ"
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Let's implement the model and the loss (negative ELBO). We work with the notion of a *surrogate loss*, that is, a computation node whose gradients wrt to parameters are equivalent to the gradients we need.\n",
    "\n",
    "For a given sample $z \\sim Q(z|x, \\lambda)$, the following is a single-sample surrogate loss:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathcal S(\\theta, \\lambda|x, y) = \\log P(y|x, z, \\theta) + \\color{red}{\\text{detach}(\\log P(y|x, z, \\theta) )}\\log Q(z|x, \\lambda) - \\sum_{i=1}^n \\text{KL}(Q(z_i|x, \\lambda) || P(z_i|\\phi))\n",
    "\\end{align}\n",
    "where we introduce an auxiliary function such that\n",
    "\\begin{align}\n",
    "\\text{detach}(f(\\alpha))  &= h(\\alpha) \\\\\n",
    "\\nabla_\\beta \\text{detach}(h(\\alpha))  &= 0 \n",
    "\\end{align}\n",
    "or in words, *detach* does not alter the forward call of its argument function $h$, but it alters $h$'s backward call by setting gradients to zero.\n",
    "\n",
    "Show that it's gradients wrt $\\theta$ and $\\lambda$ are exactly what we need:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FednEChaX6WI"
   },
   "source": [
    "\\begin{align}\n",
    "\\nabla_\\theta \\mathcal S(\\theta, \\lambda|x, y) = \\nabla_\\theta \\log P(y|x, z, \\theta) + 0\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_\\lambda \\mathcal S(\\theta, \\lambda|x, y) &= 0 + \\underbrace{\\log Q(z|x, \\lambda)\\nabla_\\lambda \\log P(y|x, z, \\theta)  + \\log P(y|x, z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)}_{\\text{chain rule}} \\\\ \n",
    "&= 0+ 0 + \\log P(y|x, z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OaUMKDShx9T0"
   },
   "source": [
    "Implement the forward pass and loss below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cnwwk-7tfR02"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    Classifier model:\n",
    "        Z_i ~ Bern(p_1) for i in 1..n\n",
    "        Y|x,z ~ Cat(f([x_i if z_i 1 else 0 for i in 1..n ]))\n",
    "    \n",
    "    Inference model:\n",
    "        Z_i|x ~ Bern(b_i) for i in 1..n\n",
    "            where b_i = g_i(x)\n",
    "    \n",
    "    Objective:\n",
    "        Single-sample MC estimate of ELBO\n",
    "    \n",
    "    Loss:\n",
    "        Surrogate loss\n",
    "\n",
    "    Consists of:\n",
    "        - a product of Bernoulli distributions inference network\n",
    "        - a classifier network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab:       object = None,\n",
    "                 vocab_size:  int = 0,\n",
    "                 emb_size:    int = 200,\n",
    "                 hidden_size: int = 200,\n",
    "                 num_classes: int = 5,\n",
    "                 prior_p1:    float = 0.3,                 \n",
    "                 det_prior: bool = True,\n",
    "                 beta_shape:  list = [0.6, 0.6],\n",
    "                 dropout:     float = 0.1,\n",
    "                 layer_cls:   str = 'bow',\n",
    "                 layer_inf:   str = 'bow',\n",
    "                 latent_variables: bool = True):\n",
    "        \"\"\"\n",
    "        :param vocab: Vocabulary\n",
    "        :param vocab_size: necessary for embedding layer\n",
    "        :param emb_size: dimensionality of embedding layer\n",
    "        :param hidden_size: dimensionality of hidden layers\n",
    "        :param num_classes: number of classes\n",
    "        :param prior_p1: (scalar) prior Bernoulli parameter\n",
    "        :param det_prior: (boolean) whether the prior parameter is deterministic\n",
    "        :param beta_shape: (pair of positive scalars) \n",
    "            when the prior parameter is stochastic\n",
    "            it is sampled from a Beta distribution (ignore this at first)\n",
    "        :param dropout: (scalar) dropout rate\n",
    "        :param layer_cls: type of encoder for classification\n",
    "        :param layer_inf: type of encoder for inference\n",
    "        :param latent_variables: whether compute and use Z as a latent variable\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.padding_idx = 1\n",
    "        self.embed = embed = nn.Embedding(vocab_size, emb_size,\n",
    "                                          padding_idx=self.padding_idx)\n",
    "\n",
    "        self.cls_net = Classifier(\n",
    "            embed=embed,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=num_classes,\n",
    "            dropout=dropout,\n",
    "            layer=layer_cls)\n",
    "        \n",
    "        self.inference_net = ProductOfBernoullis(\n",
    "            embed=embed, \n",
    "            hidden_size=hidden_size,\n",
    "            layer=layer_inf)\n",
    "        \n",
    "        self._prior_p1 = prior_p1\n",
    "        self._det_prior = det_prior\n",
    "        self._beta_shape = beta_shape\n",
    "        self._latent_variables = latent_variables\n",
    "        \n",
    "    def get_prior_p1(self, p_min=0.001, p_max=0.999):\n",
    "        \"\"\"Return the prior Bernoulli parameter\"\"\"\n",
    "        if self._det_prior:\n",
    "            return self._prior_p1\n",
    "        else:\n",
    "            a, b = self._beta_shape\n",
    "            prior_p1 = np.random.beta(a, b)\n",
    "            prior_p1 = max(prior_p1, p_min)\n",
    "            prior_p1 = min(prior_p1, p_max)\n",
    "        return prior_p1\n",
    "\n",
    "    def predict(self, py: Categorical, **kwargs):\n",
    "        \"\"\"\n",
    "        Predict deterministically using argmax.\n",
    "        :param py: B Categorical distributions (one per instance in batch)\n",
    "        :return: predictions\n",
    "            [B] sentiment levels\n",
    "        \"\"\"\n",
    "        assert not self.training, \"should be in eval mode for prediction\"\n",
    "        return py.log_probs.argmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Generate a sequence z with inference model,\n",
    "         then predict with rationale xz, that is, x masked by z.\n",
    "\n",
    "        :param x: [B, T] documents\n",
    "        :param mask: [B, T] indicates valid positions vs padded positions\n",
    "        :return:\n",
    "            Categorical distributions P(y|x, z)\n",
    "            Bernoulli distributions Q(z|x)\n",
    "            Single sample z ~ Q(z|x) used for the conditional P(y|x, z)\n",
    "        \"\"\"\n",
    "        mask = (x != self.padding_idx)\n",
    "        \n",
    "        if self._latent_variables:\n",
    "            qz = self.inference_net(x, mask)\n",
    "            z = qz.sample()\n",
    "        else:\n",
    "            qz = None\n",
    "            z = torch.ones_like(x)\n",
    "        \n",
    "#         z = torch.where(mask, z, torch.zeros_like(z))\n",
    "        py = self.cls_net(x, mask, z)  # py: Categorical\n",
    "        return py, qz, z\n",
    "\n",
    "    def get_loss(self,\n",
    "                 y,\n",
    "                 py: Categorical,\n",
    "                 qz: Bernoulli,\n",
    "                 z,\n",
    "                 mask,\n",
    "                 iter_i=0,\n",
    "                 # you may ignore the rest of the arguments for the time being\n",
    "                 #  leave them as they are\n",
    "                 kl_weight=1.0,\n",
    "                 min_kl=0.0,\n",
    "                 ll_mean=0.,\n",
    "                 ll_std=1.,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        This computes the loss for the whole model.\n",
    "\n",
    "        :param y: target labels [B]\n",
    "        :param py: conditionals P(y|x, z)\n",
    "        :param qz: approximate posteriors Q(z|x)\n",
    "        :param z: sample of binary selectors [B, T]\n",
    "        :param mask: indicates valid positions [B, T]\n",
    "        :param iter_i: indicates the iteration\n",
    "        :param kl_weight: (scalar) multiplies the KL term\n",
    "        :param min_kl: (scalar) sets a minimum for the KL (aka free bits)\n",
    "        :param ll_mean: (scalar) running average of reward\n",
    "        :param ll_std: (scalar) running standard deviation of reward\n",
    "        :return: loss (torch node), terms (dict)\n",
    "        \n",
    "            terms is an OrderedDict that holds the scalar items involved in the loss\n",
    "            e.g. `terms['ll'] = ll.item()` is the log-likelihood term\n",
    "            \n",
    "            Consider tracking the following:\n",
    "            Single-sample ELBO: terms['elbo']\n",
    "            Log-Likelihood log P(y|x,z): terms['ll']\n",
    "            KL: terms['kl']\n",
    "            Score function surrogate log P(y|z, x) log Q(z|x): terms['sf']            \n",
    "            Rate of selected words: terms['selected']\n",
    "        \"\"\"\n",
    "\n",
    "        lengths = mask.sum(1).float()\n",
    "        batch_size = mask.size(0)\n",
    "        terms = OrderedDict()\n",
    "        \n",
    "        ll = py.log_pmf(y)  # log P(y|x,z), [B, 1]\n",
    "        \n",
    "        if not self._latent_variables:\n",
    "            ll = ll.mean()\n",
    "            terms['ll'] = ll.item()\n",
    "            terms['ll_mean'] = ll_mean\n",
    "            terms['ll_std'] = ll_std\n",
    "            return -ll, terms\n",
    "        \n",
    "        # KL(q||p)\n",
    "        # [B, T]\n",
    "        prior_p1 = self.get_prior_p1()\n",
    "        pz = Bernoulli(probs=torch.full_like(qz.probs, prior_p1))\n",
    "        \n",
    "        kl = qz.kl(pz)\n",
    "        kl = torch.where(mask, kl, torch.zeros_like(kl))\n",
    "\n",
    "        # Compute the log density of the sample\n",
    "        log_q_z = qz.log_pmf(z)  # [B, T]\n",
    "        log_q_z = torch.where(mask, log_q_z, torch.zeros_like(log_q_z))\n",
    "        # We have independent Bernoullis, thus we just sum their log probabilities\n",
    "        log_q_z = log_q_z.sum(1)  # [B]\n",
    "        \n",
    "        # surrogate objective for score function estimator\n",
    "        # [B]\n",
    "        reward = (ll.detach() - torch.full_like(ll, ll_mean)) / torch.full_like(ll, ll_std)\n",
    "        sf_surrogate = (reward * log_q_z)\n",
    "\n",
    "        # Make terms in the ELBO\n",
    "        # []\n",
    "        ll = ll.mean()\n",
    "        sf_surrogate = sf_surrogate.mean()\n",
    "        # KL may require annealing and free-bits\n",
    "        # [B]\n",
    "        kl = kl.sum(dim=-1)\n",
    "        kl_fb = torch.max(torch.full_like(kl, min_kl), kl)\n",
    "        # []\n",
    "        kl = kl.mean() \n",
    "        kl_fb = kl_fb.mean() \n",
    "        kl_fb = kl_fb * kl_weight\n",
    "        \n",
    "        terms['elbo'] = (ll - kl_fb).item()\n",
    "        terms['ll'] = ll.item()\n",
    "        terms['kl_fb'] = kl_fb.item()\n",
    "        terms['kl'] = kl.item()\n",
    "        terms['kl_weight'] = kl_weight\n",
    "        terms['sf'] = sf_surrogate.item()\n",
    "        terms['reward'] = reward.mean().item()\n",
    "        terms['ll_mean'] = ll_mean\n",
    "        terms['ll_std'] = ll_std\n",
    "        terms['selected'] = (z.sum(1) / lengths).mean().item()\n",
    "        terms['prior_p1'] = prior_p1\n",
    "        terms['avg_p1'] = (torch.where(mask, qz.probs, torch.zeros_like(qz.probs)).sum() / mask.sum().float()).item()\n",
    "        # TODO log min and max p1 in batch (mask properly)\n",
    "        return - ll - sf_surrogate + kl_fb, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNQDXTpqWvZa"
   },
   "outputs": [],
   "source": [
    "# This will be used later for maintaining running averages of quantites like\n",
    "#  terms in the ELBO\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class MovingStats(object):\n",
    "    def __init__(self, memory=-1):\n",
    "        self.data = deque([])\n",
    "        self.memory = memory\n",
    "        \n",
    "    def append(self, value):\n",
    "        if self.memory != 0:\n",
    "            if self.memory > 0 and len(self.data) == self.memory:\n",
    "                self.data.popleft()\n",
    "            self.data.append(value)\n",
    "        \n",
    "    def mean(self):\n",
    "        if len(self.data):\n",
    "            return np.mean([x for x in self.data])\n",
    "        else:\n",
    "            return 0.\n",
    "    \n",
    "    def std(self):\n",
    "        return np.std(self.data) if len(self.data) > 1 else 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "081YSfU9WvZc"
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Pc80gseWvZd"
   },
   "outputs": [],
   "source": [
    "# some helper code for mini batching\n",
    "#  this will take care of annoying things such as \n",
    "#  sorting training instances by length (necessary for pytorch's LSTM, for example)\n",
    "from sst.util import make_kv_string, get_minibatch, prepare_minibatch, print_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "_WVr97kilIRV",
    "outputId": "7a9a3984-682a-4520-9f13-84f9364b4d58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Configuration\n",
      "training_path        : sst/data/sst/train.txt\n",
      "dev_path             : sst/data/sst/dev.txt\n",
      "test_path            : sst/data/sst/test.txt\n",
      "word_vectors         : sst/data/sst/glove.840B.300d.filtered.txt\n",
      "prior_p1             :        0.3\n",
      "beta_a               :        0.6\n",
      "beta_b               :        0.6\n",
      "det_prior            :          1\n",
      "num_epochs           :         50\n",
      "print_every          :        100\n",
      "eval_every           :         -1\n",
      "batch_size           :         25\n",
      "eval_batch_size      :         25\n",
      "subphrases           :          0\n",
      "min_phrase_length    :          2\n",
      "lowercase            :          1\n",
      "fix_emb              :          1\n",
      "embed_size           :        300\n",
      "hidden_size          :        150\n",
      "num_layers           :          1\n",
      "dropout              :        0.5\n",
      "layer_inf            : lstm      \n",
      "layer_cls            : lstm      \n",
      "save_path            : data/results\n",
      "baseline_memory      :       1000\n",
      "min_kl               :        0.0\n",
      "kl_weight            :        1.0\n",
      "kl_inc               :      1e-05\n",
      "lr                   :     0.0002\n",
      "weight_decay         :      1e-05\n",
      "lr_decay             :        0.5\n",
      "patience             :          5\n",
      "cooldown             :          5\n",
      "threshold            :     0.0001\n",
      "min_lr               :      1e-05\n",
      "max_grad_norm        :        5.0\n",
      "latent_variables     :          1\n",
      "Set eval_every to 341\n",
      "Loading data\n",
      "train 8544\n",
      "dev 1101\n",
      "test 2210\n",
      "\n",
      "# Example\n",
      "First dev example: Example(tokens=['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.'], label=3, transitions=[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1], token_labels=[2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2])\n",
      "First dev example tokens: ['it', \"'s\", 'a', 'lovely', 'film', 'with', 'lovely', 'performances', 'by', 'buy', 'and', 'accorsi', '.']\n",
      "First dev example label: 3\n"
     ]
    }
   ],
   "source": [
    "import torch.optim\n",
    "# We will use Adam\n",
    "from torch.optim import Adam\n",
    "# and a couple of tricks to reduce learning rate on plateau\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "# here is some helper code to evaluate your model\n",
    "from sst.evaluate import evaluate\n",
    "\n",
    "\n",
    "cfg = dict()\n",
    "\n",
    "# Data\n",
    "cfg['training_path'] = \"sst/data/sst/train.txt\"\n",
    "cfg['dev_path'] = \"sst/data/sst/dev.txt\"\n",
    "cfg['test_path'] = \"sst/data/sst/test.txt\"\n",
    "cfg['word_vectors'] = 'sst/data/sst/glove.840B.300d.filtered.txt'\n",
    "# Model\n",
    "cfg['prior_p1'] = 0.3\n",
    "cfg['beta_a'] = 0.6\n",
    "cfg['beta_b'] = 0.6\n",
    "cfg['det_prior'] = True\n",
    "# Architecture\n",
    "cfg['num_epochs'] = 50  # 50\n",
    "cfg['print_every'] = 100\n",
    "cfg['eval_every'] = -1\n",
    "cfg['batch_size'] = 25\n",
    "cfg['eval_batch_size'] = 25\n",
    "cfg['subphrases'] = False\n",
    "cfg['min_phrase_length'] = 2\n",
    "cfg['lowercase'] = True\n",
    "cfg['fix_emb'] = True\n",
    "cfg['embed_size'] = 300\n",
    "cfg['hidden_size'] = 150\n",
    "cfg['num_layers'] = 1\n",
    "cfg['dropout'] = 0.5\n",
    "cfg['layer_inf'] = 'lstm'\n",
    "cfg['layer_cls'] = 'lstm'\n",
    "cfg['save_path'] = 'data/results'\n",
    "cfg['baseline_memory'] = 1000\n",
    "cfg['min_kl'] = 0.  # use more than 0 to enable free bits\n",
    "cfg['kl_weight'] = 1.  # start from zero to enable annealing\n",
    "cfg['kl_inc'] = 0.00001\n",
    "# Optimiser (leave as is)\n",
    "cfg['lr'] = 0.0002\n",
    "cfg['weight_decay'] = 1e-5\n",
    "cfg['lr_decay'] = 0.5\n",
    "cfg['patience'] = 5\n",
    "cfg['cooldown'] = 5\n",
    "cfg['threshold'] = 1e-4\n",
    "cfg['min_lr'] = 1e-5\n",
    "cfg['max_grad_norm'] = 5.\n",
    "# special case - with latent variables\n",
    "cfg['latent_variables'] = True\n",
    "\n",
    "\n",
    "print('# Configuration')\n",
    "for k, v in cfg.items():\n",
    "    print(\"{:20} : {:10}\".format(k, v))\n",
    "\n",
    "\n",
    "iters_per_epoch = len(train_data) // cfg[\"batch_size\"]\n",
    "\n",
    "if cfg[\"eval_every\"] == -1:\n",
    "    eval_every = iters_per_epoch\n",
    "    print(\"Set eval_every to {}\".format(iters_per_epoch))\n",
    "\n",
    "\n",
    "# Let's load the data into memory.\n",
    "print(\"Loading data\")\n",
    "train_data = list(examplereader(\n",
    "    cfg['training_path'],\n",
    "    lower=cfg['lowercase'], \n",
    "    subphrases=cfg['subphrases'],\n",
    "    min_length=cfg['min_phrase_length']))\n",
    "dev_data = list(examplereader(cfg['dev_path'], lower=cfg['lowercase']))\n",
    "test_data = list(examplereader(cfg['test_path'], lower=cfg['lowercase']))\n",
    "\n",
    "print(\"train\", len(train_data))\n",
    "print(\"dev\", len(dev_data))\n",
    "print(\"test\", len(test_data))\n",
    "\n",
    "print('\\n# Example')\n",
    "example = dev_data[0]\n",
    "print(\"First dev example:\", example)\n",
    "print(\"First dev example tokens:\", example.tokens)\n",
    "print(\"First dev example label:\", example.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7cvA4K3q2QY2",
    "outputId": "15245097-3f5c-4fc4-8816-b13fb90cacef"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvoFbqez12o8"
   },
   "outputs": [],
   "source": [
    "def compute_pos_frequency(sents):\n",
    "    # decorate func made key tokens bold: dec = \"**\" if z_ == 1 else \"\"\n",
    "    def extract_tokens_z(tokens):\n",
    "        z = list(map(lambda t: int(t[:2] == '**'), tokens))\n",
    "        pure_tokens = list(map(lambda x: x[0][2:-2] if z == 1 else x[0], zip(tokens, z)))\n",
    "        return pure_tokens, z\n",
    "    \n",
    "    pos_freqs = []\n",
    "    for raw_tokens in sents:\n",
    "        pure_tokens, z = extract_tokens_z(raw_tokens)\n",
    "        tagged_tokens = nltk.pos_tag(pure_tokens)\n",
    "        POSes = list(zip(*tagged_tokens))[1]\n",
    "        pos_freqs += [pos for pos, z_ in zip(POSes, z) if z_ == 1]\n",
    "    \n",
    "    pos_freqs = Counter(pos_freqs)\n",
    "    return pos_freqs\n",
    "\n",
    "\n",
    "sents_samples = [\n",
    "    ['**Today**', '**is**', 'a', 'good', '**day**', '.'],\n",
    "    ['Yes', ',', '**it**', 'is']\n",
    "]\n",
    "assert compute_pos_frequency(sents_samples) == Counter({'NN': 2, 'FW': 1, 'VBZ': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocabulary object to map str <-> int\n",
    "vocab = Vocabulary()  # populated by load_glove\n",
    "glove_path = cfg[\"word_vectors\"]\n",
    "vectors = load_glove(glove_path, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 20727, <pad> idx: 1\n"
     ]
    }
   ],
   "source": [
    "print('Vocab size: {}, <pad> idx: {}'.format(len(vocab.w2i), vocab.w2i['<pad>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may consider using tensorboardX\n",
    "# writer = SummaryWriter(log_dir=cfg[\"save_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the sentiment labels 0-4 to a more readable form (and the opposite)\n",
    "i2t = [\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"]\n",
    "t2i = OrderedDict({p: i for p, i in zip(i2t, range(len(i2t)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Constructing model\n",
      "Classifier #params: 543905\n",
      "ProductOfBernoullis #params: 6760801\n",
      "\n",
      "# Loading embeddings\n",
      "fixed word embeddings\n"
     ]
    }
   ],
   "source": [
    "print('\\n# Constructing model')\n",
    "model = Model(\n",
    "    vocab_size=len(vocab.w2i),\n",
    "    emb_size=cfg[\"embed_size\"],\n",
    "    hidden_size=cfg[\"hidden_size\"],\n",
    "    num_classes=len(t2i),\n",
    "    prior_p1=cfg['prior_p1'],\n",
    "    det_prior=cfg['det_prior'],\n",
    "    beta_shape=[cfg['beta_a'], cfg['beta_b']],\n",
    "    vocab=vocab,\n",
    "    dropout=cfg[\"dropout\"],\n",
    "    layer_cls=cfg[\"layer_cls\"],\n",
    "    layer_inf=cfg[\"layer_inf\"],\n",
    "    latent_variables=cfg['latent_variables'])\n",
    "\n",
    "print('\\n# Loading embeddings')\n",
    "with torch.no_grad():\n",
    "    model.embed.weight.data.copy_(torch.from_numpy(vectors))\n",
    "    if cfg[\"fix_emb\"]:\n",
    "        print(\"fixed word embeddings\")\n",
    "        model.embed.weight.requires_grad = False\n",
    "    model.embed.weight[1] = 0.  # padding zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congigure optimiser\n",
    "optimizer = Adam(model.parameters(), lr=cfg[\"lr\"],\n",
    "                 weight_decay=cfg[\"weight_decay\"])\n",
    "# and learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=cfg[\"lr_decay\"], patience=cfg[\"patience\"],\n",
    "    verbose=True, cooldown=cfg[\"cooldown\"], threshold=cfg[\"threshold\"],\n",
    "    min_lr=cfg[\"min_lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embed): Embedding(20727, 300, padding_idx=1)\n",
      "  (cls_net): Classifier(\n",
      "    (embed_layer): Sequential(\n",
      "      (0): Embedding(20727, 300, padding_idx=1)\n",
      "      (1): Dropout(p=0.5)\n",
      "    )\n",
      "    (enc_layer): LSTMEncoder(\n",
      "      (lstm): LSTM(300, 150, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (output_layer): Sequential(\n",
      "      (0): Dropout(p=0.5)\n",
      "      (1): Linear(in_features=300, out_features=5, bias=True)\n",
      "      (2): LogSoftmax()\n",
      "    )\n",
      "  )\n",
      "  (inference_net): ProductOfBernoullis(\n",
      "    (emb_layer): Embedding(20727, 300, padding_idx=1)\n",
      "    (enc_layer): LSTMEncoder(\n",
      "      (lstm): LSTM(300, 150, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (outp): Sequential(\n",
      "      (0): Dropout(p=0.1)\n",
      "      (1): Linear(in_features=300, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "embed.weight             [20727, 300] requires_grad=False\n",
      "cls_net.enc_layer.lstm.weight_ih_l0 [600, 300]   requires_grad=True\n",
      "cls_net.enc_layer.lstm.weight_hh_l0 [600, 150]   requires_grad=True\n",
      "cls_net.enc_layer.lstm.bias_ih_l0 [600]        requires_grad=True\n",
      "cls_net.enc_layer.lstm.bias_hh_l0 [600]        requires_grad=True\n",
      "cls_net.enc_layer.lstm.weight_ih_l0_reverse [600, 300]   requires_grad=True\n",
      "cls_net.enc_layer.lstm.weight_hh_l0_reverse [600, 150]   requires_grad=True\n",
      "cls_net.enc_layer.lstm.bias_ih_l0_reverse [600]        requires_grad=True\n",
      "cls_net.enc_layer.lstm.bias_hh_l0_reverse [600]        requires_grad=True\n",
      "cls_net.output_layer.1.weight [5, 300]     requires_grad=True\n",
      "cls_net.output_layer.1.bias [5]          requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_ih_l0 [600, 300]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_hh_l0 [600, 150]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_ih_l0 [600]        requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_hh_l0 [600]        requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_ih_l0_reverse [600, 300]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.weight_hh_l0_reverse [600, 150]   requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_ih_l0_reverse [600]        requires_grad=True\n",
      "inference_net.enc_layer.lstm.bias_hh_l0_reverse [600]        requires_grad=True\n",
      "inference_net.outp.1.weight [1, 300]     requires_grad=True\n",
      "inference_net.outp.1.bias [1]          requires_grad=True\n",
      "\n",
      "Total parameters: 7304706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare a few auxiliary variables\n",
    "iter_i = 0\n",
    "train_loss = 0.\n",
    "print_num = 0\n",
    "losses = []\n",
    "accuracies, valid_losses = [], []\n",
    "best_eval = 1.0e9\n",
    "best_iter = 0\n",
    "dev_pos_freqs = None\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Some debugging info\n",
    "print(model)\n",
    "print_parameters(model)\n",
    "\n",
    "batch_size = cfg['batch_size']\n",
    "eval_batch_size = cfg['eval_batch_size']\n",
    "print_every = cfg['print_every']\n",
    "\n",
    "# Parameters of tricks to better optimise the ELBO\n",
    "kl_inc = cfg['kl_inc']\n",
    "kl_weight = cfg['kl_weight']\n",
    "min_kl = cfg['min_kl']\n",
    "# Running estimates for baselines\n",
    "ll_moving_stats = MovingStats(cfg['baseline_memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PMqtVj0WvZf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 0 Iter 100 loss=7.5995 elbo -1.6909 ll -1.6334 kl_fb 0.0575 kl 0.0575 kl_weight 1.0000 sf 23.8304 reward -1.8804 ll_mean -1.5855 ll_std 0.0255 selected 0.9904 prior_p1 0.3000 avg_p1 0.2959\n",
      "Epoch 0 Iter 200 loss=5.6908 elbo -1.5786 ll -1.5362 kl_fb 0.0424 kl 0.0424 kl_weight 1.0000 sf -10.7604 reward 0.8330 ll_mean -1.5778 ll_std 0.0500 selected 0.9696 prior_p1 0.3000 avg_p1 0.3085\n",
      "Epoch 0 Iter 300 loss=3.4805 elbo -1.5902 ll -1.5646 kl_fb 0.0256 kl 0.0256 kl_weight 1.0000 sf -2.1717 reward 0.1912 ll_mean -1.5744 ll_std 0.0513 selected 0.9599 prior_p1 0.3000 avg_p1 0.3060\n",
      "\n",
      "# epoch 0 iter 341: dev loss -16.7412 elbo -1.5852 ll -1.5621 kl_fb 0.0230 kl 0.0230 kl_weight 1.0000 sf 18.3264 reward -1.5621 ll_mean 0.0000 ll_std 1.0000 selected 1.0885 prior_p1 0.3000 avg_p1 0.3012 acc 0.2670\n",
      " dev0 [gold=3,pred=3]: it 's **a** lovely film with **lovely** **performances** by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which is probably for the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not **nearly** moved to tears by a **couple** **of** **scenes** **,** you 've **got** **ice** water in your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 1 Iter 400 loss=4.1786 elbo -1.5526 ll -1.5283 kl_fb 0.0243 kl 0.0243 kl_weight 1.0000 sf -10.2632 reward 0.7831 ll_mean -1.5712 ll_std 0.0548 selected 1.3143 prior_p1 0.3000 avg_p1 0.3110\n",
      "Epoch 1 Iter 500 loss=7.6743 elbo -1.6709 ll -1.6507 kl_fb 0.0202 kl 0.0202 kl_weight 1.0000 sf 17.9240 reward -1.4940 ll_mean -1.5644 ll_std 0.0577 selected 1.0283 prior_p1 0.3000 avg_p1 0.2935\n",
      "Epoch 1 Iter 600 loss=11.0943 elbo -1.4489 ll -1.4323 kl_fb 0.0166 kl 0.0166 kl_weight 1.0000 sf -22.2578 reward 1.9576 ll_mean -1.5558 ll_std 0.0631 selected 1.1056 prior_p1 0.3000 avg_p1 0.3076\n",
      "\n",
      "# epoch 1 iter 682: dev loss -16.0997 elbo -1.5053 ll -1.4930 kl_fb 0.0123 kl 0.0123 kl_weight 1.0000 sf 17.6050 reward -1.4930 ll_mean 0.0000 ll_std 1.0000 selected 1.1048 prior_p1 0.3000 avg_p1 0.3027 acc 0.3433\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** **film** with lovely performances by buy **and** accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which **is** probably **for** the **best** .\n",
      " dev2 [gold=3,pred=1]: and if **you** 're not nearly **moved** to tears **by** **a** **couple** **of** **scenes** , you **'ve** got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 2 Iter 700 loss=9.9640 elbo -1.4664 ll -1.4535 kl_fb 0.0129 kl 0.0129 kl_weight 1.0000 sf -17.8919 reward 1.4187 ll_mean -1.5487 ll_std 0.0671 selected 0.8620 prior_p1 0.3000 avg_p1 0.3005\n",
      "Epoch 2 Iter 800 loss=7.1028 elbo -1.5551 ll -1.5460 kl_fb 0.0091 kl 0.0091 kl_weight 1.0000 sf 0.2616 reward -0.0253 ll_mean -1.5442 ll_std 0.0688 selected 1.4024 prior_p1 0.3000 avg_p1 0.2991\n",
      "Epoch 2 Iter 900 loss=8.8751 elbo -1.4599 ll -1.4504 kl_fb 0.0095 kl 0.0095 kl_weight 1.0000 sf -13.8408 reward 1.2492 ll_mean -1.5391 ll_std 0.0710 selected 1.4012 prior_p1 0.3000 avg_p1 0.3034\n",
      "Epoch 2 Iter 1000 loss=10.2230 elbo -1.4289 ll -1.4126 kl_fb 0.0163 kl 0.0163 kl_weight 1.0000 sf -18.8127 reward 1.6049 ll_mean -1.5335 ll_std 0.0753 selected 1.6189 prior_p1 0.3000 avg_p1 0.3125\n",
      "\n",
      "# epoch 2 iter 1023: dev loss -15.9627 elbo -1.4794 ll -1.4679 kl_fb 0.0115 kl 0.0115 kl_weight 1.0000 sf 17.4421 reward -1.4679 ll_mean 0.0000 ll_std 1.0000 selected 1.1101 prior_p1 0.3000 avg_p1 0.3060 acc 0.3470\n",
      " dev0 [gold=3,pred=1]: **it** **'s** **a** lovely film with lovely performances **by** **buy** and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted here , which is probably for **the** best .\n",
      " dev2 [gold=3,pred=1]: and if **you** 're not **nearly** moved to tears **by** **a** couple **of** scenes , you 've **got** ice **water** in **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 3 Iter 1100 loss=8.9474 elbo -1.6222 ll -1.6030 kl_fb 0.0192 kl 0.0192 kl_weight 1.0000 sf 11.5457 reward -1.0177 ll_mean -1.5225 ll_std 0.0792 selected 1.5155 prior_p1 0.3000 avg_p1 0.3163\n",
      "Epoch 3 Iter 1200 loss=4.8084 elbo -1.4715 ll -1.4598 kl_fb 0.0117 kl 0.0117 kl_weight 1.0000 sf -8.9784 reward 0.6987 ll_mean -1.5154 ll_std 0.0796 selected 0.9749 prior_p1 0.3000 avg_p1 0.3104\n",
      "Epoch 3 Iter 1300 loss=5.1627 elbo -1.4850 ll -1.4780 kl_fb 0.0070 kl 0.0070 kl_weight 1.0000 sf -3.3355 reward 0.3623 ll_mean -1.5072 ll_std 0.0807 selected 1.1024 prior_p1 0.3000 avg_p1 0.3049\n",
      "\n",
      "# epoch 3 iter 1364: dev loss -15.5931 elbo -1.4983 ll -1.4818 kl_fb 0.0165 kl 0.0165 kl_weight 1.0000 sf 17.0914 reward -1.4818 ll_mean 0.0000 ll_std 1.0000 selected 1.0642 prior_p1 0.3000 avg_p1 0.2864 acc 0.3233\n",
      " dev0 [gold=3,pred=3]: it 's a **lovely** film with lovely performances **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , **which** **is** probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're **not** nearly **moved** to tears by **a** couple of scenes , you **'ve** got ice **water** in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 4 Iter 1400 loss=3.9228 elbo -1.4237 ll -1.4136 kl_fb 0.0101 kl 0.0101 kl_weight 1.0000 sf -12.6750 reward 1.0572 ll_mean -1.4997 ll_std 0.0815 selected 1.1836 prior_p1 0.3000 avg_p1 0.3065\n",
      "Epoch 4 Iter 1500 loss=2.4949 elbo -1.5623 ll -1.5523 kl_fb 0.0101 kl 0.0101 kl_weight 1.0000 sf 7.5205 reward -0.7049 ll_mean -1.4949 ll_std 0.0814 selected 1.0252 prior_p1 0.3000 avg_p1 0.3022\n",
      "Epoch 4 Iter 1600 loss=5.3938 elbo -1.5327 ll -1.5163 kl_fb 0.0164 kl 0.0164 kl_weight 1.0000 sf 3.8361 reward -0.3133 ll_mean -1.4901 ll_std 0.0835 selected 1.3362 prior_p1 0.3000 avg_p1 0.2940\n",
      "Epoch 4 Iter 1700 loss=2.4915 elbo -1.4169 ll -1.4046 kl_fb 0.0122 kl 0.0122 kl_weight 1.0000 sf -13.4350 reward 0.9864 ll_mean -1.4879 ll_std 0.0845 selected 1.2024 prior_p1 0.3000 avg_p1 0.3079\n",
      "\n",
      "# epoch 4 iter 1705: dev loss -15.6752 elbo -1.4668 ll -1.4608 kl_fb 0.0060 kl 0.0060 kl_weight 1.0000 sf 17.1420 reward -1.4608 ll_mean 0.0000 ll_std 1.0000 selected 1.0802 prior_p1 0.3000 avg_p1 0.3002 acc 0.3397\n",
      " dev0 [gold=3,pred=1]: it 's **a** lovely film **with** lovely **performances** **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , which is probably **for** **the** **best** .\n",
      " dev2 [gold=3,pred=3]: **and** **if** **you** 're not nearly moved to **tears** by a couple of scenes **,** **you** **'ve** got ice **water** in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 5 Iter 1800 loss=4.5893 elbo -1.8437 ll -1.8203 kl_fb 0.0233 kl 0.0233 kl_weight 1.0000 sf 44.8776 reward -3.8476 ll_mean -1.4826 ll_std 0.0878 selected 1.6198 prior_p1 0.3000 avg_p1 0.3179\n",
      "Epoch 5 Iter 1900 loss=2.9123 elbo -1.5400 ll -1.5317 kl_fb 0.0083 kl 0.0083 kl_weight 1.0000 sf 5.6318 reward -0.5750 ll_mean -1.4802 ll_std 0.0896 selected 0.9389 prior_p1 0.3000 avg_p1 0.3044\n",
      "Epoch 5 Iter 2000 loss=2.7174 elbo -1.5840 ll -1.5725 kl_fb 0.0114 kl 0.0114 kl_weight 1.0000 sf 12.0142 reward -1.0477 ll_mean -1.4789 ll_std 0.0894 selected 1.0903 prior_p1 0.3000 avg_p1 0.3108\n",
      "\n",
      "# epoch 5 iter 2046: dev loss -16.0618 elbo -1.4673 ll -1.4496 kl_fb 0.0177 kl 0.0177 kl_weight 1.0000 sf 17.5291 reward -1.4496 ll_mean 0.0000 ll_std 1.0000 selected 1.0950 prior_p1 0.3000 avg_p1 0.3170 acc 0.3579\n",
      " dev0 [gold=3,pred=1]: it **'s** a **lovely** **film** with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here , **which** is probably for the **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears **by** a **couple** **of** scenes **,** you 've **got** ice water **in** **your** **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 6 Iter 2100 loss=3.6302 elbo -1.4478 ll -1.4392 kl_fb 0.0086 kl 0.0086 kl_weight 1.0000 sf -5.3416 reward 0.4351 ll_mean -1.4778 ll_std 0.0887 selected 1.4969 prior_p1 0.3000 avg_p1 0.3026\n",
      "Epoch 6 Iter 2200 loss=4.5248 elbo -1.1911 ll -1.1837 kl_fb 0.0074 kl 0.0074 kl_weight 1.0000 sf -41.4306 reward 3.2365 ll_mean -1.4735 ll_std 0.0895 selected 1.1317 prior_p1 0.3000 avg_p1 0.3055\n",
      "Epoch 6 Iter 2300 loss=2.2913 elbo -1.3812 ll -1.3693 kl_fb 0.0119 kl 0.0119 kl_weight 1.0000 sf -14.8064 reward 1.1348 ll_mean -1.4713 ll_std 0.0899 selected 1.2797 prior_p1 0.3000 avg_p1 0.3045\n",
      "\n",
      "# epoch 6 iter 2387: dev loss -15.7020 elbo -1.4488 ll -1.4328 kl_fb 0.0160 kl 0.0160 kl_weight 1.0000 sf 17.1508 reward -1.4328 ll_mean 0.0000 ll_std 1.0000 selected 1.0934 prior_p1 0.3000 avg_p1 0.3150 acc 0.3497\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a **lovely** film with lovely **performances** **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted **here** , which is probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly moved **to** **tears** by a couple of scenes , you 've got **ice** **water** in **your** veins **.**\n",
      "\n",
      "Epoch     6: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 7 Iter 2400 loss=2.6551 elbo -1.4988 ll -1.4847 kl_fb 0.0141 kl 0.0141 kl_weight 1.0000 sf 1.9872 reward -0.1731 ll_mean -1.4690 ll_std 0.0909 selected 1.6900 prior_p1 0.3000 avg_p1 0.3135\n",
      "Epoch 7 Iter 2500 loss=2.7253 elbo -1.4536 ll -1.4451 kl_fb 0.0085 kl 0.0085 kl_weight 1.0000 sf -2.6318 reward 0.2193 ll_mean -1.4658 ll_std 0.0942 selected 1.2570 prior_p1 0.3000 avg_p1 0.3021\n",
      "Epoch 7 Iter 2600 loss=2.0021 elbo -1.3982 ll -1.3891 kl_fb 0.0091 kl 0.0091 kl_weight 1.0000 sf -10.8689 reward 0.8112 ll_mean -1.4656 ll_std 0.0943 selected 0.8547 prior_p1 0.3000 avg_p1 0.3079\n",
      "Epoch 7 Iter 2700 loss=3.1731 elbo -1.5826 ll -1.5767 kl_fb 0.0059 kl 0.0059 kl_weight 1.0000 sf 13.3835 reward -1.2050 ll_mean -1.4620 ll_std 0.0952 selected 1.0047 prior_p1 0.3000 avg_p1 0.2980\n",
      "\n",
      "# epoch 7 iter 2728: dev loss -15.5872 elbo -1.4550 ll -1.4492 kl_fb 0.0059 kl 0.0059 kl_weight 1.0000 sf 17.0422 reward -1.4492 ll_mean 0.0000 ll_std 1.0000 selected 1.0816 prior_p1 0.3000 avg_p1 0.3045 acc 0.3597\n",
      " dev0 [gold=3,pred=1]: **it** 's a lovely film with lovely performances **by** **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted **here** , **which** **is** probably **for** **the** best .\n",
      " dev2 [gold=3,pred=1]: **and** if **you** 're **not** nearly moved to tears **by** a couple of **scenes** **,** you 've got ice **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 8 Iter 2800 loss=0.7837 elbo -1.5516 ll -1.5441 kl_fb 0.0075 kl 0.0075 kl_weight 1.0000 sf 8.7383 reward -0.8370 ll_mean -1.4629 ll_std 0.0970 selected 1.0601 prior_p1 0.3000 avg_p1 0.3072\n",
      "Epoch 8 Iter 2900 loss=1.8736 elbo -1.4795 ll -1.4735 kl_fb 0.0060 kl 0.0060 kl_weight 1.0000 sf 1.1487 reward -0.1239 ll_mean -1.4614 ll_std 0.0979 selected 1.2793 prior_p1 0.3000 avg_p1 0.3025\n",
      "Epoch 8 Iter 3000 loss=3.7757 elbo -1.4579 ll -1.4516 kl_fb 0.0063 kl 0.0063 kl_weight 1.0000 sf -0.8199 reward 0.0707 ll_mean -1.4586 ll_std 0.0991 selected 1.5791 prior_p1 0.3000 avg_p1 0.2992\n",
      "\n",
      "# epoch 8 iter 3069: dev loss -15.5714 elbo -1.4390 ll -1.4341 kl_fb 0.0049 kl 0.0049 kl_weight 1.0000 sf 17.0104 reward -1.4341 ll_mean 0.0000 ll_std 1.0000 selected 1.0911 prior_p1 0.3000 avg_p1 0.3040 acc 0.3597\n",
      " dev0 [gold=3,pred=1]: **it** **'s** a lovely **film** with **lovely** performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** unindicted **here** , **which** is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if **you** 're **not** nearly **moved** **to** **tears** **by** **a** **couple** **of** scenes , you 've got ice water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 9 Iter 3100 loss=1.0934 elbo -1.5394 ll -1.5299 kl_fb 0.0095 kl 0.0095 kl_weight 1.0000 sf 9.8828 reward -0.6969 ll_mean -1.4584 ll_std 0.1026 selected 0.8613 prior_p1 0.3000 avg_p1 0.3074\n",
      "Epoch 9 Iter 3200 loss=0.9999 elbo -1.5325 ll -1.5274 kl_fb 0.0051 kl 0.0051 kl_weight 1.0000 sf 8.9883 reward -0.6648 ll_mean -1.4589 ll_std 0.1031 selected 0.7912 prior_p1 0.3000 avg_p1 0.3024\n",
      "Epoch 9 Iter 3300 loss=1.3760 elbo -1.3379 ll -1.3331 kl_fb 0.0048 kl 0.0048 kl_weight 1.0000 sf -14.1267 reward 1.2146 ll_mean -1.4587 ll_std 0.1034 selected 0.9976 prior_p1 0.3000 avg_p1 0.2988\n",
      "Epoch 9 Iter 3400 loss=2.4120 elbo -1.6643 ll -1.6571 kl_fb 0.0071 kl 0.0071 kl_weight 1.0000 sf 19.3357 reward -1.9659 ll_mean -1.4572 ll_std 0.1017 selected 1.2239 prior_p1 0.3000 avg_p1 0.3046\n",
      "\n",
      "# epoch 9 iter 3410: dev loss -15.8069 elbo -1.4594 ll -1.4517 kl_fb 0.0077 kl 0.0077 kl_weight 1.0000 sf 17.2663 reward -1.4517 ll_mean 0.0000 ll_std 1.0000 selected 1.0901 prior_p1 0.3000 avg_p1 0.3099 acc 0.3460\n",
      " dev0 [gold=3,pred=1]: it **'s** a lovely film **with** **lovely** performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** you 're **not** **nearly** **moved** to tears **by** a couple of scenes **,** **you** **'ve** **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 10 Iter 3500 loss=2.7131 elbo -1.6199 ll -1.6147 kl_fb 0.0053 kl 0.0053 kl_weight 1.0000 sf 19.4486 reward -1.5602 ll_mean -1.4560 ll_std 0.1017 selected 1.1419 prior_p1 0.3000 avg_p1 0.3036\n",
      "Epoch 10 Iter 3600 loss=1.4002 elbo -1.4887 ll -1.4833 kl_fb 0.0053 kl 0.0053 kl_weight 1.0000 sf 3.5748 reward -0.2714 ll_mean -1.4557 ll_std 0.1018 selected 0.7962 prior_p1 0.3000 avg_p1 0.2983\n",
      "Epoch 10 Iter 3700 loss=0.4659 elbo -1.5018 ll -1.4963 kl_fb 0.0055 kl 0.0055 kl_weight 1.0000 sf 4.2818 reward -0.3828 ll_mean -1.4574 ll_std 0.1017 selected 1.2184 prior_p1 0.3000 avg_p1 0.2975\n",
      "\n",
      "# epoch 10 iter 3751: dev loss -15.5833 elbo -1.4431 ll -1.4385 kl_fb 0.0046 kl 0.0046 kl_weight 1.0000 sf 17.0264 reward -1.4385 ll_mean 0.0000 ll_std 1.0000 selected 1.0822 prior_p1 0.3000 avg_p1 0.3048 acc 0.3579\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film **with** **lovely** **performances** by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: **no** **one** **goes** **unindicted** here **,** **which** is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if **you** 're not **nearly** moved **to** **tears** **by** a couple of scenes , you 've got **ice** water in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 11 Iter 3800 loss=0.4835 elbo -1.5069 ll -1.5016 kl_fb 0.0053 kl 0.0053 kl_weight 1.0000 sf 6.1711 reward -0.4535 ll_mean -1.4570 ll_std 0.0983 selected 1.2061 prior_p1 0.3000 avg_p1 0.2967\n",
      "Epoch 11 Iter 3900 loss=2.0083 elbo -1.4659 ll -1.4567 kl_fb 0.0092 kl 0.0092 kl_weight 1.0000 sf 0.0336 reward -0.0032 ll_mean -1.4564 ll_std 0.0961 selected 1.4594 prior_p1 0.3000 avg_p1 0.3099\n",
      "Epoch 11 Iter 4000 loss=0.9236 elbo -1.4814 ll -1.4767 kl_fb 0.0046 kl 0.0046 kl_weight 1.0000 sf 2.0030 reward -0.1952 ll_mean -1.4582 ll_std 0.0948 selected 1.2532 prior_p1 0.3000 avg_p1 0.3004\n",
      "\n",
      "# epoch 11 iter 4092: dev loss -15.7788 elbo -1.4530 ll -1.4491 kl_fb 0.0039 kl 0.0039 kl_weight 1.0000 sf 17.2317 reward -1.4491 ll_mean 0.0000 ll_std 1.0000 selected 1.0853 prior_p1 0.3000 avg_p1 0.3033 acc 0.3633\n",
      " dev0 [gold=3,pred=1]: **it** **'s** a lovely **film** **with** lovely performances by **buy** **and** **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved to tears by **a** couple **of** scenes , you **'ve** got **ice** water in **your** veins **.**\n",
      "\n",
      "Epoch 12 Iter 4100 loss=2.5996 elbo -1.3994 ll -1.3944 kl_fb 0.0049 kl 0.0049 kl_weight 1.0000 sf -6.4084 reward 0.6720 ll_mean -1.4571 ll_std 0.0933 selected 1.3527 prior_p1 0.3000 avg_p1 0.3038\n",
      "Shuffling training data\n",
      "Epoch 12 Iter 4200 loss=4.2986 elbo -1.5014 ll -1.4942 kl_fb 0.0072 kl 0.0072 kl_weight 1.0000 sf 5.3247 reward -0.4278 ll_mean -1.4543 ll_std 0.0934 selected 1.3396 prior_p1 0.3000 avg_p1 0.3066\n",
      "Epoch 12 Iter 4300 loss=2.4375 elbo -1.6046 ll -1.6000 kl_fb 0.0046 kl 0.0046 kl_weight 1.0000 sf 15.8441 reward -1.5672 ll_mean -1.4524 ll_std 0.0942 selected 1.7180 prior_p1 0.3000 avg_p1 0.3006\n",
      "Epoch 12 Iter 4400 loss=-0.1422 elbo -1.3991 ll -1.3945 kl_fb 0.0046 kl 0.0046 kl_weight 1.0000 sf -7.5866 reward 0.6304 ll_mean -1.4546 ll_std 0.0953 selected 1.1706 prior_p1 0.3000 avg_p1 0.3011\n",
      "\n",
      "# epoch 12 iter 4433: dev loss -15.6477 elbo -1.4466 ll -1.4406 kl_fb 0.0060 kl 0.0060 kl_weight 1.0000 sf 17.0943 reward -1.4406 ll_mean 0.0000 ll_std 1.0000 selected 1.0891 prior_p1 0.3000 avg_p1 0.3078 acc 0.3697\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with lovely performances by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , **which** is probably for the **best** **.**\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved **to** tears by a couple of **scenes** , you 've got **ice** **water** in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 13 Iter 4500 loss=1.9473 elbo -1.4531 ll -1.4485 kl_fb 0.0046 kl 0.0046 kl_weight 1.0000 sf -0.5942 reward 0.0663 ll_mean -1.4549 ll_std 0.0956 selected 1.1688 prior_p1 0.3000 avg_p1 0.2977\n",
      "Epoch 13 Iter 4600 loss=2.1281 elbo -1.2818 ll -1.2722 kl_fb 0.0095 kl 0.0095 kl_weight 1.0000 sf -23.1572 reward 1.8963 ll_mean -1.4540 ll_std 0.0959 selected 1.1696 prior_p1 0.3000 avg_p1 0.2932\n",
      "Epoch 13 Iter 4700 loss=4.7398 elbo -1.3200 ll -1.3082 kl_fb 0.0119 kl 0.0119 kl_weight 1.0000 sf -20.6167 reward 1.4616 ll_mean -1.4498 ll_std 0.0969 selected 1.1114 prior_p1 0.3000 avg_p1 0.3110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 13 iter 4774: dev loss -15.5931 elbo -1.4554 ll -1.4514 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 17.0485 reward -1.4514 ll_mean 0.0000 ll_std 1.0000 selected 1.0813 prior_p1 0.3000 avg_p1 0.3020 acc 0.3433\n",
      " dev0 [gold=3,pred=1]: it 's a lovely **film** with **lovely** performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted here , **which** **is** probably for the best .\n",
      " dev2 [gold=3,pred=1]: **and** if you **'re** not **nearly** **moved** to tears **by** a couple of scenes **,** you **'ve** got ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 14 Iter 4800 loss=0.1275 elbo -1.4610 ll -1.4553 kl_fb 0.0057 kl 0.0057 kl_weight 1.0000 sf 0.8441 reward -0.0626 ll_mean -1.4492 ll_std 0.0978 selected 1.2673 prior_p1 0.3000 avg_p1 0.3042\n",
      "Epoch 14 Iter 4900 loss=1.8676 elbo -1.6653 ll -1.6560 kl_fb 0.0093 kl 0.0093 kl_weight 1.0000 sf 22.4805 reward -2.0721 ll_mean -1.4483 ll_std 0.1002 selected 1.3540 prior_p1 0.3000 avg_p1 0.3082\n",
      "Epoch 14 Iter 5000 loss=0.5146 elbo -1.5056 ll -1.4957 kl_fb 0.0098 kl 0.0098 kl_weight 1.0000 sf 6.0360 reward -0.4716 ll_mean -1.4481 ll_std 0.1011 selected 1.6111 prior_p1 0.3000 avg_p1 0.3073\n",
      "Epoch 14 Iter 5100 loss=2.2090 elbo -1.3095 ll -1.3055 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf -15.1131 reward 1.4007 ll_mean -1.4474 ll_std 0.1013 selected 1.0492 prior_p1 0.3000 avg_p1 0.3013\n",
      "\n",
      "# epoch 14 iter 5115: dev loss -15.6773 elbo -1.4610 ll -1.4568 kl_fb 0.0042 kl 0.0042 kl_weight 1.0000 sf 17.1382 reward -1.4568 ll_mean 0.0000 ll_std 1.0000 selected 1.0839 prior_p1 0.3000 avg_p1 0.3017 acc 0.3306\n",
      " dev0 [gold=3,pred=1]: it 's a lovely film **with** lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes unindicted here **,** which is **probably** **for** the best .\n",
      " dev2 [gold=3,pred=1]: **and** **if** **you** **'re** not **nearly** moved to tears by a couple of **scenes** , you 've got **ice** water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 15 Iter 5200 loss=0.7657 elbo -1.5802 ll -1.5736 kl_fb 0.0066 kl 0.0066 kl_weight 1.0000 sf 14.4595 reward -1.2332 ll_mean -1.4493 ll_std 0.1008 selected 0.9234 prior_p1 0.3000 avg_p1 0.2954\n",
      "Epoch 15 Iter 5300 loss=0.2531 elbo -1.3180 ll -1.3112 kl_fb 0.0068 kl 0.0068 kl_weight 1.0000 sf -16.8599 reward 1.4011 ll_mean -1.4512 ll_std 0.0999 selected 1.3103 prior_p1 0.3000 avg_p1 0.3038\n",
      "Epoch 15 Iter 5400 loss=3.1809 elbo -1.4996 ll -1.4948 kl_fb 0.0048 kl 0.0048 kl_weight 1.0000 sf 5.6057 reward -0.4699 ll_mean -1.4475 ll_std 0.1007 selected 0.9591 prior_p1 0.3000 avg_p1 0.2994\n",
      "\n",
      "# epoch 15 iter 5456: dev loss -15.3925 elbo -1.4514 ll -1.4475 kl_fb 0.0039 kl 0.0039 kl_weight 1.0000 sf 16.8439 reward -1.4475 ll_mean 0.0000 ll_std 1.0000 selected 1.0680 prior_p1 0.3000 avg_p1 0.2967 acc 0.3415\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** lovely film with **lovely** **performances** **by** buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one **goes** unindicted here , which is **probably** **for** the **best** **.**\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly moved to tears **by** a couple of scenes , **you** **'ve** got ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 16 Iter 5500 loss=0.8789 elbo -1.3430 ll -1.3349 kl_fb 0.0081 kl 0.0081 kl_weight 1.0000 sf -12.5920 reward 1.1370 ll_mean -1.4479 ll_std 0.0993 selected 1.1214 prior_p1 0.3000 avg_p1 0.3084\n",
      "Epoch 16 Iter 5600 loss=1.4162 elbo -1.3808 ll -1.3764 kl_fb 0.0043 kl 0.0043 kl_weight 1.0000 sf -7.7852 reward 0.7077 ll_mean -1.4474 ll_std 0.1003 selected 1.6093 prior_p1 0.3000 avg_p1 0.3035\n",
      "Epoch 16 Iter 5700 loss=1.7700 elbo -1.6910 ll -1.6859 kl_fb 0.0051 kl 0.0051 kl_weight 1.0000 sf 23.7495 reward -2.3559 ll_mean -1.4493 ll_std 0.1004 selected 1.3139 prior_p1 0.3000 avg_p1 0.3074\n",
      "\n",
      "# epoch 16 iter 5797: dev loss -15.4010 elbo -1.4258 ll -1.4226 kl_fb 0.0033 kl 0.0033 kl_weight 1.0000 sf 16.8268 reward -1.4226 ll_mean 0.0000 ll_std 1.0000 selected 1.0821 prior_p1 0.3000 avg_p1 0.3010 acc 0.3660\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** unindicted here **,** which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved **to** tears **by** **a** couple of scenes , you 've got ice **water** in your veins **.**\n",
      "\n",
      "Epoch 17 Iter 5800 loss=3.0546 elbo -1.4928 ll -1.4887 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 4.3601 reward -0.4062 ll_mean -1.4473 ll_std 0.1021 selected 1.0415 prior_p1 0.3000 avg_p1 0.2995\n",
      "Shuffling training data\n",
      "Epoch 17 Iter 5900 loss=1.9845 elbo -1.4503 ll -1.4446 kl_fb 0.0057 kl 0.0057 kl_weight 1.0000 sf -0.2916 reward 0.0256 ll_mean -1.4472 ll_std 0.1022 selected 1.1108 prior_p1 0.3000 avg_p1 0.3080\n",
      "Epoch 17 Iter 6000 loss=-0.1327 elbo -1.6606 ll -1.6553 kl_fb 0.0053 kl 0.0053 kl_weight 1.0000 sf 25.9740 reward -2.0381 ll_mean -1.4472 ll_std 0.1021 selected 0.9621 prior_p1 0.3000 avg_p1 0.2951\n",
      "Epoch 17 Iter 6100 loss=1.7405 elbo -1.5169 ll -1.5104 kl_fb 0.0065 kl 0.0065 kl_weight 1.0000 sf 8.0766 reward -0.6186 ll_mean -1.4472 ll_std 0.1021 selected 1.4067 prior_p1 0.3000 avg_p1 0.3032\n",
      "\n",
      "# epoch 17 iter 6138: dev loss -15.6806 elbo -1.4527 ll -1.4499 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf 17.1333 reward -1.4499 ll_mean 0.0000 ll_std 1.0000 selected 1.0783 prior_p1 0.3000 avg_p1 0.3004 acc 0.3560\n",
      " dev0 [gold=3,pred=1]: **it** **'s** a **lovely** film with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one **goes** unindicted here **,** which is probably for **the** **best** **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** nearly **moved** to tears **by** a couple of scenes , you 've **got** ice water in your veins .\n",
      "\n",
      "Epoch    17: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Shuffling training data\n",
      "Epoch 18 Iter 6200 loss=0.7047 elbo -1.3089 ll -1.3036 kl_fb 0.0053 kl 0.0053 kl_weight 1.0000 sf -15.8832 reward 1.4100 ll_mean -1.4479 ll_std 0.1023 selected 0.8473 prior_p1 0.3000 avg_p1 0.3057\n",
      "Epoch 18 Iter 6300 loss=0.7177 elbo -1.3225 ll -1.3191 kl_fb 0.0033 kl 0.0033 kl_weight 1.0000 sf -11.7902 reward 1.2367 ll_mean -1.4468 ll_std 0.1032 selected 1.1874 prior_p1 0.3000 avg_p1 0.3000\n",
      "Epoch 18 Iter 6400 loss=1.4195 elbo -1.3726 ll -1.3696 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf -9.7768 reward 0.7728 ll_mean -1.4484 ll_std 0.1020 selected 1.1425 prior_p1 0.3000 avg_p1 0.3023\n",
      "\n",
      "# epoch 18 iter 6479: dev loss -15.4926 elbo -1.4406 ll -1.4380 kl_fb 0.0026 kl 0.0026 kl_weight 1.0000 sf 16.9332 reward -1.4380 ll_mean 0.0000 ll_std 1.0000 selected 1.0834 prior_p1 0.3000 avg_p1 0.3021 acc 0.3524\n",
      " dev0 [gold=3,pred=0]: it 's a **lovely** film with lovely **performances** by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: **no** **one** goes **unindicted** here , which is **probably** for the best .\n",
      " dev2 [gold=3,pred=1]: and if you **'re** not nearly moved to tears by a **couple** of scenes , you **'ve** got **ice** water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 19 Iter 6500 loss=1.2904 elbo -1.3452 ll -1.3405 kl_fb 0.0047 kl 0.0047 kl_weight 1.0000 sf -13.8091 reward 1.0537 ll_mean -1.4483 ll_std 0.1023 selected 1.2282 prior_p1 0.3000 avg_p1 0.3022\n",
      "Epoch 19 Iter 6600 loss=3.9716 elbo -1.3781 ll -1.3728 kl_fb 0.0053 kl 0.0053 kl_weight 1.0000 sf -9.9296 reward 0.7155 ll_mean -1.4462 ll_std 0.1026 selected 1.4267 prior_p1 0.3000 avg_p1 0.3057\n",
      "Epoch 19 Iter 6700 loss=-0.8580 elbo -1.4588 ll -1.4557 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf 0.7811 reward -0.0688 ll_mean -1.4486 ll_std 0.1020 selected 1.1530 prior_p1 0.3000 avg_p1 0.2976\n",
      "Epoch 19 Iter 6800 loss=0.9386 elbo -1.3909 ll -1.3857 kl_fb 0.0051 kl 0.0051 kl_weight 1.0000 sf -6.8090 reward 0.6457 ll_mean -1.4503 ll_std 0.1000 selected 1.1997 prior_p1 0.3000 avg_p1 0.3038\n",
      "\n",
      "# epoch 19 iter 6820: dev loss -15.4998 elbo -1.4395 ll -1.4370 kl_fb 0.0025 kl 0.0025 kl_weight 1.0000 sf 16.9393 reward -1.4370 ll_mean 0.0000 ll_std 1.0000 selected 1.0841 prior_p1 0.3000 avg_p1 0.2992 acc 0.3624\n",
      " dev0 [gold=3,pred=1]: it 's a lovely **film** with lovely **performances** **by** buy and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which **is** probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you **'re** not nearly moved **to** tears **by** a couple of scenes , you 've got ice water in your veins .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 20 Iter 6900 loss=0.6349 elbo -1.5484 ll -1.5446 kl_fb 0.0038 kl 0.0038 kl_weight 1.0000 sf 10.3366 reward -0.9452 ll_mean -1.4516 ll_std 0.0984 selected 1.2344 prior_p1 0.3000 avg_p1 0.2956\n",
      "Epoch 20 Iter 7000 loss=2.3724 elbo -1.4559 ll -1.4521 kl_fb 0.0038 kl 0.0038 kl_weight 1.0000 sf 0.1886 reward -0.0172 ll_mean -1.4504 ll_std 0.0990 selected 1.5570 prior_p1 0.3000 avg_p1 0.3018\n",
      "Epoch 20 Iter 7100 loss=1.4224 elbo -1.4077 ll -1.4044 kl_fb 0.0032 kl 0.0032 kl_weight 1.0000 sf -4.3660 reward 0.4704 ll_mean -1.4511 ll_std 0.0992 selected 1.5367 prior_p1 0.3000 avg_p1 0.3005\n",
      "\n",
      "# epoch 20 iter 7161: dev loss -15.3888 elbo -1.4392 ll -1.4369 kl_fb 0.0023 kl 0.0023 kl_weight 1.0000 sf 16.8280 reward -1.4369 ll_mean 0.0000 ll_std 1.0000 selected 1.0790 prior_p1 0.3000 avg_p1 0.3016 acc 0.3642\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film with lovely performances by buy **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes unindicted here , which is probably for **the** best **.**\n",
      " dev2 [gold=3,pred=1]: **and** if you **'re** **not** nearly moved to **tears** by a couple of scenes **,** you 've **got** ice water in your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 21 Iter 7200 loss=3.1979 elbo -1.4546 ll -1.4513 kl_fb 0.0033 kl 0.0033 kl_weight 1.0000 sf 0.3222 reward -0.0257 ll_mean -1.4488 ll_std 0.1003 selected 1.2417 prior_p1 0.3000 avg_p1 0.3002\n",
      "Epoch 21 Iter 7300 loss=3.5890 elbo -1.3121 ll -1.3076 kl_fb 0.0045 kl 0.0045 kl_weight 1.0000 sf -16.8614 reward 1.3729 ll_mean -1.4467 ll_std 0.1013 selected 1.0975 prior_p1 0.3000 avg_p1 0.3007\n",
      "Epoch 21 Iter 7400 loss=3.0210 elbo -1.4789 ll -1.4754 kl_fb 0.0035 kl 0.0035 kl_weight 1.0000 sf 3.5212 reward -0.2963 ll_mean -1.4449 ll_std 0.1027 selected 0.9516 prior_p1 0.3000 avg_p1 0.3023\n",
      "Epoch 21 Iter 7500 loss=1.6077 elbo -1.3615 ll -1.3572 kl_fb 0.0044 kl 0.0044 kl_weight 1.0000 sf -10.3378 reward 0.8378 ll_mean -1.4443 ll_std 0.1041 selected 0.7599 prior_p1 0.3000 avg_p1 0.2997\n",
      "\n",
      "# epoch 21 iter 7502: dev loss -15.7272 elbo -1.4487 ll -1.4463 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf 17.1759 reward -1.4463 ll_mean 0.0000 ll_std 1.0000 selected 1.0968 prior_p1 0.3000 avg_p1 0.2990 acc 0.3497\n",
      " dev0 [gold=3,pred=3]: it 's a lovely **film** with lovely performances **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted **here** , which is probably for **the** best **.**\n",
      " dev2 [gold=3,pred=1]: and if **you** **'re** **not** nearly **moved** to tears by **a** couple of scenes **,** you **'ve** got ice **water** in **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 22 Iter 7600 loss=3.5665 elbo -1.1809 ll -1.1769 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf -28.8008 reward 2.5870 ll_mean -1.4446 ll_std 0.1035 selected 1.0795 prior_p1 0.3000 avg_p1 0.2983\n",
      "Epoch 22 Iter 7700 loss=0.2564 elbo -1.4058 ll -1.4030 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf -4.4163 reward 0.3870 ll_mean -1.4433 ll_std 0.1042 selected 1.0091 prior_p1 0.3000 avg_p1 0.2985\n",
      "Epoch 22 Iter 7800 loss=0.0758 elbo -1.3987 ll -1.3944 kl_fb 0.0042 kl 0.0042 kl_weight 1.0000 sf -6.5565 reward 0.4725 ll_mean -1.4433 ll_std 0.1034 selected 1.0702 prior_p1 0.3000 avg_p1 0.3016\n",
      "\n",
      "# epoch 22 iter 7843: dev loss -15.6648 elbo -1.4576 ll -1.4551 kl_fb 0.0025 kl 0.0025 kl_weight 1.0000 sf 17.1224 reward -1.4551 ll_mean 0.0000 ll_std 1.0000 selected 1.0847 prior_p1 0.3000 avg_p1 0.2982 acc 0.3560\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** lovely **film** **with** lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here **,** **which** **is** probably for the best .\n",
      " dev2 [gold=3,pred=3]: **and** **if** **you** 're not nearly **moved** to tears by **a** couple of scenes , you 've got ice water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 23 Iter 7900 loss=0.8798 elbo -1.5366 ll -1.5333 kl_fb 0.0033 kl 0.0033 kl_weight 1.0000 sf 8.4493 reward -0.8822 ll_mean -1.4424 ll_std 0.1030 selected 1.3605 prior_p1 0.3000 avg_p1 0.3049\n",
      "Epoch 23 Iter 8000 loss=1.7137 elbo -1.5430 ll -1.5379 kl_fb 0.0052 kl 0.0052 kl_weight 1.0000 sf 12.0370 reward -0.9322 ll_mean -1.4419 ll_std 0.1030 selected 1.3480 prior_p1 0.3000 avg_p1 0.3021\n",
      "Epoch 23 Iter 8100 loss=1.1771 elbo -1.4806 ll -1.4774 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf 3.6637 reward -0.3483 ll_mean -1.4412 ll_std 0.1040 selected 1.4096 prior_p1 0.3000 avg_p1 0.3030\n",
      "\n",
      "# epoch 23 iter 8184: dev loss -15.5428 elbo -1.4467 ll -1.4446 kl_fb 0.0021 kl 0.0021 kl_weight 1.0000 sf 16.9895 reward -1.4446 ll_mean 0.0000 ll_std 1.0000 selected 1.0828 prior_p1 0.3000 avg_p1 0.2995 acc 0.3488\n",
      " dev0 [gold=3,pred=1]: it 's **a** lovely **film** with **lovely** performances **by** **buy** and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes **unindicted** here , which **is** probably for the best .\n",
      " dev2 [gold=3,pred=1]: and if you **'re** **not** nearly moved to tears by a **couple** of scenes , **you** **'ve** got ice water in **your** **veins** **.**\n",
      "\n",
      "Epoch 24 Iter 8200 loss=0.3569 elbo -1.6029 ll -1.5992 kl_fb 0.0037 kl 0.0037 kl_weight 1.0000 sf 18.5126 reward -1.5121 ll_mean -1.4428 ll_std 0.1034 selected 1.1811 prior_p1 0.3000 avg_p1 0.2964\n",
      "Shuffling training data\n",
      "Epoch 24 Iter 8300 loss=-0.0741 elbo -1.3657 ll -1.3633 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf -8.3194 reward 0.8083 ll_mean -1.4456 ll_std 0.1017 selected 1.1022 prior_p1 0.3000 avg_p1 0.2997\n",
      "Epoch 24 Iter 8400 loss=3.9973 elbo -1.3979 ll -1.3933 kl_fb 0.0046 kl 0.0046 kl_weight 1.0000 sf -5.6079 reward 0.5103 ll_mean -1.4447 ll_std 0.1008 selected 2.0931 prior_p1 0.3000 avg_p1 0.3058\n",
      "Epoch 24 Iter 8500 loss=1.3659 elbo -1.4074 ll -1.4030 kl_fb 0.0044 kl 0.0044 kl_weight 1.0000 sf -4.4718 reward 0.4209 ll_mean -1.4447 ll_std 0.0989 selected 1.3475 prior_p1 0.3000 avg_p1 0.3005\n",
      "\n",
      "# epoch 24 iter 8525: dev loss -15.4728 elbo -1.4371 ll -1.4352 kl_fb 0.0019 kl 0.0019 kl_weight 1.0000 sf 16.9098 reward -1.4352 ll_mean 0.0000 ll_std 1.0000 selected 1.0656 prior_p1 0.3000 avg_p1 0.3005 acc 0.3597\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** **film** with **lovely** **performances** by **buy** and accorsi **.**\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're not **nearly** **moved** to **tears** by a couple of scenes , **you** **'ve** **got** ice water **in** **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 25 Iter 8600 loss=2.7346 elbo -1.4175 ll -1.4143 kl_fb 0.0032 kl 0.0032 kl_weight 1.0000 sf -3.8709 reward 0.3126 ll_mean -1.4454 ll_std 0.0996 selected 1.2210 prior_p1 0.3000 avg_p1 0.3029\n",
      "Epoch 25 Iter 8700 loss=0.3194 elbo -1.5268 ll -1.5228 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 9.8607 reward -0.7805 ll_mean -1.4454 ll_std 0.0992 selected 1.2859 prior_p1 0.3000 avg_p1 0.3050\n",
      "Epoch 25 Iter 8800 loss=1.9842 elbo -1.6442 ll -1.6401 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 22.2252 reward -1.9497 ll_mean -1.4435 ll_std 0.1008 selected 1.2321 prior_p1 0.3000 avg_p1 0.3029\n",
      "\n",
      "# epoch 25 iter 8866: dev loss -15.2995 elbo -1.4315 ll -1.4292 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf 16.7311 reward -1.4292 ll_mean 0.0000 ll_std 1.0000 selected 1.0798 prior_p1 0.3000 avg_p1 0.2972 acc 0.3688\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film **with** lovely **performances** by **buy** and accorsi **.**\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** **here** , **which** is probably **for** the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly **moved** to **tears** by a couple **of** scenes , you 've got **ice** **water** in **your** **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 26 Iter 8900 loss=2.2786 elbo -1.4172 ll -1.4142 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf -3.3806 reward 0.2792 ll_mean -1.4427 ll_std 0.1020 selected 1.2477 prior_p1 0.3000 avg_p1 0.2964\n",
      "Epoch 26 Iter 9000 loss=2.4356 elbo -1.4602 ll -1.4554 kl_fb 0.0048 kl 0.0048 kl_weight 1.0000 sf 1.5063 reward -0.1313 ll_mean -1.4419 ll_std 0.1030 selected 1.4310 prior_p1 0.3000 avg_p1 0.3075\n",
      "Epoch 26 Iter 9100 loss=2.3267 elbo -1.4928 ll -1.4888 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 5.3218 reward -0.4766 ll_mean -1.4406 ll_std 0.1012 selected 1.8014 prior_p1 0.3000 avg_p1 0.3058\n",
      "Epoch 26 Iter 9200 loss=1.3576 elbo -1.4314 ll -1.4273 kl_fb 0.0041 kl 0.0041 kl_weight 1.0000 sf -1.7641 reward 0.1251 ll_mean -1.4399 ll_std 0.1011 selected 1.4003 prior_p1 0.3000 avg_p1 0.3031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 26 iter 9207: dev loss -15.5160 elbo -1.4410 ll -1.4383 kl_fb 0.0026 kl 0.0026 kl_weight 1.0000 sf 16.9569 reward -1.4383 ll_mean 0.0000 ll_std 1.0000 selected 1.0940 prior_p1 0.3000 avg_p1 0.3039 acc 0.3579\n",
      " dev0 [gold=3,pred=1]: **it** 's a lovely film **with** lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no **one** **goes** unindicted here **,** which is probably **for** the best **.**\n",
      " dev2 [gold=3,pred=1]: **and** **if** you **'re** not nearly moved to tears by a couple of **scenes** , **you** 've got ice **water** **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 27 Iter 9300 loss=1.4653 elbo -1.4174 ll -1.4148 kl_fb 0.0027 kl 0.0027 kl_weight 1.0000 sf -2.7699 reward 0.2294 ll_mean -1.4379 ll_std 0.1011 selected 1.3769 prior_p1 0.3000 avg_p1 0.3005\n",
      "Epoch 27 Iter 9400 loss=2.8166 elbo -1.2421 ll -1.2370 kl_fb 0.0052 kl 0.0052 kl_weight 1.0000 sf -25.8612 reward 1.9894 ll_mean -1.4388 ll_std 0.1015 selected 1.1738 prior_p1 0.3000 avg_p1 0.3034\n",
      "Epoch 27 Iter 9500 loss=0.7254 elbo -1.3411 ll -1.3364 kl_fb 0.0047 kl 0.0047 kl_weight 1.0000 sf -13.8799 reward 1.0024 ll_mean -1.4385 ll_std 0.1019 selected 1.0665 prior_p1 0.3000 avg_p1 0.3044\n",
      "\n",
      "# epoch 27 iter 9548: dev loss -15.5288 elbo -1.4483 ll -1.4458 kl_fb 0.0025 kl 0.0025 kl_weight 1.0000 sf 16.9771 reward -1.4458 ll_mean 0.0000 ll_std 1.0000 selected 1.0770 prior_p1 0.3000 avg_p1 0.3027 acc 0.3315\n",
      " dev0 [gold=3,pred=1]: it 's a lovely **film** with **lovely** **performances** **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: **no** **one** goes **unindicted** here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=1]: and if **you** 're **not** nearly moved to **tears** by **a** **couple** of **scenes** , **you** **'ve** got ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 28 Iter 9600 loss=1.4548 elbo -1.5413 ll -1.5357 kl_fb 0.0056 kl 0.0056 kl_weight 1.0000 sf 12.3441 reward -0.9570 ll_mean -1.4387 ll_std 0.1013 selected 1.3341 prior_p1 0.3000 avg_p1 0.3072\n",
      "Epoch 28 Iter 9700 loss=1.2355 elbo -1.5968 ll -1.5939 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf 17.7444 reward -1.5473 ll_mean -1.4374 ll_std 0.1012 selected 1.1089 prior_p1 0.3000 avg_p1 0.3013\n",
      "Epoch 28 Iter 9800 loss=-0.1130 elbo -1.2617 ll -1.2564 kl_fb 0.0053 kl 0.0053 kl_weight 1.0000 sf -20.7892 reward 1.8025 ll_mean -1.4393 ll_std 0.1014 selected 1.6258 prior_p1 0.3000 avg_p1 0.3047\n",
      "\n",
      "# epoch 28 iter 9889: dev loss -15.4969 elbo -1.4368 ll -1.4343 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf 16.9337 reward -1.4343 ll_mean 0.0000 ll_std 1.0000 selected 1.0644 prior_p1 0.3000 avg_p1 0.3032 acc 0.3597\n",
      " dev0 [gold=3,pred=3]: **it** 's a **lovely** film **with** lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , which **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and if **you** 're not nearly **moved** to **tears** by a couple of scenes , you **'ve** **got** ice water in your veins **.**\n",
      "\n",
      "Epoch    28: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 29 Iter 9900 loss=0.5833 elbo -1.3536 ll -1.3511 kl_fb 0.0026 kl 0.0026 kl_weight 1.0000 sf -7.9832 reward 0.8745 ll_mean -1.4399 ll_std 0.1016 selected 1.2631 prior_p1 0.3000 avg_p1 0.3040\n",
      "Shuffling training data\n",
      "Epoch 29 Iter 10000 loss=3.0715 elbo -1.2428 ll -1.2397 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf -21.3246 reward 1.9867 ll_mean -1.4392 ll_std 0.1004 selected 1.5561 prior_p1 0.3000 avg_p1 0.3023\n",
      "Epoch 29 Iter 10100 loss=0.2709 elbo -1.5419 ll -1.5380 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 10.4567 reward -0.9622 ll_mean -1.4409 ll_std 0.1009 selected 1.3626 prior_p1 0.3000 avg_p1 0.3054\n",
      "Epoch 29 Iter 10200 loss=2.2005 elbo -1.3958 ll -1.3903 kl_fb 0.0056 kl 0.0056 kl_weight 1.0000 sf -6.6594 reward 0.5005 ll_mean -1.4402 ll_std 0.0997 selected 1.2221 prior_p1 0.3000 avg_p1 0.3061\n",
      "\n",
      "# epoch 29 iter 10230: dev loss -15.6633 elbo -1.4451 ll -1.4419 kl_fb 0.0033 kl 0.0033 kl_weight 1.0000 sf 17.1084 reward -1.4419 ll_mean 0.0000 ll_std 1.0000 selected 1.0884 prior_p1 0.3000 avg_p1 0.3055 acc 0.3542\n",
      " dev0 [gold=3,pred=3]: it **'s** **a** **lovely** film with **lovely** performances by **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted **here** , which **is** probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not **nearly** **moved** to tears by a couple of **scenes** , you 've got ice **water** **in** **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 30 Iter 10300 loss=3.2009 elbo -1.4294 ll -1.4270 kl_fb 0.0023 kl 0.0023 kl_weight 1.0000 sf -1.1250 reward 0.1155 ll_mean -1.4388 ll_std 0.1016 selected 1.2865 prior_p1 0.3000 avg_p1 0.3037\n",
      "Epoch 30 Iter 10400 loss=2.7916 elbo -1.2909 ll -1.2880 kl_fb 0.0029 kl 0.0029 kl_weight 1.0000 sf -16.3404 reward 1.4642 ll_mean -1.4385 ll_std 0.1028 selected 1.7204 prior_p1 0.3000 avg_p1 0.3019\n",
      "Epoch 30 Iter 10500 loss=0.4987 elbo -1.5099 ll -1.5071 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf 7.8986 reward -0.6608 ll_mean -1.4389 ll_std 0.1033 selected 1.2804 prior_p1 0.3000 avg_p1 0.2989\n",
      "\n",
      "# epoch 30 iter 10571: dev loss -15.3603 elbo -1.4217 ll -1.4196 kl_fb 0.0021 kl 0.0021 kl_weight 1.0000 sf 16.7820 reward -1.4196 ll_mean 0.0000 ll_std 1.0000 selected 1.0836 prior_p1 0.3000 avg_p1 0.3023 acc 0.3860\n",
      " dev0 [gold=3,pred=3]: **it** **'s** **a** lovely film with **lovely** **performances** by buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** **unindicted** here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: **and** if you **'re** not **nearly** moved to tears by a couple of scenes **,** you 've **got** ice **water** **in** **your** **veins** **.**\n",
      "\n",
      "Epoch 31 Iter 10600 loss=1.0694 elbo -1.3824 ll -1.3794 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf -7.2130 reward 0.5815 ll_mean -1.4398 ll_std 0.1038 selected 1.5682 prior_p1 0.3000 avg_p1 0.3029\n",
      "Shuffling training data\n",
      "Epoch 31 Iter 10700 loss=0.6998 elbo -1.4620 ll -1.4586 kl_fb 0.0034 kl 0.0034 kl_weight 1.0000 sf 2.1970 reward -0.1770 ll_mean -1.4402 ll_std 0.1036 selected 1.3015 prior_p1 0.3000 avg_p1 0.2994\n",
      "Epoch 31 Iter 10800 loss=3.1704 elbo -1.3483 ll -1.3460 kl_fb 0.0023 kl 0.0023 kl_weight 1.0000 sf -8.8485 reward 0.8785 ll_mean -1.4371 ll_std 0.1037 selected 2.2420 prior_p1 0.3000 avg_p1 0.3002\n",
      "Epoch 31 Iter 10900 loss=2.6436 elbo -1.4099 ll -1.4065 kl_fb 0.0034 kl 0.0034 kl_weight 1.0000 sf -3.6415 reward 0.2765 ll_mean -1.4350 ll_std 0.1031 selected 1.4939 prior_p1 0.3000 avg_p1 0.3005\n",
      "\n",
      "# epoch 31 iter 10912: dev loss -15.3440 elbo -1.4401 ll -1.4379 kl_fb 0.0021 kl 0.0021 kl_weight 1.0000 sf 16.7840 reward -1.4379 ll_mean 0.0000 ll_std 1.0000 selected 1.0709 prior_p1 0.3000 avg_p1 0.3026 acc 0.3615\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** lovely film with lovely performances by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one **goes** unindicted here , which is probably **for** the **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're **not** nearly moved to tears **by** a couple of scenes , you 've got ice water in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 32 Iter 11000 loss=1.2582 elbo -1.5902 ll -1.5865 kl_fb 0.0037 kl 0.0037 kl_weight 1.0000 sf 17.4916 reward -1.4848 ll_mean -1.4360 ll_std 0.1013 selected 1.0678 prior_p1 0.3000 avg_p1 0.3022\n",
      "Epoch 32 Iter 11100 loss=0.2480 elbo -1.4423 ll -1.4393 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf 0.3141 reward -0.0297 ll_mean -1.4363 ll_std 0.1014 selected 0.9498 prior_p1 0.3000 avg_p1 0.3027\n",
      "Epoch 32 Iter 11200 loss=2.3147 elbo -1.4543 ll -1.4513 kl_fb 0.0029 kl 0.0029 kl_weight 1.0000 sf 1.9874 reward -0.1551 ll_mean -1.4356 ll_std 0.1015 selected 1.2758 prior_p1 0.3000 avg_p1 0.3013\n",
      "\n",
      "# epoch 32 iter 11253: dev loss -15.3055 elbo -1.4250 ll -1.4228 kl_fb 0.0022 kl 0.0022 kl_weight 1.0000 sf 16.7305 reward -1.4228 ll_mean 0.0000 ll_std 1.0000 selected 1.0726 prior_p1 0.3000 avg_p1 0.2971 acc 0.3697\n",
      " dev0 [gold=3,pred=3]: it 's a lovely film **with** lovely **performances** by **buy** and **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no **one** **goes** unindicted here , which is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: and **if** **you** 're not **nearly** **moved** to **tears** **by** **a** couple of scenes **,** you **'ve** got ice water in **your** veins **.**\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling training data\n",
      "Epoch 33 Iter 11300 loss=0.3616 elbo -1.3535 ll -1.3505 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf -10.8433 reward 0.8635 ll_mean -1.4378 ll_std 0.1011 selected 1.6865 prior_p1 0.3000 avg_p1 0.3011\n",
      "Epoch 33 Iter 11400 loss=0.3242 elbo -1.4741 ll -1.4710 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf 4.1919 reward -0.3138 ll_mean -1.4396 ll_std 0.1001 selected 0.9512 prior_p1 0.3000 avg_p1 0.3029\n",
      "Epoch 33 Iter 11500 loss=1.2737 elbo -1.5625 ll -1.5590 kl_fb 0.0034 kl 0.0034 kl_weight 1.0000 sf 14.3156 reward -1.2137 ll_mean -1.4391 ll_std 0.0988 selected 0.7003 prior_p1 0.3000 avg_p1 0.3033\n",
      "\n",
      "# epoch 33 iter 11594: dev loss -15.4292 elbo -1.4370 ll -1.4352 kl_fb 0.0017 kl 0.0017 kl_weight 1.0000 sf 16.8662 reward -1.4352 ll_mean 0.0000 ll_std 1.0000 selected 1.0834 prior_p1 0.3000 avg_p1 0.2994 acc 0.3424\n",
      " dev0 [gold=3,pred=1]: it 's a **lovely** **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted **here** , which is **probably** **for** the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved **to** **tears** by **a** couple **of** scenes , you 've **got** ice **water** in **your** veins .\n",
      "\n",
      "Epoch 34 Iter 11600 loss=2.2499 elbo -1.3903 ll -1.3879 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf -5.2931 reward 0.5091 ll_mean -1.4380 ll_std 0.0983 selected 1.3101 prior_p1 0.3000 avg_p1 0.3005\n",
      "Shuffling training data\n",
      "Epoch 34 Iter 11700 loss=1.9742 elbo -1.4360 ll -1.4327 kl_fb 0.0033 kl 0.0033 kl_weight 1.0000 sf -0.5180 reward 0.0412 ll_mean -1.4367 ll_std 0.0979 selected 0.7395 prior_p1 0.3000 avg_p1 0.2993\n",
      "Epoch 34 Iter 11800 loss=4.1136 elbo -1.4853 ll -1.4828 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf 4.3554 reward -0.4882 ll_mean -1.4356 ll_std 0.0968 selected 1.0141 prior_p1 0.3000 avg_p1 0.3028\n",
      "Epoch 34 Iter 11900 loss=-2.1096 elbo -1.4425 ll -1.4392 kl_fb 0.0032 kl 0.0032 kl_weight 1.0000 sf -0.0988 reward 0.0073 ll_mean -1.4399 ll_std 0.0978 selected 1.2436 prior_p1 0.3000 avg_p1 0.3030\n",
      "\n",
      "# epoch 34 iter 11935: dev loss -15.4547 elbo -1.4384 ll -1.4365 kl_fb 0.0019 kl 0.0019 kl_weight 1.0000 sf 16.8932 reward -1.4365 ll_mean 0.0000 ll_std 1.0000 selected 1.0832 prior_p1 0.3000 avg_p1 0.3009 acc 0.3515\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** **lovely** **film** with lovely **performances** **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted here , **which** is **probably** for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** moved to **tears** **by** a couple **of** scenes , you 've got ice water **in** **your** veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 35 Iter 12000 loss=2.0056 elbo -1.4494 ll -1.4475 kl_fb 0.0019 kl 0.0019 kl_weight 1.0000 sf 0.8448 reward -0.0784 ll_mean -1.4397 ll_std 0.0990 selected 1.0720 prior_p1 0.3000 avg_p1 0.3021\n",
      "Epoch 35 Iter 12100 loss=1.7259 elbo -1.4908 ll -1.4878 kl_fb 0.0029 kl 0.0029 kl_weight 1.0000 sf 6.4761 reward -0.4986 ll_mean -1.4383 ll_std 0.0994 selected 0.7953 prior_p1 0.3000 avg_p1 0.3019\n",
      "Epoch 35 Iter 12200 loss=3.2880 elbo -1.3015 ll -1.2981 kl_fb 0.0034 kl 0.0034 kl_weight 1.0000 sf -16.8614 reward 1.3856 ll_mean -1.4377 ll_std 0.1007 selected 1.4510 prior_p1 0.3000 avg_p1 0.3030\n",
      "\n",
      "# epoch 35 iter 12276: dev loss -15.5321 elbo -1.4439 ll -1.4420 kl_fb 0.0019 kl 0.0019 kl_weight 1.0000 sf 16.9760 reward -1.4420 ll_mean 0.0000 ll_std 1.0000 selected 1.0789 prior_p1 0.3000 avg_p1 0.3017 acc 0.3624\n",
      " dev0 [gold=3,pred=1]: it 's **a** lovely film **with** lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=4]: no **one** goes unindicted **here** , **which** **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=3]: and **if** **you** 're **not** **nearly** **moved** to tears by a couple of scenes , you 've got ice water in your veins .\n",
      "\n",
      "Epoch 36 Iter 12300 loss=2.1829 elbo -1.3247 ll -1.3217 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf -16.3766 reward 1.1393 ll_mean -1.4361 ll_std 0.1004 selected 1.2357 prior_p1 0.3000 avg_p1 0.3005\n",
      "Shuffling training data\n",
      "Epoch 36 Iter 12400 loss=0.9007 elbo -1.4931 ll -1.4900 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf 6.6766 reward -0.5429 ll_mean -1.4353 ll_std 0.1008 selected 1.5449 prior_p1 0.3000 avg_p1 0.2987\n",
      "Epoch 36 Iter 12500 loss=1.7634 elbo -1.2014 ll -1.1985 kl_fb 0.0029 kl 0.0029 kl_weight 1.0000 sf -25.9205 reward 2.3373 ll_mean -1.4346 ll_std 0.1010 selected 1.7527 prior_p1 0.3000 avg_p1 0.3027\n",
      "Epoch 36 Iter 12600 loss=1.1147 elbo -1.3644 ll -1.3605 kl_fb 0.0039 kl 0.0039 kl_weight 1.0000 sf -9.0877 reward 0.7459 ll_mean -1.4349 ll_std 0.0997 selected 1.3063 prior_p1 0.3000 avg_p1 0.3022\n",
      "\n",
      "# epoch 36 iter 12617: dev loss -15.5571 elbo -1.4405 ll -1.4387 kl_fb 0.0018 kl 0.0018 kl_weight 1.0000 sf 16.9977 reward -1.4387 ll_mean 0.0000 ll_std 1.0000 selected 1.0745 prior_p1 0.3000 avg_p1 0.3012 acc 0.3460\n",
      " dev0 [gold=3,pred=3]: **it** 's **a** **lovely** film **with** lovely performances **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** **one** goes unindicted here , which is probably **for** the best .\n",
      " dev2 [gold=3,pred=1]: and if **you** **'re** not nearly moved to **tears** by a couple **of** scenes **,** you 've got **ice** water **in** your veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 37 Iter 12700 loss=0.7651 elbo -1.1871 ll -1.1834 kl_fb 0.0036 kl 0.0036 kl_weight 1.0000 sf -30.7836 reward 2.5225 ll_mean -1.4358 ll_std 0.1000 selected 0.8837 prior_p1 0.3000 avg_p1 0.3023\n",
      "Epoch 37 Iter 12800 loss=2.5372 elbo -1.5236 ll -1.5178 kl_fb 0.0058 kl 0.0058 kl_weight 1.0000 sf 10.3250 reward -0.8053 ll_mean -1.4370 ll_std 0.1004 selected 0.9892 prior_p1 0.3000 avg_p1 0.3059\n",
      "Epoch 37 Iter 12900 loss=2.6413 elbo -1.4583 ll -1.4549 kl_fb 0.0034 kl 0.0034 kl_weight 1.0000 sf 2.5058 reward -0.2223 ll_mean -1.4328 ll_std 0.0994 selected 1.6106 prior_p1 0.3000 avg_p1 0.3012\n",
      "\n",
      "# epoch 37 iter 12958: dev loss -15.3225 elbo -1.4281 ll -1.4256 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf 16.7506 reward -1.4256 ll_mean 0.0000 ll_std 1.0000 selected 1.0841 prior_p1 0.3000 avg_p1 0.2965 acc 0.3797\n",
      " dev0 [gold=3,pred=1]: **it** 's a lovely film with lovely performances by buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one goes unindicted here **,** which is probably **for** the best .\n",
      " dev2 [gold=3,pred=1]: and if you **'re** not nearly **moved** **to** tears **by** a couple **of** **scenes** , you 've **got** ice water **in** **your** **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 38 Iter 13000 loss=1.2004 elbo -1.4808 ll -1.4779 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf 5.3551 reward -0.4480 ll_mean -1.4330 ll_std 0.1003 selected 1.3708 prior_p1 0.3000 avg_p1 0.3024\n",
      "Epoch 38 Iter 13100 loss=2.0708 elbo -1.4979 ll -1.4946 kl_fb 0.0033 kl 0.0033 kl_weight 1.0000 sf 6.9230 reward -0.6169 ll_mean -1.4322 ll_std 0.1012 selected 1.9846 prior_p1 0.3000 avg_p1 0.3040\n",
      "Epoch 38 Iter 13200 loss=2.1716 elbo -1.3442 ll -1.3405 kl_fb 0.0037 kl 0.0037 kl_weight 1.0000 sf -11.2569 reward 0.9131 ll_mean -1.4327 ll_std 0.1009 selected 0.8366 prior_p1 0.3000 avg_p1 0.3007\n",
      "\n",
      "# epoch 38 iter 13299: dev loss -15.5882 elbo -1.4401 ll -1.4380 kl_fb 0.0021 kl 0.0021 kl_weight 1.0000 sf 17.0283 reward -1.4380 ll_mean 0.0000 ll_std 1.0000 selected 1.0822 prior_p1 0.3000 avg_p1 0.3024 acc 0.3651\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** **lovely** film with lovely performances **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=1]: no one goes **unindicted** here , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: **and** if you **'re** not **nearly** moved to **tears** by a couple of **scenes** , you 've **got** ice water in your veins .\n",
      "\n",
      "Epoch 39 Iter 13300 loss=1.4860 elbo -1.4867 ll -1.4826 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 6.6327 reward -0.4976 ll_mean -1.4326 ll_std 0.1007 selected 0.8558 prior_p1 0.3000 avg_p1 0.3024\n",
      "Shuffling training data\n",
      "Epoch 39 Iter 13400 loss=2.0740 elbo -1.4774 ll -1.4728 kl_fb 0.0045 kl 0.0045 kl_weight 1.0000 sf 4.3443 reward -0.4164 ll_mean -1.4314 ll_std 0.0994 selected 1.0804 prior_p1 0.3000 avg_p1 0.3038\n",
      "Epoch 39 Iter 13500 loss=-0.3383 elbo -1.4814 ll -1.4773 kl_fb 0.0041 kl 0.0041 kl_weight 1.0000 sf 4.8342 reward -0.4436 ll_mean -1.4326 ll_std 0.1008 selected 1.0796 prior_p1 0.3000 avg_p1 0.3010\n",
      "Epoch 39 Iter 13600 loss=3.1432 elbo -1.3219 ll -1.3189 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf -13.8899 reward 1.1032 ll_mean -1.4306 ll_std 0.1013 selected 1.2747 prior_p1 0.3000 avg_p1 0.2998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# epoch 39 iter 13640: dev loss -15.7067 elbo -1.4524 ll -1.4499 kl_fb 0.0025 kl 0.0025 kl_weight 1.0000 sf 17.1591 reward -1.4499 ll_mean 0.0000 ll_std 1.0000 selected 1.0737 prior_p1 0.3000 avg_p1 0.3043 acc 0.3560\n",
      " dev0 [gold=3,pred=1]: it 's a lovely **film** with lovely performances by **buy** and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here , **which** **is** probably for **the** best **.**\n",
      " dev2 [gold=3,pred=1]: and **if** **you** **'re** not nearly moved to tears **by** **a** couple of scenes , you 've **got** **ice** **water** in your **veins** **.**\n",
      "\n",
      "Epoch    39: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Shuffling training data\n",
      "Epoch 40 Iter 13700 loss=1.6134 elbo -1.4013 ll -1.3976 kl_fb 0.0037 kl 0.0037 kl_weight 1.0000 sf -3.0523 reward 0.3116 ll_mean -1.4294 ll_std 0.1020 selected 1.4221 prior_p1 0.3000 avg_p1 0.3040\n",
      "Epoch 40 Iter 13800 loss=-0.5026 elbo -1.4515 ll -1.4485 kl_fb 0.0030 kl 0.0030 kl_weight 1.0000 sf 1.7335 reward -0.1635 ll_mean -1.4317 ll_std 0.1028 selected 1.2923 prior_p1 0.3000 avg_p1 0.3023\n",
      "Epoch 40 Iter 13900 loss=1.0801 elbo -1.3139 ll -1.3104 kl_fb 0.0035 kl 0.0035 kl_weight 1.0000 sf -15.1670 reward 1.1806 ll_mean -1.4328 ll_std 0.1037 selected 1.3015 prior_p1 0.3000 avg_p1 0.3006\n",
      "\n",
      "# epoch 40 iter 13981: dev loss -15.5339 elbo -1.4466 ll -1.4449 kl_fb 0.0017 kl 0.0017 kl_weight 1.0000 sf 16.9805 reward -1.4449 ll_mean 0.0000 ll_std 1.0000 selected 1.0665 prior_p1 0.3000 avg_p1 0.3001 acc 0.3488\n",
      " dev0 [gold=3,pred=3]: **it** **'s** a **lovely** film with lovely **performances** **by** buy and accorsi **.**\n",
      " dev1 [gold=2,pred=3]: **no** one **goes** unindicted here , **which** is probably **for** **the** **best** **.**\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly moved to tears by **a** couple **of** scenes **,** you 've got ice water **in** **your** **veins** **.**\n",
      "\n",
      "Epoch 41 Iter 14000 loss=-0.1800 elbo -1.4666 ll -1.4643 kl_fb 0.0023 kl 0.0023 kl_weight 1.0000 sf 3.0156 reward -0.2938 ll_mean -1.4338 ll_std 0.1040 selected 1.4503 prior_p1 0.3000 avg_p1 0.3013\n",
      "Shuffling training data\n",
      "Epoch 41 Iter 14100 loss=0.5138 elbo -1.4724 ll -1.4700 kl_fb 0.0024 kl 0.0024 kl_weight 1.0000 sf 4.3413 reward -0.3346 ll_mean -1.4354 ll_std 0.1035 selected 1.0650 prior_p1 0.3000 avg_p1 0.3011\n",
      "Epoch 41 Iter 14200 loss=1.3282 elbo -1.4329 ll -1.4298 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf -0.9865 reward 0.0618 ll_mean -1.4362 ll_std 0.1039 selected 0.9234 prior_p1 0.3000 avg_p1 0.3024\n",
      "Epoch 41 Iter 14300 loss=0.4536 elbo -1.4600 ll -1.4561 kl_fb 0.0039 kl 0.0039 kl_weight 1.0000 sf 1.9894 reward -0.1759 ll_mean -1.4378 ll_std 0.1040 selected 1.5987 prior_p1 0.3000 avg_p1 0.3041\n",
      "\n",
      "# epoch 41 iter 14322: dev loss -15.3920 elbo -1.4227 ll -1.4205 kl_fb 0.0022 kl 0.0022 kl_weight 1.0000 sf 16.8147 reward -1.4205 ll_mean 0.0000 ll_std 1.0000 selected 1.0780 prior_p1 0.3000 avg_p1 0.3037 acc 0.3706\n",
      " dev0 [gold=3,pred=3]: it **'s** a lovely film with lovely **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if you 're **not** **nearly** **moved** to **tears** by **a** couple **of** scenes , you 've **got** ice water in your **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 42 Iter 14400 loss=3.1872 elbo -1.5398 ll -1.5357 kl_fb 0.0041 kl 0.0041 kl_weight 1.0000 sf 8.6317 reward -0.9373 ll_mean -1.4372 ll_std 0.1050 selected 1.9762 prior_p1 0.3000 avg_p1 0.3047\n",
      "Epoch 42 Iter 14500 loss=3.2269 elbo -1.3704 ll -1.3675 kl_fb 0.0029 kl 0.0029 kl_weight 1.0000 sf -7.6327 reward 0.6417 ll_mean -1.4348 ll_std 0.1049 selected 1.5832 prior_p1 0.3000 avg_p1 0.3019\n",
      "Epoch 42 Iter 14600 loss=1.8580 elbo -1.4614 ll -1.4578 kl_fb 0.0036 kl 0.0036 kl_weight 1.0000 sf 2.3452 reward -0.2051 ll_mean -1.4361 ll_std 0.1053 selected 1.3512 prior_p1 0.3000 avg_p1 0.3006\n",
      "\n",
      "# epoch 42 iter 14663: dev loss -15.4897 elbo -1.4404 ll -1.4387 kl_fb 0.0016 kl 0.0016 kl_weight 1.0000 sf 16.9300 reward -1.4387 ll_mean 0.0000 ll_std 1.0000 selected 1.0717 prior_p1 0.3000 avg_p1 0.3001 acc 0.3651\n",
      " dev0 [gold=3,pred=1]: **it** 's a lovely **film** with lovely performances by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: no **one** goes **unindicted** here **,** which is probably for the **best** .\n",
      " dev2 [gold=3,pred=1]: **and** if **you** 're not nearly **moved** to **tears** **by** a **couple** of scenes , you **'ve** got ice **water** in your veins .\n",
      "\n",
      "Epoch 43 Iter 14700 loss=1.2152 elbo -1.4270 ll -1.4242 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf -1.4369 reward 0.1236 ll_mean -1.4371 ll_std 0.1041 selected 1.1174 prior_p1 0.3000 avg_p1 0.3002\n",
      "Shuffling training data\n",
      "Epoch 43 Iter 14800 loss=1.1763 elbo -1.3419 ll -1.3381 kl_fb 0.0038 kl 0.0038 kl_weight 1.0000 sf -9.7226 reward 0.9449 ll_mean -1.4361 ll_std 0.1038 selected 0.9801 prior_p1 0.3000 avg_p1 0.3010\n",
      "Epoch 43 Iter 14900 loss=1.4847 elbo -1.6268 ll -1.6240 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf 22.3822 reward -1.8147 ll_mean -1.4358 ll_std 0.1037 selected 1.2541 prior_p1 0.3000 avg_p1 0.3019\n",
      "Epoch 43 Iter 15000 loss=2.0126 elbo -1.5996 ll -1.5954 kl_fb 0.0042 kl 0.0042 kl_weight 1.0000 sf 21.2556 reward -1.5674 ll_mean -1.4343 ll_std 0.1027 selected 1.9143 prior_p1 0.3000 avg_p1 0.3027\n",
      "\n",
      "# epoch 43 iter 15004: dev loss -15.3970 elbo -1.4257 ll -1.4235 kl_fb 0.0022 kl 0.0022 kl_weight 1.0000 sf 16.8227 reward -1.4235 ll_mean 0.0000 ll_std 1.0000 selected 1.0826 prior_p1 0.3000 avg_p1 0.3036 acc 0.3697\n",
      " dev0 [gold=3,pred=1]: it **'s** a lovely film with lovely performances **by** buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no one goes unindicted **here** , which is probably for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly moved to tears by **a** **couple** of scenes **,** you 've got **ice** water **in** your veins **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 44 Iter 15100 loss=0.5616 elbo -1.3739 ll -1.3702 kl_fb 0.0036 kl 0.0036 kl_weight 1.0000 sf -6.5278 reward 0.6269 ll_mean -1.4344 ll_std 0.1024 selected 1.4706 prior_p1 0.3000 avg_p1 0.3034\n",
      "Epoch 44 Iter 15200 loss=1.2729 elbo -1.7459 ll -1.7395 kl_fb 0.0064 kl 0.0064 kl_weight 1.0000 sf 36.3406 reward -2.9754 ll_mean -1.4340 ll_std 0.1027 selected 1.5677 prior_p1 0.3000 avg_p1 0.3010\n",
      "Epoch 44 Iter 15300 loss=1.3486 elbo -1.4671 ll -1.4642 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf 3.8910 reward -0.3050 ll_mean -1.4330 ll_std 0.1024 selected 1.1386 prior_p1 0.3000 avg_p1 0.3011\n",
      "\n",
      "# epoch 44 iter 15345: dev loss -15.2411 elbo -1.4113 ll -1.4095 kl_fb 0.0019 kl 0.0019 kl_weight 1.0000 sf 16.6525 reward -1.4095 ll_mean 0.0000 ll_std 1.0000 selected 1.0870 prior_p1 0.3000 avg_p1 0.3023 acc 0.3842\n",
      " dev0 [gold=3,pred=1]: **it** 's **a** **lovely** film **with** lovely performances **by** buy **and** **accorsi** .\n",
      " dev1 [gold=2,pred=3]: no **one** goes unindicted here **,** which **is** probably for **the** **best** .\n",
      " dev2 [gold=3,pred=1]: and if **you** **'re** **not** nearly moved to **tears** by **a** couple of **scenes** , you **'ve** got ice water in **your** veins .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 45 Iter 15400 loss=2.1632 elbo -1.4827 ll -1.4788 kl_fb 0.0039 kl 0.0039 kl_weight 1.0000 sf 4.7243 reward -0.4398 ll_mean -1.4336 ll_std 0.1028 selected 1.1536 prior_p1 0.3000 avg_p1 0.3025\n",
      "Epoch 45 Iter 15500 loss=1.6146 elbo -1.6007 ll -1.5981 kl_fb 0.0026 kl 0.0026 kl_weight 1.0000 sf 19.2773 reward -1.5953 ll_mean -1.4345 ll_std 0.1025 selected 0.9784 prior_p1 0.3000 avg_p1 0.3010\n",
      "Epoch 45 Iter 15600 loss=0.8340 elbo -1.3577 ll -1.3551 kl_fb 0.0026 kl 0.0026 kl_weight 1.0000 sf -10.4710 reward 0.7801 ll_mean -1.4357 ll_std 0.1033 selected 1.2107 prior_p1 0.3000 avg_p1 0.3004\n",
      "\n",
      "# epoch 45 iter 15686: dev loss -15.4878 elbo -1.4389 ll -1.4371 kl_fb 0.0018 kl 0.0018 kl_weight 1.0000 sf 16.9266 reward -1.4371 ll_mean 0.0000 ll_std 1.0000 selected 1.0699 prior_p1 0.3000 avg_p1 0.3016 acc 0.3560\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film with **lovely** performances **by** **buy** and accorsi .\n",
      " dev1 [gold=2,pred=1]: no **one** **goes** unindicted here , **which** is probably **for** the best .\n",
      " dev2 [gold=3,pred=1]: and if you 're not nearly **moved** **to** **tears** **by** **a** couple **of** **scenes** , you **'ve** got **ice** **water** **in** **your** **veins** .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Iter 15700 loss=1.7374 elbo -1.4250 ll -1.4216 kl_fb 0.0034 kl 0.0034 kl_weight 1.0000 sf -1.9282 reward 0.1284 ll_mean -1.4349 ll_std 0.1038 selected 0.8470 prior_p1 0.3000 avg_p1 0.3014\n",
      "Shuffling training data\n",
      "Epoch 46 Iter 15800 loss=1.5020 elbo -1.4516 ll -1.4490 kl_fb 0.0026 kl 0.0026 kl_weight 1.0000 sf 1.6637 reward -0.1411 ll_mean -1.4345 ll_std 0.1031 selected 0.9445 prior_p1 0.3000 avg_p1 0.3015\n",
      "Epoch 46 Iter 15900 loss=0.9278 elbo -1.3519 ll -1.3488 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf -10.2004 reward 0.8434 ll_mean -1.4350 ll_std 0.1022 selected 1.2244 prior_p1 0.3000 avg_p1 0.3000\n",
      "Epoch 46 Iter 16000 loss=0.0218 elbo -1.4541 ll -1.4515 kl_fb 0.0026 kl 0.0026 kl_weight 1.0000 sf 1.8638 reward -0.1456 ll_mean -1.4366 ll_std 0.1024 selected 1.4607 prior_p1 0.3000 avg_p1 0.3007\n",
      "\n",
      "# epoch 46 iter 16027: dev loss -15.6700 elbo -1.4455 ll -1.4436 kl_fb 0.0018 kl 0.0018 kl_weight 1.0000 sf 17.1155 reward -1.4436 ll_mean 0.0000 ll_std 1.0000 selected 1.0868 prior_p1 0.3000 avg_p1 0.3016 acc 0.3333\n",
      " dev0 [gold=3,pred=3]: **it** 's a lovely film with **lovely** **performances** by buy and accorsi .\n",
      " dev1 [gold=2,pred=1]: **no** one goes unindicted **here** , which is probably for the best .\n",
      " dev2 [gold=3,pred=1]: and **if** you **'re** not nearly moved **to** tears by a couple **of** scenes , **you** 've got ice **water** **in** **your** **veins** **.**\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 47 Iter 16100 loss=2.5183 elbo -1.5599 ll -1.5559 kl_fb 0.0040 kl 0.0040 kl_weight 1.0000 sf 18.2260 reward -1.1953 ll_mean -1.4346 ll_std 0.1015 selected 1.1789 prior_p1 0.3000 avg_p1 0.3031\n",
      "Epoch 47 Iter 16200 loss=2.4794 elbo -1.4940 ll -1.4916 kl_fb 0.0023 kl 0.0023 kl_weight 1.0000 sf 6.8520 reward -0.5717 ll_mean -1.4338 ll_std 0.1011 selected 1.1299 prior_p1 0.3000 avg_p1 0.3030\n",
      "Epoch 47 Iter 16300 loss=2.9765 elbo -1.4379 ll -1.4356 kl_fb 0.0023 kl 0.0023 kl_weight 1.0000 sf 0.3315 reward -0.0331 ll_mean -1.4322 ll_std 0.1021 selected 1.0913 prior_p1 0.3000 avg_p1 0.3032\n",
      "\n",
      "# epoch 47 iter 16368: dev loss -15.4677 elbo -1.4326 ll -1.4304 kl_fb 0.0022 kl 0.0022 kl_weight 1.0000 sf 16.9002 reward -1.4304 ll_mean 0.0000 ll_std 1.0000 selected 1.0731 prior_p1 0.3000 avg_p1 0.3033 acc 0.3769\n",
      " dev0 [gold=3,pred=3]: it 's **a** **lovely** film with lovely **performances** by **buy** and **accorsi** **.**\n",
      " dev1 [gold=2,pred=3]: no one goes **unindicted** here **,** which is probably **for** the best .\n",
      " dev2 [gold=3,pred=3]: and if you 're not nearly **moved** to **tears** by a **couple** **of** scenes , you **'ve** **got** ice **water** **in** your veins **.**\n",
      "\n",
      "Epoch 48 Iter 16400 loss=1.9327 elbo -1.3064 ll -1.3036 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf -15.6621 reward 1.2579 ll_mean -1.4324 ll_std 0.1025 selected 1.3583 prior_p1 0.3000 avg_p1 0.3027\n",
      "Shuffling training data\n",
      "Epoch 48 Iter 16500 loss=2.6372 elbo -1.4640 ll -1.4611 kl_fb 0.0029 kl 0.0029 kl_weight 1.0000 sf 3.0779 reward -0.2868 ll_mean -1.4313 ll_std 0.1038 selected 1.1756 prior_p1 0.3000 avg_p1 0.3018\n",
      "Epoch 48 Iter 16600 loss=1.8895 elbo -1.5514 ll -1.5487 kl_fb 0.0028 kl 0.0028 kl_weight 1.0000 sf 11.8054 reward -1.1422 ll_mean -1.4296 ll_std 0.1042 selected 0.7901 prior_p1 0.3000 avg_p1 0.3014\n",
      "Epoch 48 Iter 16700 loss=0.9975 elbo -1.5110 ll -1.5088 kl_fb 0.0022 kl 0.0022 kl_weight 1.0000 sf 8.8301 reward -0.7510 ll_mean -1.4301 ll_std 0.1048 selected 0.8308 prior_p1 0.3000 avg_p1 0.3000\n",
      "\n",
      "# epoch 48 iter 16709: dev loss -15.5735 elbo -1.4399 ll -1.4383 kl_fb 0.0017 kl 0.0017 kl_weight 1.0000 sf 17.0134 reward -1.4383 ll_mean 0.0000 ll_std 1.0000 selected 1.0689 prior_p1 0.3000 avg_p1 0.3010 acc 0.3624\n",
      " dev0 [gold=3,pred=1]: it 's **a** **lovely** film with lovely **performances** by **buy** **and** accorsi .\n",
      " dev1 [gold=2,pred=1]: no one goes unindicted **here** , **which** is probably for **the** best .\n",
      " dev2 [gold=3,pred=1]: and **if** **you** 're **not** nearly moved to tears by **a** couple of scenes **,** **you** 've got ice **water** in your **veins** .\n",
      "\n",
      "Shuffling training data\n",
      "Epoch 49 Iter 16800 loss=1.8923 elbo -1.2879 ll -1.2835 kl_fb 0.0044 kl 0.0044 kl_weight 1.0000 sf -16.6650 reward 1.3879 ll_mean -1.4297 ll_std 0.1054 selected 1.4449 prior_p1 0.3000 avg_p1 0.3016\n",
      "Epoch 49 Iter 16900 loss=-0.9225 elbo -1.5488 ll -1.5459 kl_fb 0.0029 kl 0.0029 kl_weight 1.0000 sf 14.2713 reward -1.0864 ll_mean -1.4308 ll_std 0.1059 selected 0.9492 prior_p1 0.3000 avg_p1 0.3028\n",
      "Epoch 49 Iter 17000 loss=1.2237 elbo -1.4694 ll -1.4663 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf 4.0115 reward -0.3488 ll_mean -1.4294 ll_std 0.1057 selected 1.1155 prior_p1 0.3000 avg_p1 0.3011\n",
      "\n",
      "# epoch 49 iter 17050: dev loss -15.4749 elbo -1.4331 ll -1.4313 kl_fb 0.0018 kl 0.0018 kl_weight 1.0000 sf 16.9080 reward -1.4313 ll_mean 0.0000 ll_std 1.0000 selected 1.0827 prior_p1 0.3000 avg_p1 0.3021 acc 0.3442\n",
      " dev0 [gold=3,pred=1]: it 's **a** lovely **film** with **lovely** **performances** by buy and **accorsi** .\n",
      " dev1 [gold=2,pred=4]: no one goes unindicted here , **which** **is** probably for the best **.**\n",
      " dev2 [gold=3,pred=1]: and if **you** **'re** not nearly **moved** to tears **by** **a** **couple** of scenes **,** you 've got ice **water** in **your** **veins** .\n",
      "\n",
      "Epoch 50 Iter 17100 loss=-0.2521 elbo -1.4371 ll -1.4340 kl_fb 0.0031 kl 0.0031 kl_weight 1.0000 sf 0.3285 reward -0.0233 ll_mean -1.4315 ll_std 0.1064 selected 1.0155 prior_p1 0.3000 avg_p1 0.3022\n",
      "Shuffling training data\n",
      "Epoch 50 Iter 17200 loss=1.2765 elbo -1.3147 ll -1.3113 kl_fb 0.0035 kl 0.0035 kl_weight 1.0000 sf -14.2421 reward 1.1358 ll_mean -1.4324 ll_std 0.1067 selected 1.4652 prior_p1 0.3000 avg_p1 0.3030\n",
      "Epoch 50 Iter 17300 loss=2.2196 elbo -1.3745 ll -1.3713 kl_fb 0.0032 kl 0.0032 kl_weight 1.0000 sf -6.5768 reward 0.5814 ll_mean -1.4329 ll_std 0.1059 selected 0.9523 prior_p1 0.3000 avg_p1 0.3030\n",
      "\n",
      "# epoch 50 iter 17391: dev loss -15.5951 elbo -1.4394 ll -1.4375 kl_fb 0.0019 kl 0.0019 kl_weight 1.0000 sf 17.0344 reward -1.4375 ll_mean 0.0000 ll_std 1.0000 selected 1.0703 prior_p1 0.3000 avg_p1 0.3025 acc 0.3733\n",
      " dev0 [gold=3,pred=1]: **it** **'s** a lovely **film** with **lovely** performances **by** buy and **accorsi** .\n",
      " dev1 [gold=2,pred=1]: no **one** goes unindicted here , **which** is probably for the **best** .\n",
      " dev2 [gold=3,pred=3]: and **if** you 're not nearly moved **to** tears by **a** **couple** of **scenes** , **you** 've got **ice** water **in** your **veins** **.**\n",
      "\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "stop_training = False\n",
    "while True:  # when we run out of examples, shuffle and continue\n",
    "    for batch in get_minibatch(train_data, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "        epoch = iter_i // iters_per_epoch\n",
    "        if epoch > cfg['num_epochs']:\n",
    "            stop_training = True\n",
    "            break\n",
    "\n",
    "        # forward pass\n",
    "        model.train()\n",
    "\n",
    "        # backward pass\n",
    "        model.zero_grad()  # erase previous gradients\n",
    "        \n",
    "        x, y, _ = prepare_minibatch(batch, model.vocab, device=device)\n",
    "        mask = (x != 1)\n",
    "\n",
    "        py, qz, z = model(x)  # py: Categorical\n",
    "        \n",
    "        # \"KL annealing\"\n",
    "        kl_weight += kl_inc\n",
    "        if kl_weight > 1.:\n",
    "            kl_weight = 1.0\n",
    "\n",
    "        loss, terms = model.get_loss(\n",
    "            y,\n",
    "            py=py,\n",
    "            qz=qz,\n",
    "            z=z,\n",
    "            mask=mask,\n",
    "            kl_weight=kl_weight,\n",
    "            min_kl=min_kl,\n",
    "            ll_mean=ll_moving_stats.mean(),\n",
    "            ll_std=ll_moving_stats.std(),\n",
    "            iter_i=iter_i)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # keep an running estimate of the reward (log P(y|x,z))\n",
    "        ll_moving_stats.append(terms['ll'])\n",
    "\n",
    "        loss.backward() # compute new gradients\n",
    "\n",
    "        # gradient clipping generally helps\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cfg['max_grad_norm'])\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        print_num += 1\n",
    "        iter_i += 1\n",
    "\n",
    "        # print info\n",
    "        if iter_i % print_every == 0:\n",
    "\n",
    "            train_loss = train_loss / print_every\n",
    "\n",
    "            print_str = make_kv_string(terms)\n",
    "            print(\"Epoch %r Iter %r loss=%.4f %s\" %\n",
    "                  (epoch, iter_i, train_loss, print_str))\n",
    "            losses.append(train_loss)\n",
    "            print_num = 0\n",
    "            train_loss = 0.\n",
    "\n",
    "        # evaluate\n",
    "        if iter_i % eval_every == 0:\n",
    "\n",
    "            dev_eval, rationales = evaluate(\n",
    "                model, dev_data,\n",
    "                batch_size=eval_batch_size,\n",
    "                device=device,\n",
    "                cfg=cfg, iter_i=iter_i)\n",
    "            accuracies.append(dev_eval[\"acc\"])\n",
    "            valid_losses.append(dev_eval['loss'])\n",
    "\n",
    "            # compute pos freqs for the last epoch\n",
    "            if (iter_i // iters_per_epoch) > cfg['num_epochs']:\n",
    "                tokens = [rationale[0] for rationale in rationales]\n",
    "                dev_pos_freqs = compute_pos_frequency(tokens)\n",
    "\n",
    "            print(\"\\n# epoch %r iter %r: dev %s\" % (\n",
    "                epoch, iter_i, make_kv_string(dev_eval)))\n",
    "\n",
    "            for exid in range(3):\n",
    "                print(' dev%d [gold=%d,pred=%d]:' % (exid, dev_data[exid].label, rationales[exid][1]),  \n",
    "                      ' '.join(rationales[exid][0]))\n",
    "            print()\n",
    "\n",
    "            # adjust learning rate\n",
    "            scheduler.step(dev_eval[\"loss\"])\n",
    "\n",
    "    if stop_training:\n",
    "        model.eval()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3860127157126376 -15.360341696590986\n"
     ]
    }
   ],
   "source": [
    "# Best acc\n",
    "max_acc = max(accuracies)\n",
    "idxs = accuracies.index(max_acc)\n",
    "valid_loss = valid_losses[idxs]\n",
    "print(max_acc, valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "25BWgZj44nE9",
    "outputId": "effa4090-97d1-4b2f-ee6f-d3b38452826c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NNP', 2519), ('NN', 1490), ('JJ', 1208), ('VBP', 309), ('VB', 283)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_pos_freqs.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "| model                   | test accuracy | most common POSes    |\n",
    "|-------------------------|---------------|----------------------|\n",
    "| bow, fixed embeddings   | 36,70         | NNP, NN, JJ, VBP, VB |\n",
    "| bow, trained embeddings | 37,33         | NNP, NN, JJ, VBP, VB |\n",
    "| ff, fixed embeddings    | 36,51         | NNP, NN, JJ, VBP, VB |\n",
    "| lstm, fixed embeddings  | 38,60         | NNP, NN, JJ, VBP, VB |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7w_Ko657vRGo"
   },
   "source": [
    "# Variance reduction\n",
    "\n",
    "**This is an extra**\n",
    "\n",
    "We can use a *control variate* to reduce the variance of our gradient estimates.\n",
    "\n",
    "Let's recap the idea in general terms. We are looking to solve some expectation\n",
    "\\begin{align}\n",
    "\\mu_f = \\mathbb E[f(Z)]\n",
    "\\end{align}\n",
    "but unfortunatelly, realising the full sum (or integral for continuous variables) is intractable. Thus we employ MC estimation\n",
    "\\begin{align}\n",
    "\\hat \\mu_f &\\overset{\\text{MC}}{\\approx} \\frac{1}{S} \\sum_{s=1}^S f(z_s) & \\text{where }z_s \\sim Q(z|x)\n",
    "\\end{align}\n",
    "Note that the variance of this estimate is\n",
    "\\begin{align}\n",
    "\\text{Var}(\\hat \\mu_f) &=  \\frac{1}{S}\\text{Var}(f(Z)) \\\\\n",
    "&= \\frac{1}{S} \\mathbb E[( f(Z) - \\mathbb E[f(Z)])^2]\n",
    "\\end{align}\n",
    "Note that this variance is such that it goes down as we sample more, in a rate $\\mathcal O(S^{-1})$.\n",
    "See that if we sample $10$ times more, we will only obtain an decrease in variance in the order of $10^{-1}$. This means that sampling more is generally not the most convenient way to decrease variance.\n",
    "\n",
    "*Digression* we can estimate the variance itself via MC, an unbiased estimate looks like\n",
    "\\begin{align}\n",
    "\\hat \\sigma^2_f = \\frac{1}{S(S-1)} \\sum_{s=1}^S (f(z_s) - \\hat \\mu_f)^2\n",
    "\\end{align}\n",
    "but not that this estimate is even hard to improve since it decreases with $\\mathcal O(S^{-2})$.\n",
    "\n",
    "Back to out main problem: let's try and improve the variance of our estimator to $\\mu_f$.\n",
    "\n",
    "It's a fact, and it can be shown trivially, that\n",
    "\\begin{align}\n",
    "\\mu_f &=  \\mathbb E[f(Z) - \\psi(Z)] + \\underbrace{\\mathbb E[\\psi(Z)]}_{\\mu_\\psi} \\\\\n",
    " &\\overset{\\text{MC}}{\\approx} \\underbrace{\\left(\\frac{1}{S} \\sum_{s=1}^S f(z_s) - \\psi(z_s) \\right) + \\mu_\\psi}_{\\hat c}\n",
    "\\end{align}\n",
    "where we assume the existence of some function $\\psi(z)$ for which the expected value $\\mu_\\psi$ is known and we estimate the expected difference $\\mathbb E[f(Z) - \\psi(Z)]$ via MC. We used this axuxiliary function, also known as a *control variate*, to derive a new estimator, which we will denote by $\\hat c$.\n",
    "\n",
    "The variance of this new estimator is show below:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}( \\hat c ) &= \\text{Var}(\\hat \\mu_{f-\\psi}) + 2\\underbrace{\\text{Cov}(\\hat \\mu_{f-\\psi}, \\mu_\\psi)}_{\\mathbb E[\\hat \\mu_{f-\\psi}  \\mu_\\psi] - \\mathbb E[\\hat \\mu_{f-\\psi}] \\mathbb E[\\mu_\\psi]} + \\underbrace{\\text{Var}(\\mu_\\psi)}_{\\color{blue}{0} } \\\\\n",
    "&= \\frac{1}{S}\\text{Var}(f- \\psi)  + 2 \\underbrace{\\left( \\mu_\\psi \\mu_{f-\\psi} - \\mu_{f-\\psi} \\mu_\\psi \\right)}_{\\color{blue}{0}} \n",
    "\\end{align}\n",
    "where the variance of $\\mu_\\psi$ is 0 because we know it in closed form (no need for MC estimation), and the covariance is $0$ as shown in the second row.\n",
    "\n",
    "That is, the variance of $\\hat c$ is essentially the variance of estimating $\\mathbb E[f(Z) - \\psi(Z)]$, which in turn depends on the variance \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Var}(f-\\psi) &= \\text{Var}(f) - 2\\text{Cov}(f, \\psi) + \\text{Var}(\\psi)\n",
    "\\end{align}\n",
    "where we can see that if $\\text{Cov}(f, \\psi) > \\frac{\\text{Var}(\\psi)}{2}$ we achieve variance reduction as then $\\text{Var}(f-\\psi)$ would be smaller than $\\text{Var(f)}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovKcRnqH_PGp"
   },
   "source": [
    "\n",
    "## Baselines\n",
    "\n",
    "Baslines are control variates of a very simple form:\n",
    "\\begin{align}\n",
    "\\mathbb E[f(Z)] = \\mathbb E[f(Z) - C] + \\mathbb E[C]\n",
    "\\end{align}\n",
    "where $C$ is a constant with respect to $z$.\n",
    "\n",
    "In the context of the score function estimator, a baseline looks like a quantity $C(x; \\omega)$, this may be\n",
    "* just a constant;\n",
    "* or a function of the input (but not of the latent variable), which could be itself implemented as a neural network;\n",
    "* a combination of the two.\n",
    " \n",
    "\n",
    "Let's focus on the first term of the ELBO (so I'm omitting the KL term here). The gradient with respect to parameters of the inference model becomes:\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\\\\\n",
    "&=\\mathbb E_{Q(z|x, \\lambda)}\\left[\\log P(x|z, \\theta) \\nabla_\\lambda \\log Q(z|x, \\lambda) - \\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] + \\underbrace{\\mathbb E_{Q(z|x, \\lambda)}\\left[\\color{red}{C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda) }  \\right] }_{=0} \\\\\n",
    "&= \\mathbb E_{Q(z|x, \\lambda)}\\left[ \\color{blue}{\\left(\\log P(x|z, \\theta) - C(x; \\omega) \\right)}\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right] \\\\\n",
    "&\n",
    "\\end{align}\n",
    "We can show that the last term is $0$\n",
    "\n",
    "\\begin{align}\n",
    "&\\mathbb E_{Q(z|x, \\lambda)}\\left[C(x; \\omega)\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]  \\\\&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\nabla_\\lambda \\log Q(z|x, \\lambda)   \\right]\\\\\n",
    "&= C(x; \\omega) \\mathbb E_{Q(z|x, \\lambda)}\\left[\\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\right] \\\\\n",
    "&= C(x; \\omega) \\sum_z Q(z|x, \\lambda) \\frac{1}{Q(z|x, \\lambda)} \\nabla_\\lambda Q(z|x, \\lambda)   \\\\\n",
    "&= C(x; \\omega) \\sum_z\\nabla_\\lambda Q(z|x, \\lambda)  \\\\\n",
    "&= C(x; \\omega) \\nabla_\\lambda \\underbrace{\\sum_z Q(z|x, \\lambda)  }_{=1}\\\\\n",
    "&=0\n",
    "\\end{align}\n",
    "\n",
    "Examples of useful baselines:\n",
    "\n",
    "* a running average of the learning signal: at some iteration $t$ we can use a running average of $\\log P(x|z, \\theta)$ using parameter estimates $\\theta$ from iterations $i < t$, this is a baseline that likely leads to high correlation between control variate and learning signal and can lead to variance reduction;\n",
    "* another technique is to have an MLP with parameters $\\omega$ predict a scalar and train this MLP to approximate the learning signal $\\log P(x|z, \\theta)$ via regression:\n",
    "\\begin{align}\n",
    "\\arg\\max_\\omega \\left( C(x; \\omega) - \\log P(x|z, \\theta) \\right)^2\n",
    "\\end{align}\n",
    "its left as an extra to implement these ideas.\n",
    "\n",
    "One more note: we can also use something called a *multiplicative baseline* in the literature of reinforcement learning, whereby we incorporate a running estimate of the standard deviation of the learning signal computed based on the values attained on previous iterations:\n",
    "\\begin{align}\n",
    "\\mathbb E_{Q(z|x, \\lambda)}\\left[ \\frac{1}{\\hat\\sigma_{\\text{past}}}\\left(\\log P(x|z, \\theta) - \\hat \\mu_{\\text{past}}\\right)\\nabla_\\lambda \\log Q(z|x, \\lambda)\\right]\n",
    "\\end{align}\n",
    "this form of contorl variate aim at promoting the learning signal (or reward in reinforcement learning literature) to be distributed by $\\mathcal N(0, 1)$. Note that multiplying the reward by a constant does not bias the estimator, and in this case, may lead to variance reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVsWgmlIWvZq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2VntYV3WvZt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTxG1AvPWvZv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of SST.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
